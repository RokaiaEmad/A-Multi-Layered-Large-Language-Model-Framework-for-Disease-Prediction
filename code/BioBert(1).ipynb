{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-11T14:21:19.928901Z",
     "iopub.status.busy": "2025-03-11T14:21:19.928441Z",
     "iopub.status.idle": "2025-03-11T14:22:45.580114Z",
     "shell.execute_reply": "2025-03-11T14:22:45.579137Z",
     "shell.execute_reply.started": "2025-03-11T14:21:19.928858Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Training Dataset Class Distribution:\n",
      "category\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ù†Ø³Ø§Ø¦ÙŠØ©                       56128\n",
      "Ø§Ù†Ù Ø§Ø°Ù† ÙˆØ­Ù†Ø¬Ø±Ø©                     15646\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹Ø¶Ù„Ø§Øª ÙˆØ§Ù„Ø¹Ø¸Ø§Ù… Ùˆ Ø§Ù„Ù…ÙØ§ØµÙ„    14848\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹ÙŠÙˆÙ†                       14639\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨ Ùˆ Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ†             12756\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ                12708\n",
      "Ø§Ù„Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù†Ø³ÙŠØ©                     8874\n",
      "Ø·Ø¨ Ø§Ù„Ø§Ø³Ù†Ø§Ù†                          8805\n",
      "Ø¬Ø±Ø§Ø­Ø© ØªØ¬Ù…ÙŠÙ„                         7875\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¯Ù…                          6861\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ğŸ”¹ Test Dataset Class Distribution:\n",
      "category\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ù†Ø³Ø§Ø¦ÙŠØ©                       14032\n",
      "Ø§Ù†Ù Ø§Ø°Ù† ÙˆØ­Ù†Ø¬Ø±Ø©                      3912\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹Ø¶Ù„Ø§Øª ÙˆØ§Ù„Ø¹Ø¸Ø§Ù… Ùˆ Ø§Ù„Ù…ÙØ§ØµÙ„     3712\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹ÙŠÙˆÙ†                        3660\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨ Ùˆ Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ†              3190\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ                 3177\n",
      "Ø§Ù„Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù†Ø³ÙŠØ©                     2219\n",
      "Ø·Ø¨ Ø§Ù„Ø§Ø³Ù†Ø§Ù†                          2202\n",
      "Ø¬Ø±Ø§Ø­Ø© ØªØ¬Ù…ÙŠÙ„                         1969\n",
      "Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¯Ù…                          1716\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b8baa13e084b88bade3a599c0ed9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fd0c8e43f04cd68941cd97e1d7e7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8084a7776424074b12fad9e2e3b254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde551dc0b6a4235bab48996415e7343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e9d28366804d5eb12e233af1da3926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/159140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568b5fa89468411bb7ff7bc75394d6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7676adec3d4a9c9e6f08497b033765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import logging\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, base_model, num_labels): \n",
    "        super(CustomModel, self).__init__()  \n",
    "        self.base_model = base_model \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(base_model.config.hidden_size, num_labels)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "# Load data\n",
    "train_path = \"/kaggle/input/maqa-dataset/Unbalanced/Unbalanced/MAQA_Train.xlsx\"\n",
    "test_path = \"/kaggle/input/maqa-dataset/Unbalanced/Unbalanced/MAQA_Test.xlsx\"\n",
    "train_df = pd.read_excel(train_path)\n",
    "test_df = pd.read_excel(test_path)\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "all_data = all_data[['q_body', 'category']]\n",
    "\n",
    "valid_categories = [\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ù†Ø³Ø§Ø¦ÙŠØ©\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹Ø¶Ù„Ø§Øª ÙˆØ§Ù„Ø¹Ø¸Ø§Ù… Ùˆ Ø§Ù„Ù…ÙØ§ØµÙ„\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ\",\n",
    "    \"Ø§Ù„Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù†Ø³ÙŠØ©\",\n",
    "    \"Ø·Ø¨ Ø§Ù„Ø§Ø³Ù†Ø§Ù†\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨ Ùˆ Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ†\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹ÙŠÙˆÙ†\",\n",
    "    \"Ø§Ù†Ù Ø§Ø°Ù† ÙˆØ­Ù†Ø¬Ø±Ø©\",\n",
    "    \"Ø¬Ø±Ø§Ø­Ø© ØªØ¬Ù…ÙŠÙ„\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¯Ù…\"\n",
    "]\n",
    "\n",
    "all_data = all_data[all_data[\"category\"].isin(valid_categories)]\n",
    "all_data = all_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df, test_df = train_test_split(all_data, test_size=0.2, random_state=42, stratify=all_data['category'])\n",
    "train_df[\"text\"] = train_df[\"q_body\"]\n",
    "test_df[\"text\"] = test_df[\"q_body\"]\n",
    "\n",
    "category_mapping = {cat: i for i, cat in enumerate(valid_categories)}\n",
    "train_df['label'] = train_df['category'].map(category_mapping)\n",
    "test_df['label'] = test_df['category'].map(category_mapping)\n",
    "\n",
    "model_name = \"monologg/biobert_v1.1_pubmed\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"text\": train_df[\"text\"].tolist(), \"label\": train_df[\"label\"].tolist()})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_df[\"text\"].tolist(), \"label\": test_df[\"label\"].tolist()})\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:22:45.581602Z",
     "iopub.status.busy": "2025-03-11T14:22:45.581336Z",
     "iopub.status.idle": "2025-03-11T14:22:45.934042Z",
     "shell.execute_reply": "2025-03-11T14:22:45.933107Z",
     "shell.execute_reply.started": "2025-03-11T14:22:45.581560Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-48adf45f4208>:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:22:45.935723Z",
     "iopub.status.busy": "2025-03-11T14:22:45.935415Z",
     "iopub.status.idle": "2025-03-11T19:46:49.096707Z",
     "shell.execute_reply": "2025-03-11T19:46:49.095928Z",
     "shell.execute_reply.started": "2025-03-11T14:22:45.935700Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Starting Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16580' max='16580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16580/16580 5:19:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.507600</td>\n",
       "      <td>0.522392</td>\n",
       "      <td>0.840835</td>\n",
       "      <td>0.841410</td>\n",
       "      <td>0.840835</td>\n",
       "      <td>0.840106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.378196</td>\n",
       "      <td>0.881048</td>\n",
       "      <td>0.879337</td>\n",
       "      <td>0.881048</td>\n",
       "      <td>0.879296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.348277</td>\n",
       "      <td>0.891427</td>\n",
       "      <td>0.891271</td>\n",
       "      <td>0.891427</td>\n",
       "      <td>0.890671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.312700</td>\n",
       "      <td>0.325073</td>\n",
       "      <td>0.898791</td>\n",
       "      <td>0.899630</td>\n",
       "      <td>0.898791</td>\n",
       "      <td>0.898556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.315732</td>\n",
       "      <td>0.902636</td>\n",
       "      <td>0.902260</td>\n",
       "      <td>0.902636</td>\n",
       "      <td>0.901884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.314258</td>\n",
       "      <td>0.904421</td>\n",
       "      <td>0.903708</td>\n",
       "      <td>0.904421</td>\n",
       "      <td>0.903655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.311632</td>\n",
       "      <td>0.906255</td>\n",
       "      <td>0.905171</td>\n",
       "      <td>0.906255</td>\n",
       "      <td>0.905081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.320682</td>\n",
       "      <td>0.905703</td>\n",
       "      <td>0.904696</td>\n",
       "      <td>0.905703</td>\n",
       "      <td>0.904561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.326859</td>\n",
       "      <td>0.906834</td>\n",
       "      <td>0.905602</td>\n",
       "      <td>0.906834</td>\n",
       "      <td>0.905728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.330647</td>\n",
       "      <td>0.906834</td>\n",
       "      <td>0.905774</td>\n",
       "      <td>0.906834</td>\n",
       "      <td>0.905894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Test Metrics: {'eval_loss': 0.33064693212509155, 'eval_accuracy': 0.9068335469602151, 'eval_precision': 0.9057742609146948, 'eval_recall': 0.9068335469602151, 'eval_f1': 0.9058936545235001, 'eval_runtime': 147.1435, 'eval_samples_per_second': 270.41, 'eval_steps_per_second': 2.82, 'epoch': 10.0}\n",
      "\n",
      "ğŸ”¹ Confusion Matrix:\n",
      "[[13514    95    83   195    34    34    12    32    27     6]\n",
      " [   78  3456    20    27    10    53     5    26    14    23]\n",
      " [  107    40  2763    38    32    84    11    55    23    24]\n",
      " [  451    39    30  1639    12     7     1     4    22    14]\n",
      " [   53    12    18     8  2067     1     5    27    11     0]\n",
      " [   44   106    74    10     5  2678    11    44    18   200]\n",
      " [    8    11    16     3     1    15  3467    33    73    33]\n",
      " [   26    29    48    10    45    37    30  3613    54    20]\n",
      " [  173    57    22    20    29    14    47    64  1515    28]\n",
      " [   21    20    35    13     5   170    21    34    27  1370]]\n",
      "\n",
      "ğŸ”¹ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95     14032\n",
      "           1       0.89      0.93      0.91      3712\n",
      "           2       0.89      0.87      0.88      3177\n",
      "           3       0.83      0.74      0.78      2219\n",
      "           4       0.92      0.94      0.93      2202\n",
      "           5       0.87      0.84      0.85      3190\n",
      "           6       0.96      0.95      0.95      3660\n",
      "           7       0.92      0.92      0.92      3912\n",
      "           8       0.85      0.77      0.81      1969\n",
      "           9       0.80      0.80      0.80      1716\n",
      "\n",
      "    accuracy                           0.91     39789\n",
      "   macro avg       0.89      0.87      0.88     39789\n",
      "weighted avg       0.91      0.91      0.91     39789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nğŸ”¹ Starting Training...\")\n",
    "trainer.train()\n",
    "\n",
    "test_metrics = trainer.evaluate(test_dataset)\n",
    "print(\"\\nğŸ”¹ Test Metrics:\", test_metrics)\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "print(\"\\nğŸ”¹ Confusion Matrix:\")\n",
    "print(confusion_matrix(labels, preds))\n",
    "\n",
    "print(\"\\nğŸ”¹ Classification Report:\")\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T19:46:49.098365Z",
     "iopub.status.busy": "2025-03-11T19:46:49.098019Z",
     "iopub.status.idle": "2025-03-11T19:46:50.135083Z",
     "shell.execute_reply": "2025-03-11T19:46:50.134377Z",
     "shell.execute_reply.started": "2025-03-11T19:46:49.098323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ğŸ”¹ Save Model & Tokenizer\n",
    "def save_complete_model(model, tokenizer, category_mapping, save_path):\n",
    "    model.base_model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "    \n",
    "    classifier_state = {\n",
    "        'classifier_state': model.classifier.state_dict(),\n",
    "        'num_labels': model.classifier.out_features\n",
    "    }\n",
    "    torch.save(classifier_state, f\"{save_path}/classifier_state.pt\")\n",
    "    \n",
    "    with open(f\"{save_path}/category_mapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(category_mapping, f)\n",
    "\n",
    "# Save the model\n",
    "save_complete_model(trainer.model, tokenizer, category_mapping, \"BioBert\")\n",
    "\n",
    "# ğŸ”¹ Load the Model for Inference\n",
    "def load_complete_model(model_path):\n",
    "    base_model = AutoModel.from_pretrained(model_path)\n",
    "    classifier_state = torch.load(f\"{model_path}/classifier_state.pt\", map_location=torch.device('cpu'))\n",
    "    model = CustomModel(base_model, classifier_state['num_labels'])\n",
    "    model.classifier.load_state_dict(classifier_state['classifier_state'])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T19:46:50.136162Z",
     "iopub.status.busy": "2025-03-11T19:46:50.135928Z",
     "iopub.status.idle": "2025-03-11T19:46:50.222846Z",
     "shell.execute_reply": "2025-03-11T19:46:50.222005Z",
     "shell.execute_reply.started": "2025-03-11T19:46:50.136142Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Loaded Successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e42658041941>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classifier_state = torch.load(f\"{model_path}/classifier_state.pt\", map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BioBert\")\n",
    "\n",
    "# Load the trained model\n",
    "model2 = load_complete_model(\"BioBert\")\n",
    "print(\"âœ… Model Loaded Successfully!\")\n",
    "\n",
    "# ğŸ”¹ Function for Predictions\n",
    "def predict_category(text, model, tokenizer, category_mapping):\n",
    "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "    logits = outputs[\"logits\"]\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "    category_mapping_reverse = {v: k for k, v in category_mapping.items()}\n",
    "    return category_mapping_reverse[predicted_label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T19:46:50.223802Z",
     "iopub.status.busy": "2025-03-11T19:46:50.223556Z",
     "iopub.status.idle": "2025-03-11T19:47:12.149340Z",
     "shell.execute_reply": "2025-03-11T19:47:12.148683Z",
     "shell.execute_reply.started": "2025-03-11T19:46:50.223775Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Input: Ø§Ù†ÙŠÙ…ÙŠØ§ Ø­Ø§Ø¯Ù‡\n",
      "Predicted Category: Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¯Ù…\n",
      "\n",
      "ğŸ”¹ Input: Ø§Ù„ØªÙ‡Ø§Ø¨ ÙÙŠ Ø§Ù„Ù…Ø¹Ø¯Ù‡\n",
      "Predicted Category: Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ\n",
      "\n",
      "ğŸ”¹ Input: Ø¬ÙØ§Ù Ø§Ù„Ø¹ÙŠÙ†\n",
      "Predicted Category: Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹ÙŠÙˆÙ†\n",
      "\n",
      "ğŸ”¹ Input: Ù†Ø²Ù„Ù‡ Ø¨Ø±Ø¯\n",
      "Predicted Category: Ø§Ù†Ù Ø§Ø°Ù† ÙˆØ­Ù†Ø¬Ø±Ø©\n",
      "\n",
      "ğŸ”¹ Input: ÙƒØ³Ø± ÙÙŠ Ø§Ù„Ù…ÙØµÙ„\n",
      "Predicted Category: Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹Ø¶Ù„Ø§Øª ÙˆØ§Ù„Ø¹Ø¸Ø§Ù… Ùˆ Ø§Ù„Ù…ÙØ§ØµÙ„\n",
      "\n",
      "âœ… Model Saved & Zipped for Download!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='BioBert.zip' target='_blank'>BioBert.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/BioBert.zip"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ğŸ”¹ Sample Predictions\n",
    "test_samples = [\"Ø§Ù†ÙŠÙ…ÙŠØ§ Ø­Ø§Ø¯Ù‡\", \"Ø§Ù„ØªÙ‡Ø§Ø¨ ÙÙŠ Ø§Ù„Ù…Ø¹Ø¯Ù‡\", \"Ø¬ÙØ§Ù Ø§Ù„Ø¹ÙŠÙ†\", \"Ù†Ø²Ù„Ù‡ Ø¨Ø±Ø¯\", \"ÙƒØ³Ø± ÙÙŠ Ø§Ù„Ù…ÙØµÙ„\"]\n",
    "for text in test_samples:\n",
    "    predicted_category = predict_category(text, model2, tokenizer, category_mapping)\n",
    "    print(f\"\\nğŸ”¹ Input: {text}\")\n",
    "    print(f\"Predicted Category: {predicted_category}\")\n",
    "\n",
    "# ğŸ”¹ Zip Model for Download\n",
    "shutil.make_archive(\"BioBert\", 'zip', \"BioBert\")\n",
    "print(\"\\nâœ… Model Saved & Zipped for Download!\")\n",
    "\n",
    "# Provide a download link\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'BioBert.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6528935,
     "sourceId": 10552124,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
