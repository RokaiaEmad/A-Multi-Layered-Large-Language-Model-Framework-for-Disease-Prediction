{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "1e2fe242-ff4e-4b80-a65e-86c9a4412a02",
    "_uuid": "534b98c4-041f-416f-8871-39f66e40d1f4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-28T16:23:28.458169Z",
     "iopub.status.busy": "2024-12-28T16:23:28.457899Z",
     "iopub.status.idle": "2024-12-28T16:26:29.534090Z",
     "shell.execute_reply": "2024-12-28T16:26:29.533216Z",
     "shell.execute_reply.started": "2024-12-28T16:23:28.458120Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.2.2\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2024.6.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.2)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (71.0.4)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1+cu121\n",
      "    Uninstalling torch-2.4.1+cu121:\n",
      "      Successfully uninstalled torch-2.4.1+cu121\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\n",
      "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 triton-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting transformers==4.40.0\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets==2.18.0\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting accelerate==0.29.3\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting evaluate==0.4.1\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting bitsandbytes==0.43.1\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting huggingface_hub==0.22.2\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting trl==0.8.6\n",
      "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft==0.10.0\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (18.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (2.1.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.70.16)\n",
      "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.10.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (2.2.2)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.22.2) (4.12.2)\n",
      "Collecting tyro>=0.5.11 (from trl==0.8.6)\n",
      "  Downloading tyro-0.9.5-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3) (12.6.85)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (13.8.1)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.8.6)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (4.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
      "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading tyro-0.9.5-py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: shtab, fsspec, responses, huggingface_hub, tyro, transformers, bitsandbytes, accelerate, peft, datasets, trl, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.24.7\n",
      "    Uninstalling huggingface-hub-0.24.7:\n",
      "      Successfully uninstalled huggingface-hub-0.24.7\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.2\n",
      "    Uninstalling transformers-4.44.2:\n",
      "      Successfully uninstalled transformers-4.44.2\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.34.2\n",
      "    Uninstalling accelerate-0.34.2:\n",
      "      Successfully uninstalled accelerate-0.34.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.2.0\n",
      "    Uninstalling datasets-3.2.0:\n",
      "      Successfully uninstalled datasets-3.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
      "distributed 2024.8.0 requires dask==2024.8.0, but you have dask 2024.12.1 which is incompatible.\n",
      "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.2.0 which is incompatible.\n",
      "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\n",
      "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.29.3 bitsandbytes-0.43.1 datasets-2.18.0 evaluate-0.4.1 fsspec-2024.2.0 huggingface_hub-0.22.2 peft-0.10.0 responses-0.18.0 shtab-1.7.1 transformers-4.40.0 trl-0.8.6 tyro-0.9.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"torch==2.2.2\" tensorboard\n",
    "%pip install --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T16:27:39.843396Z",
     "iopub.status.busy": "2024-12-28T16:27:39.843055Z",
     "iopub.status.idle": "2024-12-28T16:27:40.586509Z",
     "shell.execute_reply": "2024-12-28T16:27:40.585828Z",
     "shell.execute_reply.started": "2024-12-28T16:27:39.843368Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T16:27:42.858642Z",
     "iopub.status.busy": "2024-12-28T16:27:42.858324Z",
     "iopub.status.idle": "2024-12-28T16:27:55.098068Z",
     "shell.execute_reply": "2024-12-28T16:27:55.097430Z",
     "shell.execute_reply.started": "2024-12-28T16:27:42.858610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:01:24.063743Z",
     "iopub.status.busy": "2024-11-28T19:01:24.063491Z",
     "iopub.status.idle": "2024-11-28T19:01:32.789631Z",
     "shell.execute_reply": "2024-11-28T19:01:32.788792Z",
     "shell.execute_reply.started": "2024-11-28T19:01:24.063719Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:01:32.791262Z",
     "iopub.status.busy": "2024-11-28T19:01:32.790978Z",
     "iopub.status.idle": "2024-11-28T19:01:41.590924Z",
     "shell.execute_reply": "2024-11-28T19:01:41.590082Z",
     "shell.execute_reply.started": "2024-11-28T19:01:32.791233Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.85)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:01:41.592660Z",
     "iopub.status.busy": "2024-11-28T19:01:41.592342Z",
     "iopub.status.idle": "2024-11-28T19:01:50.175297Z",
     "shell.execute_reply": "2024-11-28T19:01:50.174269Z",
     "shell.execute_reply.started": "2024-11-28T19:01:41.592630Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.2.2)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.40.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.29.3)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install peft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:04.240287Z",
     "iopub.status.busy": "2024-12-28T19:16:04.239950Z",
     "iopub.status.idle": "2024-12-28T19:16:04.610101Z",
     "shell.execute_reply": "2024-12-28T19:16:04.609157Z",
     "shell.execute_reply.started": "2024-12-28T19:16:04.240264Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image type</th>\n",
       "      <th>Post</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Type</th>\n",
       "      <th>NER</th>\n",
       "      <th>Summarised</th>\n",
       "      <th>Refine</th>\n",
       "      <th>Post.1</th>\n",
       "      <th>Refined</th>\n",
       "      <th>NER_POST</th>\n",
       "      <th>Summarised_POST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n",
       "      <td>حرج</td>\n",
       "      <td>مخ واعصاب</td>\n",
       "      <td>مخ واعصاب</td>\n",
       "      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n",
       "      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n",
       "      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n",
       "      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n",
       "      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n",
       "      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n",
       "      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n",
       "      <td>غير حرج</td>\n",
       "      <td>قولون عصبي</td>\n",
       "      <td>باطنه</td>\n",
       "      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ</td>\n",
       "      <td>ﻗﻮﻟﻮﻥ عصبي</td>\n",
       "      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n",
       "      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n",
       "      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n",
       "      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...</td>\n",
       "      <td>ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n",
       "      <td>حرج</td>\n",
       "      <td>كدمه في الوجه</td>\n",
       "      <td>انف واذن وحنجره</td>\n",
       "      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ</td>\n",
       "      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n",
       "      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n",
       "      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n",
       "      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n",
       "      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...</td>\n",
       "      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n",
       "      <td>غير حرج</td>\n",
       "      <td>ضغط</td>\n",
       "      <td>باطنه</td>\n",
       "      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n",
       "      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n",
       "      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n",
       "      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n",
       "      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n",
       "      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n",
       "      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n",
       "      <td>غير حرج</td>\n",
       "      <td>عدم التركيز و النسيان</td>\n",
       "      <td>مخ واعصاب</td>\n",
       "      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n",
       "      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة</td>\n",
       "      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n",
       "      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n",
       "      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n",
       "      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n",
       "      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>NaN</td>\n",
       "      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n",
       "      <td>غير حرج</td>\n",
       "      <td>تساقط الشعر</td>\n",
       "      <td>جلديه وتناسليه</td>\n",
       "      <td>شعرى وقع من الامام فقط</td>\n",
       "      <td>شعرى وقع من الامام فقط</td>\n",
       "      <td>NaN</td>\n",
       "      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n",
       "      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n",
       "      <td>شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...</td>\n",
       "      <td>شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>NaN</td>\n",
       "      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...</td>\n",
       "      <td>غير حرج</td>\n",
       "      <td>هالات سوداء</td>\n",
       "      <td>جلديه وتناسليه</td>\n",
       "      <td>كريم خافي للعيوب كونسيلر طبي للهالات السوداء</td>\n",
       "      <td>هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...</td>\n",
       "      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونس...</td>\n",
       "      <td>كريم خافي للعيوب كونسيلر طبي للهالات السوداء ل...</td>\n",
       "      <td>هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>NaN</td>\n",
       "      <td>عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...</td>\n",
       "      <td>حرج</td>\n",
       "      <td>تساقط الشعر</td>\n",
       "      <td>جلديه وتناسليه</td>\n",
       "      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ</td>\n",
       "      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ</td>\n",
       "      <td>\\n\\n تساقط الشعر بدرجة كبيرة</td>\n",
       "      <td>عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...</td>\n",
       "      <td>\\n\\n تساقط الشعر بدرجة كبيرة عندي تساقط الشعر ...</td>\n",
       "      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...</td>\n",
       "      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>NaN</td>\n",
       "      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...</td>\n",
       "      <td>غير حرج</td>\n",
       "      <td>اكسده البشره</td>\n",
       "      <td>جلديه وتناسليه</td>\n",
       "      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة</td>\n",
       "      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة</td>\n",
       "      <td>NaN</td>\n",
       "      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...</td>\n",
       "      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف ال...</td>\n",
       "      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...</td>\n",
       "      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>NaN</td>\n",
       "      <td>علاج للاكزيما العصبية</td>\n",
       "      <td>حرج</td>\n",
       "      <td>اكزيما العصبيه</td>\n",
       "      <td>جلديه وتناسليه</td>\n",
       "      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ</td>\n",
       "      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>علاج للاكزيما العصبية</td>\n",
       "      <td>علاج للاكزيما العصبية</td>\n",
       "      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية</td>\n",
       "      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image type                                               Post Severity  \\\n",
       "0       Unknown  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...      حرج   \n",
       "1       Unknown          يخوان شو الحل مع القولون العصبي مشان الله  غير حرج   \n",
       "2       Unknown  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...      حرج   \n",
       "3       Unknown  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...  غير حرج   \n",
       "4       Unknown  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...  غير حرج   \n",
       "...         ...                                                ...      ...   \n",
       "1587        NaN                    شعرى وقع من الامام فقط اعمل ايه  غير حرج   \n",
       "1588        NaN  لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...  غير حرج   \n",
       "1589        NaN  عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...      حرج   \n",
       "1590        NaN  بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...  غير حرج   \n",
       "1591        NaN                              علاج للاكزيما العصبية      حرج   \n",
       "\n",
       "                  Diagnosis             Type  \\\n",
       "0                 مخ واعصاب        مخ واعصاب   \n",
       "1                قولون عصبي            باطنه   \n",
       "2             كدمه في الوجه  انف واذن وحنجره   \n",
       "3                       ضغط            باطنه   \n",
       "4     عدم التركيز و النسيان        مخ واعصاب   \n",
       "...                     ...              ...   \n",
       "1587            تساقط الشعر   جلديه وتناسليه   \n",
       "1588            هالات سوداء   جلديه وتناسليه   \n",
       "1589            تساقط الشعر   جلديه وتناسليه   \n",
       "1590           اكسده البشره   جلديه وتناسليه   \n",
       "1591         اكزيما العصبيه   جلديه وتناسليه   \n",
       "\n",
       "                                                    NER  \\\n",
       "0     ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n",
       "1                                        ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ   \n",
       "2                           \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ   \n",
       "3      \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n",
       "4     \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n",
       "...                                                 ...   \n",
       "1587                             شعرى وقع من الامام فقط   \n",
       "1588       كريم خافي للعيوب كونسيلر طبي للهالات السوداء   \n",
       "1589                                        ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ   \n",
       "1590                       ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة   \n",
       "1591                                    ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ   \n",
       "\n",
       "                                             Summarised  \\\n",
       "0     ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...   \n",
       "1                                            ﻗﻮﻟﻮﻥ عصبي   \n",
       "2     ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...   \n",
       "3     ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...   \n",
       "4                 ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة   \n",
       "...                                                 ...   \n",
       "1587                             شعرى وقع من الامام فقط   \n",
       "1588  هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...   \n",
       "1589                                        ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ   \n",
       "1590                       ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة   \n",
       "1591                                    ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ   \n",
       "\n",
       "                                                 Refine  \\\n",
       "0     \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n",
       "1     قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n",
       "2     \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n",
       "3     صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n",
       "4     \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n",
       "...                                                 ...   \n",
       "1587                                                NaN   \n",
       "1588                                                NaN   \n",
       "1589                       \\n\\n تساقط الشعر بدرجة كبيرة   \n",
       "1590                                                NaN   \n",
       "1591                                                NaN   \n",
       "\n",
       "                                                 Post.1  \\\n",
       "0     السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...   \n",
       "1             يخوان شو الحل مع القولون العصبي مشان الله   \n",
       "2     لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...   \n",
       "3     حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...   \n",
       "4     عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...   \n",
       "...                                                 ...   \n",
       "1587                    شعرى وقع من الامام فقط اعمل ايه   \n",
       "1588  لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...   \n",
       "1589  عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...   \n",
       "1590  بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...   \n",
       "1591                              علاج للاكزيما العصبية   \n",
       "\n",
       "                                                Refined  \\\n",
       "0     \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n",
       "1     قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n",
       "2     \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n",
       "3     صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n",
       "4     \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n",
       "...                                                 ...   \n",
       "1587                    شعرى وقع من الامام فقط اعمل ايه   \n",
       "1588   لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونس...   \n",
       "1589  \\n\\n تساقط الشعر بدرجة كبيرة عندي تساقط الشعر ...   \n",
       "1590   بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف ال...   \n",
       "1591                              علاج للاكزيما العصبية   \n",
       "\n",
       "                                               NER_POST  \\\n",
       "0     ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n",
       "1     ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...   \n",
       "2      \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...   \n",
       "3      \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n",
       "4     \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n",
       "...                                                 ...   \n",
       "1587  شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...   \n",
       "1588  كريم خافي للعيوب كونسيلر طبي للهالات السوداء ل...   \n",
       "1589  ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...   \n",
       "1590  ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...   \n",
       "1591              ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية   \n",
       "\n",
       "                                        Summarised_POST  \n",
       "0     ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...  \n",
       "1     ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...  \n",
       "2     ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...  \n",
       "3     ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...  \n",
       "4     ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...  \n",
       "...                                                 ...  \n",
       "1587  شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...  \n",
       "1588  هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...  \n",
       "1589  ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...  \n",
       "1590  ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...  \n",
       "1591              ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية  \n",
       "\n",
       "[1592 rows x 12 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"/kaggle/input/dataaaa/reshaped_output2 (6).xlsx\")\n",
    "# Slice the first 1951 rows\n",
    "df = df.iloc[:1592]\n",
    "\n",
    "# Display the DataFrame or its information\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:08.638839Z",
     "iopub.status.busy": "2024-12-28T19:16:08.638532Z",
     "iopub.status.idle": "2024-12-28T19:16:08.654752Z",
     "shell.execute_reply": "2024-12-28T19:16:08.653925Z",
     "shell.execute_reply.started": "2024-12-28T19:16:08.638817Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image type</th>\n",
       "      <th>Post</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Type</th>\n",
       "      <th>NER</th>\n",
       "      <th>Summarised</th>\n",
       "      <th>Refine</th>\n",
       "      <th>Post.1</th>\n",
       "      <th>Refined</th>\n",
       "      <th>NER_POST</th>\n",
       "      <th>Summarised_POST</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n",
       "      <td>حرج</td>\n",
       "      <td>مخ واعصاب</td>\n",
       "      <td>مخ واعصاب</td>\n",
       "      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n",
       "      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n",
       "      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n",
       "      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n",
       "      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n",
       "      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n",
       "      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n",
       "      <td>غير حرج</td>\n",
       "      <td>قولون عصبي</td>\n",
       "      <td>باطنه</td>\n",
       "      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ</td>\n",
       "      <td>ﻗﻮﻟﻮﻥ عصبي</td>\n",
       "      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n",
       "      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n",
       "      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n",
       "      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...</td>\n",
       "      <td>ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n",
       "      <td>حرج</td>\n",
       "      <td>كدمه في الوجه</td>\n",
       "      <td>انف واذن وحنجره</td>\n",
       "      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ</td>\n",
       "      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n",
       "      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n",
       "      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n",
       "      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n",
       "      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...</td>\n",
       "      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n",
       "      <td>غير حرج</td>\n",
       "      <td>ضغط</td>\n",
       "      <td>باطنه</td>\n",
       "      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n",
       "      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n",
       "      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n",
       "      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n",
       "      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n",
       "      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n",
       "      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n",
       "      <td>غير حرج</td>\n",
       "      <td>عدم التركيز و النسيان</td>\n",
       "      <td>مخ واعصاب</td>\n",
       "      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n",
       "      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة</td>\n",
       "      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n",
       "      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n",
       "      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n",
       "      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n",
       "      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image type                                               Post Severity  \\\n",
       "0    Unknown  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...      حرج   \n",
       "1    Unknown          يخوان شو الحل مع القولون العصبي مشان الله  غير حرج   \n",
       "2    Unknown  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...      حرج   \n",
       "3    Unknown  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...  غير حرج   \n",
       "4    Unknown  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...  غير حرج   \n",
       "\n",
       "               Diagnosis             Type  \\\n",
       "0              مخ واعصاب        مخ واعصاب   \n",
       "1             قولون عصبي            باطنه   \n",
       "2          كدمه في الوجه  انف واذن وحنجره   \n",
       "3                    ضغط            باطنه   \n",
       "4  عدم التركيز و النسيان        مخ واعصاب   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n",
       "1                                     ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ   \n",
       "2                        \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ   \n",
       "3   \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n",
       "4  \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n",
       "\n",
       "                                          Summarised  \\\n",
       "0  ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...   \n",
       "1                                         ﻗﻮﻟﻮﻥ عصبي   \n",
       "2  ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...   \n",
       "3  ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...   \n",
       "4              ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة   \n",
       "\n",
       "                                              Refine  \\\n",
       "0  \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n",
       "1  قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n",
       "2  \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n",
       "3  صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n",
       "4  \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n",
       "\n",
       "                                              Post.1  \\\n",
       "0  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...   \n",
       "1          يخوان شو الحل مع القولون العصبي مشان الله   \n",
       "2  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...   \n",
       "3  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...   \n",
       "4  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...   \n",
       "\n",
       "                                             Refined  \\\n",
       "0  \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n",
       "1  قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n",
       "2  \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n",
       "3  صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n",
       "4  \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n",
       "\n",
       "                                            NER_POST  \\\n",
       "0  ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n",
       "1  ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...   \n",
       "2   \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...   \n",
       "3   \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n",
       "4  \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n",
       "\n",
       "                                     Summarised_POST  target  \n",
       "0  ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...       5  \n",
       "1  ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...       1  \n",
       "2  ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...       0  \n",
       "3  ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...       1  \n",
       "4  ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...       5  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type']=df['Type'].astype('category')\n",
    "df['target']=df['Type'].cat.codes\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:13.688739Z",
     "iopub.status.busy": "2024-12-28T19:16:13.688444Z",
     "iopub.status.idle": "2024-12-28T19:16:13.694942Z",
     "shell.execute_reply": "2024-12-28T19:16:13.694264Z",
     "shell.execute_reply.started": "2024-12-28T19:16:13.688718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['انف واذن وحنجره', 'باطنه', 'باطنه اطفال', 'جلديه وتناسليه', 'عظام',\n",
       "       'مخ واعصاب', 'نساء وتوليد'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].cat.categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:15.241944Z",
     "iopub.status.busy": "2024-12-28T19:16:15.241651Z",
     "iopub.status.idle": "2024-12-28T19:16:15.248570Z",
     "shell.execute_reply": "2024-12-28T19:16:15.247796Z",
     "shell.execute_reply.started": "2024-12-28T19:16:15.241922Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'انف واذن وحنجره',\n",
       " 1: 'باطنه',\n",
       " 2: 'باطنه اطفال',\n",
       " 3: 'جلديه وتناسليه',\n",
       " 4: 'عظام',\n",
       " 5: 'مخ واعصاب',\n",
       " 6: 'نساء وتوليد'}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_map = {code: category for code, category in enumerate(df['Type'].cat.categories)}\n",
    "category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:18.368011Z",
     "iopub.status.busy": "2024-12-28T19:16:18.367711Z",
     "iopub.status.idle": "2024-12-28T19:16:18.375828Z",
     "shell.execute_reply": "2024-12-28T19:16:18.374915Z",
     "shell.execute_reply.started": "2024-12-28T19:16:18.367989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(955, 13) (318, 13) (319, 13)\n"
     ]
    }
   ],
   "source": [
    "train_end_point = int(df.shape[0] * 0.6)\n",
    "val_end_point = int(df.shape[0] * 0.8)\n",
    "df_train = df.iloc[:train_end_point, :]\n",
    "df_val = df.iloc[train_end_point:val_end_point, :]\n",
    "df_test = df.iloc[val_end_point:, :]\n",
    "print(df_train.shape, df_val.shape, df_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:22.525657Z",
     "iopub.status.busy": "2024-12-28T19:16:22.525295Z",
     "iopub.status.idle": "2024-12-28T19:16:22.556671Z",
     "shell.execute_reply": "2024-12-28T19:16:22.555783Z",
     "shell.execute_reply.started": "2024-12-28T19:16:22.525626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Drop 'type', 'severity', and 'age' columns along with 'label'\n",
    "dataset_train = Dataset.from_pandas(df_train.drop(['Type', 'Severity','Diagnosis', 'Image type','Summarised_POST','NER','Summarised','Refine','Post.1','Refined','Post'], axis=1))\n",
    "dataset_val = Dataset.from_pandas(df_val.drop(['Type', 'Severity','Diagnosis', 'Image type','Summarised_POST','NER','Summarised','Refine','Post.1','Refined','Post'], axis=1))\n",
    "dataset_test = Dataset.from_pandas(df_test.drop(['Type', 'Severity','Diagnosis', 'Image type','Summarised_POST','NER','Summarised','Refine','Post.1','Refined','Post'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:23.828058Z",
     "iopub.status.busy": "2024-12-28T19:16:23.827752Z",
     "iopub.status.idle": "2024-12-28T19:16:23.837467Z",
     "shell.execute_reply": "2024-12-28T19:16:23.836617Z",
     "shell.execute_reply.started": "2024-12-28T19:16:23.828035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_train_shuffled = dataset_train.shuffle(seed=42)  # Using a seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:25.130754Z",
     "iopub.status.busy": "2024-12-28T19:16:25.130418Z",
     "iopub.status.idle": "2024-12-28T19:16:25.137372Z",
     "shell.execute_reply": "2024-12-28T19:16:25.136601Z",
     "shell.execute_reply.started": "2024-12-28T19:16:25.130724Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['NER_POST', 'target'],\n",
       "        num_rows: 955\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['NER_POST', 'target'],\n",
       "        num_rows: 318\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['NER_POST', 'target'],\n",
       "        num_rows: 319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Combine them into a single DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset_train_shuffled,\n",
    "    'val': dataset_val,\n",
    "    'test': dataset_test\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:26.795440Z",
     "iopub.status.busy": "2024-12-28T19:16:26.795156Z",
     "iopub.status.idle": "2024-12-28T19:16:26.801796Z",
     "shell.execute_reply": "2024-12-28T19:16:26.800921Z",
     "shell.execute_reply.started": "2024-12-28T19:16:26.795419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['NER_POST', 'target'],\n",
       "    num_rows: 955\n",
       "})"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:34.494893Z",
     "iopub.status.busy": "2024-12-28T19:16:34.494598Z",
     "iopub.status.idle": "2024-12-28T19:16:34.502573Z",
     "shell.execute_reply": "2024-12-28T19:16:34.501576Z",
     "shell.execute_reply.started": "2024-12-28T19:16:34.494872Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['مخ واعصاب', 'باطنه', 'انف واذن وحنجره', 'باطنه اطفال', 'عظام', 'نساء وتوليد', 'جلديه وتناسليه']\n",
      "Categories (7, object): ['انف واذن وحنجره', 'باطنه', 'باطنه اطفال', 'جلديه وتناسليه', 'عظام', 'مخ واعصاب', 'نساء وتوليد']\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Type'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:36.404800Z",
     "iopub.status.busy": "2024-12-28T19:16:36.404516Z",
     "iopub.status.idle": "2024-12-28T19:16:36.412835Z",
     "shell.execute_reply": "2024-12-28T19:16:36.412013Z",
     "shell.execute_reply.started": "2024-12-28T19:16:36.404780Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    0.313089\n",
       "4    0.184293\n",
       "5    0.119372\n",
       "2    0.112042\n",
       "6    0.110995\n",
       "0    0.104712\n",
       "3    0.055497\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.target.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:38.167245Z",
     "iopub.status.busy": "2024-12-28T19:16:38.166895Z",
     "iopub.status.idle": "2024-12-28T19:16:38.177089Z",
     "shell.execute_reply": "2024-12-28T19:16:38.176182Z",
     "shell.execute_reply.started": "2024-12-28T19:16:38.167217Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: tensor([0.1528, 0.0511, 0.1428, 0.2883, 0.0868, 0.1340, 0.1441])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights = (1 / df_train.target.value_counts(normalize=True).sort_index()).tolist()\n",
    "class_weights = torch.tensor(class_weights)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:42.624983Z",
     "iopub.status.busy": "2024-12-28T19:16:42.624681Z",
     "iopub.status.idle": "2024-12-28T19:16:42.629674Z",
     "shell.execute_reply": "2024-12-28T19:16:42.628842Z",
     "shell.execute_reply.started": "2024-12-28T19:16:42.624962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:44.805948Z",
     "iopub.status.busy": "2024-12-28T19:16:44.805632Z",
     "iopub.status.idle": "2024-12-28T19:16:44.812706Z",
     "shell.execute_reply": "2024-12-28T19:16:44.811808Z",
     "shell.execute_reply.started": "2024-12-28T19:16:44.805921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:46.289510Z",
     "iopub.status.busy": "2024-12-28T19:16:46.289221Z",
     "iopub.status.idle": "2024-12-28T19:16:46.294477Z",
     "shell.execute_reply": "2024-12-28T19:16:46.293603Z",
     "shell.execute_reply.started": "2024-12-28T19:16:46.289489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=8,\n",
    "    target_modules=['query', 'key', 'value', 'dense'],  # Simplified layer names\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    task_type='SEQ_CLS'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:47.564031Z",
     "iopub.status.busy": "2024-12-28T19:16:47.563710Z",
     "iopub.status.idle": "2024-12-28T19:16:49.313987Z",
     "shell.execute_reply": "2024-12-28T19:16:49.313213Z",
     "shell.execute_reply.started": "2024-12-28T19:16:47.564006Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSelfAttention(\n",
       "                  (query): lora.Linear4bit(\n",
       "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): lora.Linear4bit(\n",
       "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): lora.Linear4bit(\n",
       "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): lora.Linear4bit(\n",
       "                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=768, out_features=3072, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=3072, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=7, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=7, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=len(category_map)\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:16:54.399472Z",
     "iopub.status.busy": "2024-12-28T19:16:54.399109Z",
     "iopub.status.idle": "2024-12-28T19:16:55.107585Z",
     "shell.execute_reply": "2024-12-28T19:16:55.106633Z",
     "shell.execute_reply.started": "2024-12-28T19:16:54.399446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the tokenizer with `add_prefix_space` if necessary for the specific model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "# Assign the `eos_token` to be used as the padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id  # Use eos_token_id for padding\n",
    "    tokenizer.pad_token = tokenizer.eos_token       # Assign eos_token as pad_token\n",
    "\n",
    "# Update the model configuration to use the tokenizer's pad_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False  # Prevent caching during training for better compatibility\n",
    "\n",
    "# Resize model embeddings if a new pad_token was added\n",
    "if len(tokenizer) != model.config.vocab_size:\n",
    "    model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:06.001106Z",
     "iopub.status.busy": "2024-12-28T19:17:06.000698Z",
     "iopub.status.idle": "2024-12-28T19:17:08.821469Z",
     "shell.execute_reply": "2024-12-28T19:17:08.820561Z",
     "shell.execute_reply.started": "2024-12-28T19:17:06.001073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16  # You can adjust this based on your system's memory capacity\n",
    "text = df_test['NER_POST'].tolist()\n",
    "\n",
    "# Initialize an empty list to store the model outputs\n",
    "all_outputs = []\n",
    "\n",
    "# Process the sentences in batches\n",
    "for i in range(0, len(text), batch_size):\n",
    "    # Get the batch of sentences\n",
    "    batch_sentences = text[i:i + batch_size]\n",
    "\n",
    "    # Tokenize the batch\n",
    "    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
    "    inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "\n",
    "    # Perform inference and store the logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        all_outputs.append(outputs['logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:13.171526Z",
     "iopub.status.busy": "2024-12-28T19:17:13.171208Z",
     "iopub.status.idle": "2024-12-28T19:17:13.180342Z",
     "shell.execute_reply": "2024-12-28T19:17:13.179561Z",
     "shell.execute_reply.started": "2024-12-28T19:17:13.171500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2134, -1.0259, -0.4441,  ...,  0.4153, -0.1066, -0.1885],\n",
       "        [-0.1106, -1.0332, -0.5639,  ...,  0.3385, -0.0999, -0.2599],\n",
       "        [-0.5924, -0.8798, -0.8321,  ...,  0.3400, -0.2594, -0.1109],\n",
       "        ...,\n",
       "        [-0.0741, -0.8561, -0.5222,  ...,  0.1802,  0.0973, -0.3928],\n",
       "        [-0.0773, -0.9907, -0.4954,  ...,  0.2408,  0.1860, -0.5099],\n",
       "        [-0.1412, -0.8952, -0.4411,  ...,  0.4149, -0.0496, -0.3232]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_outputs = torch.cat(all_outputs, dim=0)\n",
    "final_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:15.040402Z",
     "iopub.status.busy": "2024-12-28T19:17:15.040063Z",
     "iopub.status.idle": "2024-12-28T19:17:15.052066Z",
     "shell.execute_reply": "2024-12-28T19:17:15.051342Z",
     "shell.execute_reply.started": "2024-12-28T19:17:15.040376Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 6, 5, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4], device='cuda:0')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outputs.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:17.413956Z",
     "iopub.status.busy": "2024-12-28T19:17:17.413679Z",
     "iopub.status.idle": "2024-12-28T19:17:17.422955Z",
     "shell.execute_reply": "2024-12-28T19:17:17.422099Z",
     "shell.execute_reply.started": "2024-12-28T19:17:17.413936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-262-7c1d2547ae19>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1273    4\n",
       "1274    4\n",
       "1275    4\n",
       "1276    4\n",
       "1277    4\n",
       "       ..\n",
       "1587    4\n",
       "1588    4\n",
       "1589    4\n",
       "1590    4\n",
       "1591    4\n",
       "Name: predictions, Length: 319, dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n",
    "df_test['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:19.211865Z",
     "iopub.status.busy": "2024-12-28T19:17:19.211564Z",
     "iopub.status.idle": "2024-12-28T19:17:19.217332Z",
     "shell.execute_reply": "2024-12-28T19:17:19.216345Z",
     "shell.execute_reply.started": "2024-12-28T19:17:19.211842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_performance_metrics(df_test):\n",
    "  y_test = df_test.target\n",
    "  y_pred = df_test.predictions\n",
    "\n",
    "  print(\"Confusion Matrix:\")\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  print(\"\\nClassification Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "\n",
    "  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:23.574269Z",
     "iopub.status.busy": "2024-12-28T19:17:23.573942Z",
     "iopub.status.idle": "2024-12-28T19:17:23.596830Z",
     "shell.execute_reply": "2024-12-28T19:17:23.595724Z",
     "shell.execute_reply.started": "2024-12-28T19:17:23.574241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  0   0   0   0  21   0   0]\n",
      " [  0   0   0   0  39   1   0]\n",
      " [  0   0   0   0  60   0   0]\n",
      " [  0   0   0   0 140   5   2]\n",
      " [  0   0   0   0   5   0   0]\n",
      " [  0   0   0   0  11   0   0]\n",
      " [  0   0   0   0  33   1   1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.00      0.00      0.00        40\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.00      0.00      0.00       147\n",
      "           4       0.02      1.00      0.03         5\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.33      0.03      0.05        35\n",
      "\n",
      "    accuracy                           0.02       319\n",
      "   macro avg       0.05      0.15      0.01       319\n",
      "weighted avg       0.04      0.02      0.01       319\n",
      "\n",
      "Balanced Accuracy Score: 0.14693877551020407\n",
      "Accuracy Score: 0.018808777429467086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_performance_metrics(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:27.610649Z",
     "iopub.status.busy": "2024-12-28T19:17:27.610344Z",
     "iopub.status.idle": "2024-12-28T19:17:27.617838Z",
     "shell.execute_reply": "2024-12-28T19:17:27.617013Z",
     "shell.execute_reply.started": "2024-12-28T19:17:27.610622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions\n",
       "4    309\n",
       "5      7\n",
       "6      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predictions'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:29.029417Z",
     "iopub.status.busy": "2024-12-28T19:17:29.029086Z",
     "iopub.status.idle": "2024-12-28T19:17:29.033976Z",
     "shell.execute_reply": "2024-12-28T19:17:29.033245Z",
     "shell.execute_reply.started": "2024-12-28T19:17:29.029389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:33.859319Z",
     "iopub.status.busy": "2024-12-28T19:17:33.858967Z",
     "iopub.status.idle": "2024-12-28T19:17:34.141990Z",
     "shell.execute_reply": "2024-12-28T19:17:34.141093Z",
     "shell.execute_reply.started": "2024-12-28T19:17:33.859291Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbe14e20b48426daf602bad1a215b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5372611005034d64abac910ac57cdc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/318 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df756b4b85eb4986a25f9d114b192216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocessing_function(examples):\n",
    "    return tokenizer(examples['NER_POST'], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocessing_function, batched=True, remove_columns=['NER_POST'])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:53.707268Z",
     "iopub.status.busy": "2024-12-28T19:17:53.706957Z",
     "iopub.status.idle": "2024-12-28T19:17:53.711864Z",
     "shell.execute_reply": "2024-12-28T19:17:53.710963Z",
     "shell.execute_reply.started": "2024-12-28T19:17:53.707245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:17:58.246786Z",
     "iopub.status.busy": "2024-12-28T19:17:58.246493Z",
     "iopub.status.idle": "2024-12-28T19:17:58.251631Z",
     "shell.execute_reply": "2024-12-28T19:17:58.250614Z",
     "shell.execute_reply.started": "2024-12-28T19:17:58.246764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:18:00.328203Z",
     "iopub.status.busy": "2024-12-28T19:18:00.327871Z",
     "iopub.status.idle": "2024-12-28T19:18:00.336075Z",
     "shell.execute_reply": "2024-12-28T19:18:00.335179Z",
     "shell.execute_reply.started": "2024-12-28T19:18:00.328172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure class_weights is handled correctly\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        self.epoch_logs = []\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def log_metrics(self, metrics, epoch):\n",
    "        # Custom function to log and save metrics\n",
    "        print(f\"Epoch {epoch}: {metrics}\")  # Print metrics\n",
    "        self.epoch_logs.append(metrics)  # Store the results\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # Overriding to log after each epoch\n",
    "        metrics = self.evaluate()  # Evaluate after each epoch\n",
    "        self.log_metrics(metrics, epoch=len(self.epoch_logs))  # Log metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:18:01.979385Z",
     "iopub.status.busy": "2024-12-28T19:18:01.979031Z",
     "iopub.status.idle": "2024-12-28T19:18:01.987233Z",
     "shell.execute_reply": "2024-12-28T19:18:01.986522Z",
     "shell.execute_reply.started": "2024-12-28T19:18:01.979357Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"72d0e227429bd347553a5563b7396b82cb04a364\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:18:03.474746Z",
     "iopub.status.busy": "2024-12-28T19:18:03.474464Z",
     "iopub.status.idle": "2024-12-28T19:18:03.509737Z",
     "shell.execute_reply": "2024-12-28T19:18:03.509089Z",
     "shell.execute_reply.started": "2024-12-28T19:18:03.474725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='sentiment_classification',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    num_train_epochs=25,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:18:04.924094Z",
     "iopub.status.busy": "2024-12-28T19:18:04.923801Z",
     "iopub.status.idle": "2024-12-28T19:18:04.940654Z",
     "shell.execute_reply": "2024-12-28T19:18:04.939722Z",
     "shell.execute_reply.started": "2024-12-28T19:18:04.924073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-270-f7f84dfa52ac>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=lambda eval_pred: {\n",
    "        'balanced_accuracy': balanced_accuracy_score(eval_pred[1], np.argmax(eval_pred[0], axis=1)),\n",
    "        'accuracy': accuracy_score(eval_pred[1], np.argmax(eval_pred[0], axis=1))\n",
    "    },\n",
    "    class_weights=class_weights  # Pass the weights tensor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:18:06.943212Z",
     "iopub.status.busy": "2024-12-28T19:18:06.942880Z",
     "iopub.status.idle": "2024-12-28T19:42:49.457042Z",
     "shell.execute_reply": "2024-12-28T19:42:49.456215Z",
     "shell.execute_reply.started": "2024-12-28T19:18:06.943182Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 24:41, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.957700</td>\n",
       "      <td>1.918876</td>\n",
       "      <td>0.169913</td>\n",
       "      <td>0.185535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.853800</td>\n",
       "      <td>1.844089</td>\n",
       "      <td>0.244080</td>\n",
       "      <td>0.339623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.698100</td>\n",
       "      <td>1.577384</td>\n",
       "      <td>0.360477</td>\n",
       "      <td>0.474843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.329000</td>\n",
       "      <td>1.255725</td>\n",
       "      <td>0.512799</td>\n",
       "      <td>0.562893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.437700</td>\n",
       "      <td>1.115001</td>\n",
       "      <td>0.542314</td>\n",
       "      <td>0.622642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.094800</td>\n",
       "      <td>1.063396</td>\n",
       "      <td>0.674815</td>\n",
       "      <td>0.672956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.141400</td>\n",
       "      <td>1.046380</td>\n",
       "      <td>0.660592</td>\n",
       "      <td>0.647799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.944700</td>\n",
       "      <td>0.928582</td>\n",
       "      <td>0.626341</td>\n",
       "      <td>0.638365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.750600</td>\n",
       "      <td>0.936650</td>\n",
       "      <td>0.589062</td>\n",
       "      <td>0.657233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.874586</td>\n",
       "      <td>0.636957</td>\n",
       "      <td>0.723270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.553200</td>\n",
       "      <td>0.894796</td>\n",
       "      <td>0.715486</td>\n",
       "      <td>0.713836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.564100</td>\n",
       "      <td>0.888204</td>\n",
       "      <td>0.634148</td>\n",
       "      <td>0.710692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>0.903553</td>\n",
       "      <td>0.643750</td>\n",
       "      <td>0.723270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.926572</td>\n",
       "      <td>0.703976</td>\n",
       "      <td>0.723270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.922491</td>\n",
       "      <td>0.634242</td>\n",
       "      <td>0.726415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.337200</td>\n",
       "      <td>0.975040</td>\n",
       "      <td>0.661770</td>\n",
       "      <td>0.716981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.996661</td>\n",
       "      <td>0.645126</td>\n",
       "      <td>0.720126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.366100</td>\n",
       "      <td>1.002901</td>\n",
       "      <td>0.656131</td>\n",
       "      <td>0.732704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>1.029940</td>\n",
       "      <td>0.653983</td>\n",
       "      <td>0.723270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.981937</td>\n",
       "      <td>0.651382</td>\n",
       "      <td>0.742138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.393000</td>\n",
       "      <td>1.013674</td>\n",
       "      <td>0.660786</td>\n",
       "      <td>0.738994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.290800</td>\n",
       "      <td>1.024097</td>\n",
       "      <td>0.663481</td>\n",
       "      <td>0.742138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>1.036888</td>\n",
       "      <td>0.654317</td>\n",
       "      <td>0.732704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>1.060944</td>\n",
       "      <td>0.652956</td>\n",
       "      <td>0.729560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>1.046737</td>\n",
       "      <td>0.654317</td>\n",
       "      <td>0.732704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:05:57.852060Z",
     "iopub.status.busy": "2024-12-15T14:05:57.851698Z",
     "iopub.status.idle": "2024-12-15T14:05:57.860769Z",
     "shell.execute_reply": "2024-12-15T14:05:57.859862Z",
     "shell.execute_reply.started": "2024-12-15T14:05:57.852031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    0.313089\n",
       "4    0.184293\n",
       "5    0.119372\n",
       "2    0.112042\n",
       "6    0.110995\n",
       "0    0.104712\n",
       "3    0.055497\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:05:59.586322Z",
     "iopub.status.busy": "2024-12-15T14:05:59.585995Z",
     "iopub.status.idle": "2024-12-15T14:05:59.594499Z",
     "shell.execute_reply": "2024-12-15T14:05:59.593715Z",
     "shell.execute_reply.started": "2024-12-15T14:05:59.586293Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "3    0.460815\n",
       "2    0.188088\n",
       "1    0.125392\n",
       "6    0.109718\n",
       "0    0.065831\n",
       "5    0.034483\n",
       "4    0.015674\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:43:33.943856Z",
     "iopub.status.busy": "2024-12-28T19:43:33.943543Z",
     "iopub.status.idle": "2024-12-28T19:43:36.684593Z",
     "shell.execute_reply": "2024-12-28T19:43:36.683685Z",
     "shell.execute_reply.started": "2024-12-28T19:43:33.943835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, df_test):\n",
    "\n",
    "    # Convert summaries to a list\n",
    "    sentences = df_test['NER_POST'].tolist()\n",
    "\n",
    "    # Define the batch size\n",
    "    batch_size = 16  # You can adjust this based on your system's memory capacity\n",
    "\n",
    "    # Initialize an empty list to store the model outputs\n",
    "    all_outputs = []\n",
    "\n",
    "    # Process the sentences in batches\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        # Get the batch of sentences\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "\n",
    "        # Tokenize the batch\n",
    "        inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "        # Move tensors to the device where the model is (e.g., GPU or CPU)\n",
    "        inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n",
    "\n",
    "        # Perform inference and store the logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            all_outputs.append(outputs['logits'])\n",
    "\n",
    "    final_outputs = torch.cat(all_outputs, dim=0)\n",
    "\n",
    "    # Update using .loc to avoid SettingWithCopyWarning\n",
    "    df_test.loc[:, 'predictions'] = final_outputs.argmax(axis=1).cpu().numpy()\n",
    "\n",
    "    # Apply category mapping\n",
    "    df_test.loc[:, 'predictions'] = df_test['predictions'].apply(lambda l: category_map[l])\n",
    "\n",
    "# Make predictions\n",
    "make_predictions(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:43:45.388860Z",
     "iopub.status.busy": "2024-12-28T19:43:45.388578Z",
     "iopub.status.idle": "2024-12-28T19:43:45.412452Z",
     "shell.execute_reply": "2024-12-28T19:43:45.411601Z",
     "shell.execute_reply.started": "2024-12-28T19:43:45.388839Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 11   3   2   0   3   2   0]\n",
      " [  5  26   2   1   1   2   3]\n",
      " [  1   2  49   4   2   2   0]\n",
      " [  4   6  18 111   5   1   2]\n",
      " [  1   0   0   1   2   0   1]\n",
      " [  0   0   0   1   1   5   4]\n",
      " [  2   2   2   2   0   1  26]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.52      0.49        21\n",
      "           1       0.67      0.65      0.66        40\n",
      "           2       0.67      0.82      0.74        60\n",
      "           3       0.93      0.76      0.83       147\n",
      "           4       0.14      0.40      0.21         5\n",
      "           5       0.38      0.45      0.42        11\n",
      "           6       0.72      0.74      0.73        35\n",
      "\n",
      "    accuracy                           0.72       319\n",
      "   macro avg       0.57      0.62      0.58       319\n",
      "weighted avg       0.76      0.72      0.73       319\n",
      "\n",
      "Balanced Accuracy Score: 0.6204258326707306\n",
      "Accuracy Score: 0.7210031347962382\n"
     ]
    }
   ],
   "source": [
    "def get_performance_metrics(df_test):\n",
    "    # Convert both target and predictions back to numeric using category_map\n",
    "    reverse_category_map = {v: k for k, v in category_map.items()}  # Reverse the category_map to map strings to numbers\n",
    "    y_test = df_test['target']\n",
    "    y_pred = df_test['predictions'].apply(lambda x: reverse_category_map[x])\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Run the function again\n",
    "get_performance_metrics(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T16:55:47.106064Z",
     "iopub.status.busy": "2024-12-28T16:55:47.105737Z",
     "iopub.status.idle": "2024-12-28T16:55:47.611807Z",
     "shell.execute_reply": "2024-12-28T16:55:47.611043Z",
     "shell.execute_reply.started": "2024-12-28T16:55:47.106037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully to '/kaggle/outputs/arabert-post'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save the model (inside /kaggle/outputs for persistence)\n",
    "save_directory = \"/kaggle/outputs/arabert-post\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T16:56:50.405944Z",
     "iopub.status.busy": "2024-12-28T16:56:50.405650Z",
     "iopub.status.idle": "2024-12-28T16:56:50.894824Z",
     "shell.execute_reply": "2024-12-28T16:56:50.893896Z",
     "shell.execute_reply.started": "2024-12-28T16:56:50.405922Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully to '/kaggle/working/arabert-post'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save the model (inside /kaggle/outputs for persistence)\n",
    "save_directory = \"/kaggle/working/arabert-post\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T16:58:27.352931Z",
     "iopub.status.busy": "2024-12-28T16:58:27.352629Z",
     "iopub.status.idle": "2024-12-28T16:58:27.846171Z",
     "shell.execute_reply": "2024-12-28T16:58:27.845346Z",
     "shell.execute_reply.started": "2024-12-28T16:58:27.352906Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully to 'arabert-post'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save the model (inside /kaggle/outputs for persistence)\n",
    "save_directory = \"arabert-post\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:10:43.942501Z",
     "iopub.status.busy": "2024-12-28T17:10:43.942200Z",
     "iopub.status.idle": "2024-12-28T17:10:44.953771Z",
     "shell.execute_reply": "2024-12-28T17:10:44.952771Z",
     "shell.execute_reply.started": "2024-12-28T17:10:43.942477Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/arabert-post/ (stored 0%)\n",
      "  adding: kaggle/working/arabert-post/tokenizer.json"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (deflated 73%)\n",
      "  adding: kaggle/working/arabert-post/vocab.txt (deflated 62%)\n",
      "  adding: kaggle/working/arabert-post/special_tokens_map.json (deflated 80%)\n",
      "  adding: kaggle/working/arabert-post/README.md (deflated 66%)\n",
      "  adding: kaggle/working/arabert-post/tokenizer_config.json (deflated 90%)\n",
      "  adding: kaggle/working/arabert-post/adapter_model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/arabert-post/adapter_config.json (deflated 52%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r arabert_post_model.zip /kaggle/working/arabert-post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T17:11:31.015117Z",
     "iopub.status.busy": "2024-12-28T17:11:31.014778Z",
     "iopub.status.idle": "2024-12-28T17:11:31.022218Z",
     "shell.execute_reply": "2024-12-28T17:11:31.021470Z",
     "shell.execute_reply.started": "2024-12-28T17:11:31.015090Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='arabert_post_model.zip' target='_blank'>arabert_post_model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/arabert_post_model.zip"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'arabert_post_model.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T18:33:22.256736Z",
     "iopub.status.busy": "2024-12-28T18:33:22.256431Z",
     "iopub.status.idle": "2024-12-28T18:33:22.738429Z",
     "shell.execute_reply": "2024-12-28T18:33:22.737586Z",
     "shell.execute_reply.started": "2024-12-28T18:33:22.256715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully to '/kaggle/working/arabert-summarized'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save the model (inside /kaggle/outputs for persistence)\n",
    "save_directory = \"/kaggle/working/arabert-summarized\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T18:33:25.379123Z",
     "iopub.status.busy": "2024-12-28T18:33:25.378825Z",
     "iopub.status.idle": "2024-12-28T18:33:26.409440Z",
     "shell.execute_reply": "2024-12-28T18:33:26.408429Z",
     "shell.execute_reply.started": "2024-12-28T18:33:25.379100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/arabert-summarized/ (stored 0%)\n",
      "  adding: kaggle/working/arabert-summarized/tokenizer.json"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (deflated 73%)\n",
      "  adding: kaggle/working/arabert-summarized/vocab.txt (deflated 62%)\n",
      "  adding: kaggle/working/arabert-summarized/special_tokens_map.json (deflated 80%)\n",
      "  adding: kaggle/working/arabert-summarized/README.md (deflated 66%)\n",
      "  adding: kaggle/working/arabert-summarized/tokenizer_config.json (deflated 90%)\n",
      "  adding: kaggle/working/arabert-summarized/adapter_model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/arabert-summarized/adapter_config.json (deflated 52%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r arabert_summarized_model.zip /kaggle/working/arabert-summarized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T18:33:29.214299Z",
     "iopub.status.busy": "2024-12-28T18:33:29.213939Z",
     "iopub.status.idle": "2024-12-28T18:33:29.221161Z",
     "shell.execute_reply": "2024-12-28T18:33:29.220360Z",
     "shell.execute_reply.started": "2024-12-28T18:33:29.214271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='arabert_summarized_model.zip' target='_blank'>arabert_summarized_model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/arabert_summarized_model.zip"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'arabert_summarized_model.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:10:46.384322Z",
     "iopub.status.busy": "2024-12-28T19:10:46.383970Z",
     "iopub.status.idle": "2024-12-28T19:10:46.878540Z",
     "shell.execute_reply": "2024-12-28T19:10:46.877461Z",
     "shell.execute_reply.started": "2024-12-28T19:10:46.384296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully to '/kaggle/working/arabert-refined'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save the model (inside /kaggle/outputs for persistence)\n",
    "save_directory = \"/kaggle/working/arabert-refined\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:11:35.803787Z",
     "iopub.status.busy": "2024-12-28T19:11:35.803312Z",
     "iopub.status.idle": "2024-12-28T19:11:36.887294Z",
     "shell.execute_reply": "2024-12-28T19:11:36.886361Z",
     "shell.execute_reply.started": "2024-12-28T19:11:35.803750Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/arabert-refined/ (stored 0%)\n",
      "  adding: kaggle/working/arabert-refined/tokenizer.json (deflated 73%)\n",
      "  adding: kaggle/working/arabert-refined/vocab.txt (deflated 62%)\n",
      "  adding: kaggle/working/arabert-refined/special_tokens_map.json (deflated 80%)\n",
      "  adding: kaggle/working/arabert-refined/README.md (deflated 66%)\n",
      "  adding: kaggle/working/arabert-refined/tokenizer_config.json (deflated 90%)\n",
      "  adding: kaggle/working/arabert-refined/adapter_model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/arabert-refined/adapter_config.json (deflated 52%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r arabert_refined_model.zip /kaggle/working/arabert-refined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:11:38.609996Z",
     "iopub.status.busy": "2024-12-28T19:11:38.609681Z",
     "iopub.status.idle": "2024-12-28T19:11:38.616930Z",
     "shell.execute_reply": "2024-12-28T19:11:38.616225Z",
     "shell.execute_reply.started": "2024-12-28T19:11:38.609973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='arabert_refined_model.zip' target='_blank'>arabert_refined_model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/arabert_refined_model.zip"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'arabert_refined_model.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:44:16.401114Z",
     "iopub.status.busy": "2024-12-28T19:44:16.400835Z",
     "iopub.status.idle": "2024-12-28T19:44:16.909541Z",
     "shell.execute_reply": "2024-12-28T19:44:16.908648Z",
     "shell.execute_reply.started": "2024-12-28T19:44:16.401095Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully to '/kaggle/working/arabert-ner'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to save the model (inside /kaggle/outputs for persistence)\n",
    "save_directory = \"/kaggle/working/arabert-ner\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:44:32.116263Z",
     "iopub.status.busy": "2024-12-28T19:44:32.115924Z",
     "iopub.status.idle": "2024-12-28T19:44:33.143981Z",
     "shell.execute_reply": "2024-12-28T19:44:33.143223Z",
     "shell.execute_reply.started": "2024-12-28T19:44:32.116234Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/arabert-ner/ (stored 0%)\n",
      "  adding: kaggle/working/arabert-ner/tokenizer.json"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (deflated 73%)\n",
      "  adding: kaggle/working/arabert-ner/vocab.txt (deflated 62%)\n",
      "  adding: kaggle/working/arabert-ner/special_tokens_map.json (deflated 80%)\n",
      "  adding: kaggle/working/arabert-ner/README.md (deflated 66%)\n",
      "  adding: kaggle/working/arabert-ner/tokenizer_config.json (deflated 90%)\n",
      "  adding: kaggle/working/arabert-ner/adapter_model.safetensors (deflated 7%)\n",
      "  adding: kaggle/working/arabert-ner/adapter_config.json (deflated 52%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r arabert_ner_model.zip /kaggle/working/arabert-ner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T19:44:42.958109Z",
     "iopub.status.busy": "2024-12-28T19:44:42.957796Z",
     "iopub.status.idle": "2024-12-28T19:44:42.965163Z",
     "shell.execute_reply": "2024-12-28T19:44:42.964287Z",
     "shell.execute_reply.started": "2024-12-28T19:44:42.958086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='arabert_ner_model.zip' target='_blank'>arabert_ner_model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/arabert_ner_model.zip"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'arabert_ner_model.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6186713,
     "sourceId": 10042820,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6308159,
     "sourceId": 10207250,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6389894,
     "sourceId": 10320693,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
