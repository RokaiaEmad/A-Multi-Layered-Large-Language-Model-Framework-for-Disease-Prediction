{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "editable": false,
    "execution": {
     "execution_failed": "2025-06-19T00:14:24.047Z",
     "iopub.execute_input": "2025-06-18T16:05:19.408946Z",
     "iopub.status.busy": "2025-06-18T16:05:19.408692Z",
     "iopub.status.idle": "2025-06-18T23:39:02.952389Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 16:05:26.674478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750262726.697158     118 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750262726.703921     118 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Test Dataset Severity Distribution (Shuffled):\n",
      "severity\n",
      "Ø­Ø±Ø¬        30717\n",
      "ØºÙŠØ± Ø­Ø±Ø¬     9072\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… Loaded shuffled test dataset with 39789 samples.\n",
      "\n",
      "ğŸ”¹ Running ensemble and individual model predictions on test dataset (39789 samples)...\n",
      "\n",
      "================================================================================\n",
      "Processing sample 500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø±ÙŠØ¯ Ø§Ù„ØªØ§ÙƒØ¯ Ù…Ù† Ø¹Ø°Ø±ÙŠÙ‡ Ø²ÙˆØ¬ØªÙŠ ÙˆØ§Ù„ØªØ§ÙƒØ¯ Ù…Ù† Ø§Ù† Ù„Ù… ÙŠØ³Ø¨Ù‚ Ù…Ù…Ø§Ø±Ø³Ù‡ Ø§Ù„Ø¬Ù†Ø³ Ø§Ø±ÙŠØ¯ Ø¬ÙˆØ§Ø¨ Ù…ÙØµÙ„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 1000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ ÙØªØ§Ù‡ Ø¹Ù…Ø±ÙŠ 17 Ø³Ù†Ù‡ Ù…Ø° Ø§Ù† ÙƒØ§Ù† Ø¹Ù…Ø±ÙŠ 12 Ø³Ù†Ù‡ ÙˆØ§Ù†Ø§ Ø§Ø³ØªØ¹Ù…Ù„ Ø§Ù‚Ø±Ø§Øµ Ø¨ÙˆÙ†Ø³ØªÙŠÙ„ Ù„Ø§Ù† Ø§Ù„Ø§Ù„Ù… Ø´Ø¯ÙŠØ¯ ÙˆØ³Ù…Ø¹Øª Ø§Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø§Ù‚Ø±Ø§Øµ ØªØªØ³Ø¨Ø¨ ÙÙŠ Ø§Ù„Ø¹Ù‚Ù… Ù‡Ù„ Ù‡Ø°Ø§ ØµØ­ÙŠØ­\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 1500/39789\n",
      "================================================================================\n",
      "Input text: Ù…Ø§Ù‡ÙŠ Ø¹ Ø¬ ØªØ¬Ù…Ø¹ Ø§Ù„Ø§Ø·Ø¹Ù…Ù‡ ÙÙŠ Ø§Ù„Ù„ÙˆØ²ØªÙŠÙ† Ù…Ù…Ø§ ÙŠØ³Ø¨Ø¨ Ø±Ø§Ø¦Ø­Ù‡ ÙƒØ±ÙŠÙ‡Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 2000/39789\n",
      "================================================================================\n",
      "Input text: ØªÙ†Ø§ÙˆÙ„Øª Ø¯ÙˆØ§ Ù„ÙŠØªØ±ÙˆÙ…Ø§Ø± Ù…Ù†Ø´Ø· Ù„Ù„Ø§Ø¨Ø§Ø¯Ù‡ ÙˆØªØ§Ø®Ø±Øª Ø¯ÙˆØ±ØªÙŠ Ù…Ø§ Ø§Ù„Ø³Ø¨Ø¨ Ù‡Ù„ ÙŠØ³Ø¨Ø¨ Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙˆØ§Ø¡ ØªØ§Ø®ÙŠØ± Ø§Ù„Ø¯ÙˆØ±Ù‡ Ø§Ù„Ø´Ù‡Ø±ÙŠÙ‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 2500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ø§Ø¹Ù†ÙŠ Ù…Ù† Ø§Ù„Ø¨Ø±ÙˆØªÙŠÙ†Ø§Øª ÙÙŠ Ø§Ù„Ø­Ù„Ù‚ ÙˆÙ‡Ø°Ø§ Ù†Ø§ØªØ¬ Ø¹Ù† Ù…Ø±Ø¶ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠÙ‡ Ø§Ù„Ø°ÙŠ Ø§Ø¹Ù†ÙŠ Ù…Ù†Ù‡ Ù…Ù†Ø¯ ÙØªØ±Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 3000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ ÙˆÙ„Ø¯Øª ÙŠÙˆÙ… 20 8 ÙˆÙ†Ø¸ÙØª ÙŠÙˆÙ… 22 9 Ø¬Ù…Ø¹Øª Ø¨Ø¹Ø¯ ÙŠÙˆÙ…ÙŠÙ† Ù‡Ù„ ÙŠØ­Ø¯Ø« Ø­Ù…Ù„ Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø±Ø¨Ø¹ÙŠÙ† Ø§Ùˆ Ù„Ø§ Ù…Ù† ØºÙŠØ± Ø¯ÙˆØ±Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 3500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… Ø§Ø®Ø± Ø¯ÙˆØ±Ù‡ ÙƒØ§Ù†Øª 258 ÙˆÙ…ÙˆØ¹Ø¯ Ø§Ù„ÙˆÙ„Ø§Ø¯Ù‡ 16 Ù…Ø§ Ù‡ÙˆØ§ Ø§Ø®Ø± ØªØ§Ø±ÙŠØ® Ù„Ù„ÙˆÙ„Ø§Ø¯Ù‡ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠÙ‡ ÙˆØ§Ø°Ø§ ØªØ¹Ø¯ÙŠ Ø§Ø®Ø± Ù…ÙˆØ¹Ø¯ Ù‡Ù„ Ø§Ù„Ø§ÙØ¶Ù„ Ø§Ø¹Ø·Ø§Ø¡ ØªØ­Ø±ÙŠØ¶ Ø§Ùˆ ÙˆÙ„Ø§Ø¯Ù‡ Ù‚ÙŠØµØ±ÙŠÙ‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 4000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ø§Ù†Ø¬Ø¨Øª Ø¹Ù†Ø¯ÙŠ Ø´Ù‡Ø±ÙŠÙ† ÙˆÙ„Ù„Ø­ÙŠÙ† Ù…Ø§ Ø¬Ø§ØªÙ†ÙŠ Ø§Ù„Ø¯ÙˆØ±Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 4500/39789\n",
      "================================================================================\n",
      "Input text: Ø§ØªØ¨Ø¹ Ù…Ù†Ø¹ Ø§Ù„Ø­Ù…Ù„ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ ÙˆÙ„ÙƒÙ† Ø§Ø®Ø§Ù Ù…Ù† Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†ÙˆÙŠÙ‡ Ø¹Ù„ÙŠ Ø¬Ø³Ù…ÙŠ Ù Ù‡Ù„ Ø§Ù„Ù…Ø§Ø¡ Ø§Ùˆ Ø§Ù„ÙƒØ­ÙˆÙ„ ÙŠÙ‚Ø¶ÙŠ Ø¹Ù„ÙŠÙ‡Ø§ ÙÙˆØ±Ø§\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 5000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ù…Ø§Ù‡ÙˆØ§Ù„Ø³Ø¨Ø¨ ÙÙŠ Ù†Ø²ÙˆÙ„ Ø¯Ù… Ù…Ù† Ø§Ù„Ø§Ù†Ù \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 5500/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø­ÙƒÙ‡ Ø¯Ø§Ø®Ù„ÙŠÙ‡ ÙÙŠ Ø§Ù„Ø§Ø°Ù† Ø®ÙÙŠÙÙ‡ ÙˆØ£Ø­ÙŠØ§Ù†Ø§ Ø´Ø¯ÙŠØ¯Ù‡,Ù…Ø¹ ØªÙˆØ±Ù… ØºÙŠØ± Ù…Ù„Ø­ÙˆØ¸ ÙÙŠ Ø§Ø¹Ù„Ù‰ Ø§Ù„Ø±Ù‚Ø¨Ù‡ Ø¨Ø¯ÙˆÙ† Ø£Ù„Ù… Ù„ÙƒÙ† Ù…Ø¹ ÙˆØ®Ø² .Ù‡Ù„ Ù„Ù‡Ù…Ø§ Ø¹Ù„Ø§Ù‚Ù‡ØŸ \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 6000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø§Ù„Ù… Ø§Ù„Ø¶Ù‡Ø± ÙˆØ§Ù„Ø§Ù„ØªÙ‡Ø§Ø¨ Ø®ÙÙŠÙ ÙÙŠ Ø§Ù„Ù…Ù‡Ø¨Ù„Ù„ ÙƒÙŠÙ ÙŠØªÙ… Ø¹Ù„Ø§Ø¬Ù‡Ø§\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 6500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø®ÙŠ Ø§Ù„Ø§ØµØºØ± Ù„Ø¯ÙŠÙ‡ Ø¶ÙŠÙ‚ ÙÙŠ Ø§Ù„Ø§ÙˆØ±Ø·ÙŠ ÙˆÙ‡Ùˆ Ø¹ÙŠØ¨ Ø®Ù„Ù‚ÙŠ Ø¨Ø­Ø³Ø¨ Ù…Ø§ Ø§ÙƒØªØ´Ù Ø§Ù„Ø§Ø·Ø¨Ø§Ø¡Ø¡ Ù‡Ø°Ù‡ Ø§Ù„Ø§ÙŠØ§Ù… Ø§Ø±Ø¬Ùˆ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙˆÙ…Ø§ Ø§Ù„Ø¹Ù…Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 7000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø¹Ù†Ø¯ÙŠ ØªØ¶Ø®Ù… ÙƒØ¨Ø¯ Ø¯Ù‡Ù†ÙŠ Ø³Ø§Ø·Ø¹ ÙÙ‡Ù„ Ù‡Ùˆ Ù…Ø±ÙŠØ¶ Ø®Ø·ÙŠØ± ÙˆÙ…Ø§ Ø¹Ù„Ø§Ø¬Ù‡ ÙˆØ§Ø´Ø¹Ø± ÙˆØ§Ù† ÙÙŠ ØªØ´Ù†Ø¬Ø§Øª ÙÙŠ Ø¨Ø·Ù†ÙŠ \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 7500/39789\n",
      "================================================================================\n",
      "Input text: Ø¨Ø§Ù‚ÙŠ Ø§Ø³Ø¨ÙˆØ¹ ØªÙ‚Ø±ÙŠØ¨Ø§ Ù„Ù…ÙŠØ¹Ø§Ø¯ Ø§Ù„Ø¯ÙˆØ±Ù‡ Ø§Ù„Ø´Ù‡Ø±ÙŠÙ‡ Ø§Ù„Ù‚Ø§Ø¯Ù…Ù‡ Ø§Ø´Ùƒ Ø¨Ø­Ø¯ÙˆØ« Ø­Ù…Ù„ ÙˆØ§Ø³ØªØ®Ø¯Ù…Øª Ù…Ø¨ÙŠØ¯Ø§Øª Ø­Ø´Ø±ÙŠÙ‡ Ø®Ù„Ø§Ù„ Ù‡Ø°ÙŠÙ† Ø§Ù„ÙŠÙˆÙ…ÙŠÙ† Ù…Ù…Ø§ Ø§Ø¯ÙŠ Ø§Ù„ÙŠ Ø§Ø³ØªÙ†Ø´Ø§Ù‚ÙŠ Ù„Ù‡Ø§ Ù‡Ù„ Ù‡Ø°Ø§ ÙŠØ¤Ø«Ø± Ø¹Ù„ÙŠ Ø§Ù„Ø¬Ù†ÙŠÙ† ÙÙŠ Ø­Ø§Ù„ Ø­Ø¯ÙˆØ« Ø§Ù„Ø­Ù…Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 8000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ù…Ø±Ø­Ø¨Ø§ Ø§Ø¨ÙŠ ÙØ¬Ø£Ø© Ø§ØµØ¨Ø­ Ø¨ÙŠØ§Ø¶ Ø¹ÙŠÙ†Ù‡ Ø§ØµÙØ± Ùˆ ÙƒÙ„ Ø¬Ø³Ù…Ù‡ Ø§ØµÙØ± ÙˆÙƒØ§Ù† ÙŠØ´Ø¹Ø± Ø¨Ø§Ù„Ø­ÙƒØ© Ùˆ Ø§Ù„Ø§Ù† Ù‡Ùˆ ÙŠÙ‚ÙˆÙ… Ø¨Ø§Ù„ØªØ­Ø§Ù„ÙŠÙ„ Ù„ÙƒÙ†Ù‡Ù… Ù„Ù… ÙŠØ¹Ø±ÙÙˆÙ† Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ø±Ø¶ . Ø§Ø±ÙŠØ¯ Ø§Ù† Ø§Ø¹Ø±Ù Ù…Ø§... \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 8500/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø¯Ù…ÙˆØ¹ Ø¨Ø§Ù„Ø¹ÙŠÙ† Ø§Ù„Ø´Ù…Ø§Ù„ Ù…Ù†Ø° Ø´Ù‡Ø±ÙŠÙ† Ø§Ø®Ø°Øª Ù‚Ø·Ø±Ø© Ù…Ø±Ø·Ø¨Ø© Ùˆ Ù„Ø­Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ø¹ÙŠÙ† Ø§ØªØ­Ø³Ù†Øª ÙƒÙ„ Ù…Ø§ Ø§Ø¨Ø·Ù„ Ø§Ù„Ù‚Ø·Ø±Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨ÙŠØ±Ø¬Ø¹ ØªØ§Ù†Ù‰ Ø¹Ù„Ù‰ Ø§Ø¨Ø³Ø· \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 9000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù…ÙŠ ØªØ´ØªÙƒÙŠ Ù…Ù† Ø§Ù„Ø§Ù… ÙÙŠ Ø±ÙƒØ¨ØªÙŠÙ‡Ø§ Ø§Ø±ÙŠØ¯ Ù‡Ø§ Ø¹Ù„Ø§Ø¬ Ø³Ø±ÙŠØ¹ Ø¨Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙƒÙ…\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: False\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 9500/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø¹Ù…Ù„ÙŠØ© Ø§Ø²Ù„Ø§Ù„Ø© Ù…ÙŠÙ‡ Ù…Ù† Ø§Ù„Ø¹ÙŠÙ†. Ù…Ø§ Ù‡ÙŠ Ø§Ø¶Ø±Ø§Ø±Ù‡Ø§ØŸ \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 10000/39789\n",
      "================================================================================\n",
      "Input text: Ø¹Ù…Ø±ÙŠ 25 Ø¹Ø§Ù…Ø§ ÙˆØ§Ø¹Ø§Ù†ÙŠ Ù…Ù† Ù†Ø²ÙŠÙ Ù…Ù‡Ø¨Ù„ÙŠ Ø¨Ø³ÙŠØ· Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ù…Ø§Ø¹ ÙÙ…Ø§ Ø§Ù„Ø³Ø¨Ø¨ Ø§Ùˆ Ø§Ù„Ø­Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 10500/39789\n",
      "================================================================================\n",
      "Input text: Ø¨Ù…Ø§Ø°Ø§ ØªÙ†ØµØ­ÙˆÙ† Ù…Ù† ÙŠØ¹Ø§Ù†ÙŠ Ù…Ù† Ø§Ù„Ø§Ù… ÙÙŠ Ø§Ù„Ø±Ø§Ø³ ÙˆØ§Ø±Ù‚Ø¨Ù‡ Ø¨Ø³Ø¨Ø¨ ÙˆØ¨Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 11000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… Ø§Ø®ØªÙŠ Ù…ØªØ²ÙˆØ¬Ù‡ Ø¹Ù…Ø±Ù‡Ø§ 35 Ø³Ù†Ù‡ ØªØ¹Ø§Ù†ÙŠ Ù…Ù† Ù†Ø²ÙˆÙ„ Ø§Ù„Ø±Ø­Ù… ÙˆØ§Ø°Ø§ Ø¬Ø§Ø¡ Ù…ÙˆØ¹Ø¯ Ø§Ù„Ø¹Ø§Ø¯Ù‡ Ø§Ù„Ø´Ù‡Ø±ÙŠÙ‡ ØªØ´Ø¹Ø± Ø¨Ø§Ù„Ø§Ù… ÙØ¶ÙŠØ¹Ù‡ ÙÙŠ ÙƒØ§Ù…Ù„ Ø¬Ø³Ù…Ù‡Ø§ ÙˆÙŠÙƒÙˆÙ† Ø§Ù„Ø¯Ù… Ù‚ÙˆÙŠØ§ Ø¹Ù„ÙŠÙ‡Ø§ Ø¨Ù…Ø§Ø°Ø§ ØªÙ†ØµØ­ÙˆÙ†Ù‡Ø§ ÙˆØ´ÙƒØ±Ø§ Ø¬Ø²ÙŠÙ„Ø§\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 11500/39789\n",
      "================================================================================\n",
      "Input text: Ø¨Ù‚Ø§Ù„ÙŠ Ø³Ù†Ù‡ Ù…ØªØ²ÙˆØ¬Ù‡ ÙˆÙ„Ù… ÙŠØ­Ø¯Ø« Ø­Ù…Ù„ Ù†ØµØ­ÙˆÙ†ÙŠ Ø¨Ø´Ø±Ø¨ Ø§Ù„Ù…ÙŠØ±Ù…ÙŠÙ‡ Ù„ØªÙ‚ÙˆÙŠÙ‡ Ø§Ù„Ù…Ø¨Ø§ÙŠØ¶ Ø¨Ø¹Ø¯ Ù…Ø§Ø´Ø±Ø¨ØªØ§ ØªØºØ±Ø¨Ø·Øª Ø§Ù„Ø¯ÙˆØ±Ù‡ Ø¹Ù†Ø¯ÙŠ Ù…Ø¹ Ø§Ù„Ø¹Ù„Ù… ÙƒØ§Ù†Øª ØªØ¬ÙŠÙ†ÙŠ ÙƒÙ„ 28 ÙŠÙˆÙ… Ù…Ø§Ø³Ø¨Ø¨ Ø²Ù„Ùƒ Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø±Ø¯\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: False\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 12000/39789\n",
      "================================================================================\n",
      "Input text: Ù…Ø±Ø­Ø¨Ø§ Ù‡Ù„ Ø§Ù„Ù…Ø§Ø¡ Ø§Ù„Ø³Ø§Ø®Ù† Ø§Ùˆ Ø§Ù„Ø¯Ø§ÙØ¦ ÙŠØ³Ø¨Ø¨ Ø¶Ø±Ø± Ù„ Ø§Ù„ØªÙˆØ§Ø¡ Ø§Ù„Ù‚Ø¯Ù… ÙˆØªØºØ·ÙŠØ³Ù‡ Ù„ÙØªØ±Ù‡ Ù…Ù† Ø²Ù…Ù† ÙˆØ´ÙƒØ±Ø§\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 12500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø±ÙŠØ¯ Ø§Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§ØºØ°ÙŠÙ‡ Ø§Ù„Ù…ØªÙˆØ§Ø¬Ø¯Ù‡ ÙÙŠ Ø§Ù„ØµÙŠØ¯Ù„ÙŠØ§Øª ÙˆØ§Ù„Ù…Ø­Ù„Ø§Øª Ù„Ù…Ø±Ø¶ Ø§Ù„Ø³ÙŠÙ„ÙŠØ§Ùƒ Ù…Ø¹ Ø§Ù„Ø³Ø¹Ø±\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 13000/39789\n",
      "================================================================================\n",
      "Input text: Ø­ÙƒÙ‡ ÙÙŠ Ø§Ù„Ø¨Ø¸Ø± ÙˆØ§Ù†Ø§ Ø­Ø§Ù…Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 13500/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ù„Ø¯ÙŠ Ø¨Ø­Ø© Ø¹Ù…ÙŠÙ‚Ø© Ø¨ØµÙˆØªÙŠ Ùˆ Ø£Ø­Ø³Ø§Ø³ Ø¨Ø¶Ø¹Ù Ø´Ø¯ÙŠØ¯ Ø¨Ø§Ù„Ø­Ø¨Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠØ© Ø¨Ø­Ø© Ø§Ù„ØµÙˆØª Ù„Ø¯ÙŠ Ù…ØªÙ„Ø§Ø²Ù…Ø© Ù…Ù†Ø° 6 Ø³Ù†ÙˆØ§Øª ÙˆÙ„Ø§ Ø£Ø¹Ø±Ù Ø§Ù„Ø¹Ù„Ø§Ø¬ Ù„Ù‡Ø§ Ù‡Ø°Ù‡ Ø§Ù„Ø¨Ø­Ø© Ø¨Ø¯Ø£Øª ØªØ¤Ø«Ø± Ø³Ù„Ø¨Ø§ Ø¹Ù„Ù‰ Ø­ÙŠØ§ØªÙŠ Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ù„ØµØ¹ÙˆØ¨Ø©... \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 14000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… Ø§Ù†Ø§ Ø¨Ù†Øª ÙˆØ¹Ù…Ø±ÙŠ 21 ØµØ§Ø±Ù„ÙŠ ÙƒÙ… ÙŠÙˆÙ… Ø§Ø­Ø³ Ø¨Ø§Ù„Ù… Ø¨Ø§Ù„Ø°Ø±Ø§Ø¹ Ø¨Ø¹Ø¯Ù‡Ø§ ØµØ§Ø± Ø§Ù„Ø§Ù„Ù… Ù Ø§Ù„Ø°Ø±Ø§Ø¹ ÙˆØ§Ø±Ù‚Ø¨Ù‡ ÙˆØ§Ù„ÙƒØªÙ ÙˆÙƒÙ„Ù‡Ø§ Ø¨Ø§Ù„Ø¬Ù‡Ù‡ Ø§Ù„ÙŠØ³Ø±ÙŠ ÙˆØ§Ø­Ø³Ø§Ø³ Ø¯Ø§Ø¦Ù… Ø¨Ø§Ù„ØºØ«ÙŠØ§Ù† Ù‡Ù„ Ù…Ù…ÙƒÙ† ÙŠÙƒÙˆÙ† Ø§Ù„Ù‚Ù„Ø¨\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 14500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… Ø§Ø´Ø¹Ø± Ø¨Ø§ ØºØ«ÙŠØ§Ù† Ø¹Ù†Ø¯ Ø§Ù„Ø¬ÙˆØ¹ ÙˆØ¹Ù†Ø¯Ù…Ø§ Ø§ÙƒÙ„ Ù„Ø§ Ø§Ø­Ø³ Ø¨Ø§ Ø§Ù„Ø´Ø¨Ø¹ ÙˆÙ…Ø±Ø§Øª Ø§Ø­Ø³ Ø¨Ø§ Ø­Ø±Ù‚Ø§Ù† ÙÙŠ Ø§Ù„Ù…Ø¹Ø¯Ù‡ ØªØ³ØªÙ…Ø± Ù„Ø§ Ø¯Ù‚Ø§ÙŠÙ‚\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 15000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ù‡Ù„ Ù‚Ø·Ø±Ø§Øª Ø§Ù„Ø¹ÙŠÙ† ØªØ´ÙÙŠ Ø§Ù„Ø§Ø´Ø®Ø§Øµ Ø§Ù„Ù…ØµØ§Ø¨ÙŠÙ† Ø¨ØªÙ„Ù Ø§Ù„Ø´Ø¨ÙƒÙŠØ© Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø³ÙƒØ±ÙŠØŸ\n",
      "\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 15500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… Ø§Ù†Ø§ Ø¨Ø¹Ø±Ù‚ Ø¹Ø±Ù‚ Ø´Ø¯ÙŠØ¯ ÙÙŠ Ø§ÙŠØ¯ÙŠ Ø§ÙˆÙ„ Ù…Ø§ Ø§ØªØ¹Ø±Ø¶ Ù„ØªÙˆØªØ± Ø§Ùˆ Ø§Ù†ÙŠ Ø§ØªØ¹Ø±Ø¶ Ù„Ù…ÙˆÙ‚Ù ÙÙŠÙ‡ Ø¶ØºØ· ÙˆØ²Ù†ÙŠ Ø·Ø¨ÙŠØ¹ÙŠ\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 16000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ø¹Ù…Ø±ÙŠ 33 ÙˆÙ†ØµÙ ÙˆÙ…Ù† Ø§Ù…Ø§ Ø¨Ù„ØºØª ÙˆØµØ§Ø±Øª ØªÙ†Ø²Ù„ Ø§Ù„Ø¯ÙˆØ±Ù‡ ÙˆÙ…Ø¯ØªÙ‡Ø§ Ø³Ø¨Ø¹Ù‡ Ø§ÙŠØ§Ù… ÙˆÙ…Ù†Ø° Ø´Ù‡Ø±ÙŠÙ† ØªÙ†Ø²Ù„ ÙÙ‚Ø· ÙŠÙˆÙ…ÙŠÙ† Ù…Ø§ Ø³Ø¨Ø¨ ÙˆÙ‡Ù„ Ù‡Ù†Ø§Ùƒ Ù…Ø§ ÙŠØ¯Ø¹ÙŠ Ø§Ù„Ø®ÙˆÙ ÙˆÙ‡Ù„ ÙŠØ¤Ø«Ø± Ø¹Ù„ÙŠ Ø§Ù„Ø­Ù…Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 16500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ø´Ø§Ø¨ Ù…Ù† Ø§Ù„Ø¹Ù…Ø± 21 Ø³Ù†Ù‡ Ø§ØµØ§Ø¨ Ø¨Ø§Ù„Ø¨Ø±Ø¯ Ø§Ù„Ø²ÙƒØ§Ù… Ø§Ù„Ø´Ø¯ÙŠØ¯ Ø®Ù„Ø§Ù„ ÙØµÙ„ Ø§Ù„Ø´ØªØ§Ø¡ Ø¨Ø§ÙƒÙ…Ù„Ù‡ Ø§Ø±Ø§Ø¬Ø¹ ÙˆØ§Ù„Ø´ÙˆÙƒÙ„Ø§ØªÙ‡ ÙˆØ§Ù„Ø§Ø·Ø¨Ø§Ø¡Ø¡ ÙˆÙ„ÙƒÙ† Ø¯ÙˆÙ† ÙØ§Ø¦Ø¯Ù‡ ÙÙ„Ø§ Ø§Ø·ÙŠØ¨ Ø§Ù„Ø§ Ø§Ù† ÙŠØ­Ù„ Ø§Ù„Ø´ØªØ§Ø¡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 17000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† ÙˆØ¬Ø¹ ÙÙŠ Ø§Ø±Ù‚Ø¨Ù‡ Ø­Ø§Ø¯ ÙˆØ°Ù„Ùƒ Ù…Ø¤Ø«Ø± Ø¹Ù„ÙŠ Ø§Ù„ÙƒØªÙ ÙˆÙ„Ø§ Ø§Ø³ØªØ·ÙŠØ¹ Ø§Ù† Ø§Ù†Ø§Ù… Ø§Ùˆ Ø§Ø­Ø±Ùƒ Ø±Ù‚Ø¨ØªÙŠ Ù…Ø§Ù„Ø­Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 17500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ù„Ø¯ÙŠ Ø§Ø³Ù‡Ø§Ù„ Ø¹Ø§Ø¯ÙŠ Ø§Ø´Ø±Ø¨ Ù…Ø§Ø¡ ÙƒØ«ÙŠØ± Ù„Ø§Ù† Ø¹Ù†Ø¯ÙŠ Ø±Ù…Ù„ ÙÙŠ Ø§Ù„ÙƒÙ„ÙŠ Ø¨Ø³ Ù„Ù…Ù† Ø§Ø´Ø±Ø¨ ÙƒØ«ÙŠØ± Ù…Ø§Ø¡ ÙŠØ²ÙŠØ¯ Ø§Ø³Ù‡Ø§Ù„ Ù…Ø§Ø°Ø§ Ø§ÙØ¹Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 18000/39789\n",
      "================================================================================\n",
      "Input text: Ø¹Ù…Ø±ÙŠ 36 Ø³Ù†Ù‡ Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªØ±ÙƒÙŠØ¨ Ù„ÙˆÙ„Ø¨ Ù†Ø­Ø§Ø³ÙŠ Ø¨Ø¹Ø¯ Ø¹Ù…Ù„ÙŠØªÙŠÙ† Ù‚ÙŠØµØ±ÙŠØªÙŠÙ† Ø§Ù„Ø§Ø®ÙŠØ±Ù‡ ÙÙŠ ÙŠÙ†Ø§ÙŠØ± 2014 ÙˆÙƒÙŠÙ ÙŠÙ…Ù†Ø¹ Ø§Ù„Ù„ÙˆÙ„Ø¨ Ø§Ù„Ø­Ù…Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 18500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… Ù‡Ù„ ØªÙ†ØµØ­ÙˆÙ†ÙŠ Ø¨Ø¹Ù…Ù„ ØªÙ„Ø¨ÙŠØ³Ù‡ Ù„Ù„Ø³Ù† Ø§Ù„Ø§Ù…Ø§Ù…ÙŠ Ù„Ø§Ù†ÙŠ Ù‚Ù…Øª Ø¨Ø³Ø­Ø¨ Ø¹ØµØ¨Ù‡ ÙˆÙ„Ù„Ø¹Ù„Ù… ØªØ§Ø¬ Ø§Ù„Ø³Ù† Ø³Ù„ÙŠÙ… Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ ÙˆØ®Ø§Ù„ÙŠ Ù…Ù† Ø§Ù„ØªØ³ÙˆØ³ ÙˆÙ„ÙƒÙ† Ù„Ø§ Ø§Ø¹Ø±Ù Ù„Ù…Ø§Ø°Ø§ Ø§Ù„ØªÙ‡Ø¨ Ø¹ØµØ¨ Ø§Ù„Ø³Ù†\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 19000/39789\n",
      "================================================================================\n",
      "Input text: Ø§ØªØªÙ†ÙŠ Ø§Ù„Ø¯ÙˆØ±Ù‡ Ø§Ù„Ø´Ù‡Ø±ÙŠÙ‡ Ù„Ù„Ù…Ø±Ù‡ Ø§Ù„Ø§ÙˆÙ„ÙŠ Ù…Ø±Ù‡ ÙˆØ§Ø­Ø¯Ù‡ ÙˆØ§Ù†Ù‚Ø·Ø¹Øª Ù„Ù…Ø¯Ù‡ 6 Ø§Ø´Ù‡Ø± Ù‡Ù„ Ù‡Ø°Ø§ Ø§Ù…Ø± Ø·Ø¨ÙŠØ¹ÙŠ Ø§Ù… Ù„Ø§ Ø¹Ù„Ù…Ø§ Ø§Ù†Ù†ÙŠ Ø§Ø¨Ù„Øº 16 Ø³Ù†Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 19500/39789\n",
      "================================================================================\n",
      "Input text: Ø­Ø§Ù…Ù„ ÙÙŠ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø«Ø§Ù„Ø« ÙˆØªØ­Ù„ÙŠÙ„ ÙÙŠØªØ§Ù…ÙŠÙ† Ø¯ Ù‚ÙŠÙ…ØªÙ‡ 11 Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¬Ø±Ø¹Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø¨Ù‡ ÙŠÙˆÙ…ÙŠØ§\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 20000/39789\n",
      "================================================================================\n",
      "Input text: Ø·ÙÙ„ØªÙŠ Ø¹Ù…Ø±Ù‡Ø§ Ø³Ù†Ù‡ ÙˆØªØ³Ø¹ Ø´Ù‡ÙˆØ± Ø¸Ù‡Ø±Øª Ù„Ù‡Ø§ Ø±Ø§Ø¦Ø­Ù‡ ÙÙŠ ÙÙ…Ù‡Ø§ Ù…Ù†Ø° Ø§Ø±Ø¨Ø¹ Ø§ÙŠØ§Ù… ÙˆÙ‡ÙŠ ÙˆØ§Ù„Ø­Ù…Ø¯ Ø§Ù„Ù„Ù‡ Ù„Ø§ ØªØ´ÙƒÙˆØ§ Ù…Ù† Ø´ÙŠ Ø¹Ù†Ø¯Ù‡Ø§ ØªØ³Ù†ÙŠÙ† ÙÙŠ Ø§Ù„Ø§Ø¶Ø±Ø§Ø³\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 20500/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø¹Ø§Ù†ÙŠØª Ù…Ù† Ù†Ø²Ù„Ø© Ø¨Ø±Ø¯ Ù„ÙƒÙ† Ø´ÙÙŠØª Ø¥Ù„Ø§ Ø£Ù† Ø§Ù„Ø³Ø¹Ø§Ù„ Ø¨Ù‚ÙŠ Ø¹Ù†Ø¯ÙŠ Ù„ÙƒÙ†Ù‡ Ø³Ø¹Ø§Ù„ Ø¬Ø§Ù Ø®Ø§ØµØ© ÙÙŠ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ù…ØºÙ„Ù‚Ø© Ù…Ø§Ù‡Ùˆ Ø£ÙØ¶Ù„ Ø¹Ù„Ø§Ø¬ ØŸ \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 21000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù„Ø³ Ù… Ø¹Ù„ÙŠÙƒÙ… Ø§Ù†Ø§ Ø­Ø§Ù…Ù„ ÙÙŠ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø«Ø§Ù…Ù† Ø¨ØªÙˆØ§Ù… Ø« Ø«ÙŠ Ø§Ø­Ø¨ Ø§Ù† Ø§Ø³Ø¦Ù„ Ø¹Ù† Ø§Ù„Ø§Ø¨Ø± Ø§Ù„Ù…ÙƒÙ…Ù„Ù‡ Ù„Ø§Ù„Ø±Ø¦Ù‡ Ù‡Ù„ Ù‡ÙŠ Ø¶Ø±ÙˆØ±ÙŠÙ‡ ÙˆÙ…ØªÙŠ ÙŠØ¬Ø¨ Ø§Ø®Ø°Ù‡Ø§ Ù…Ø¹ Ø¬Ø²ÙŠÙ„ Ø§Ù„Ø´ÙƒØ±\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: False\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 21500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø³Ø¨Ø§Ø¨ ÙˆØ¬ÙˆØ¯ Ø·Ø¨Ù‚Ù‡ Ø¨ÙŠØ¶Ø§Ø¡ Ø¹Ù„ÙŠ Ø§Ù„Ù„Ø³Ø§Ù† ÙˆØ¬ÙØ§Ù Ø§Ù„Ø±ÙŠÙ‚ Ù…Ø¹ ÙˆØ¬ÙˆØ¯ Ø·Ø¹Ù… Ù…Ø±Ø§Ø±Ù‡ ÙÙŠ Ø§Ù„ÙÙ…\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 22000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "ÙƒÙ… Ù…Ù‚Ø§Ø³ Ù†Ø¸Ø±ÙŠ ÙˆÙ‡Ù„ Ø§Ø­ØªØ§Ø¬ Ù„Ù„Ø¨Ø³ Ù†Ø¸Ø§Ø±Ø©ØŸ \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 22500/39789\n",
      "================================================================================\n",
      "Input text: ØªØ§Ø®Ø± Ø§Ù„Ø¯ÙˆØ±Ù‡ Ø§Ù„Ø´Ù‡Ø±ÙŠÙ‡ Ù„Ù…Ø¯Ù‡ 10 Ø§ÙŠØ§Ù… Ø¹Ù†Ø¯ ÙØªØ§Ù‡ Ø¹Ø°Ø±Ø§Ø¡ Ù‡Ù„ Ù‡Ùˆ Ø¹Ø§Ø¯ÙŠ Ø§Ù… Ù„Ø§\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 23000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø´Ø¹Ø± ÙÙŠ Ø§Ù„Ù… ÙÙŠ Ù…Ù†Ø·Ù‚Ù‡ ÙƒÙˆØ¹ Ø§ÙŠØ¯ Ø§Ø´Ù…Ø§Ù„ ÙˆØ§Ù„ÙŠÙ…ÙŠÙ† Ù…Ù† 4 Ø§ÙŠØ§Ù… ÙˆÙŠÙ…ØªØ¯ Ù†Ø­Ùˆ Ø®Ù„Ù Ø§Ù„Ø¹Ø¶Ù„Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 23500/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø®Ù„Ø·Ù‡ Ø·Ø¨ÙŠÙŠØ¹Ù‡ Ù„ØªØ±Ø·ÙŠØ¨ Ø§Ù„Ø´Ø¹Ø± \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: False\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 24500/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø§ÙŠØ´ Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ùˆ Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø¥Ù‚Ù„Ø§Ø¹ Ø¹Ù† Ø§Ù„ØªØ¯Ø®ÙŠÙ† ØŸ\n",
      "Ù„Ù„Ù…Ø±Ø¶Ù‰ Ø§Ù„Ù‚Ù„Ø¨ Ø§Ùˆ Ø§Ù„ÙŠ Ø§ØµØ§Ø¨ØªÙ‡Ù… Ø¬Ù„Ø·Ù‡ Ù…Ø³Ø¨Ù‚Ø§Ù‹ ØŸ\n",
      "\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 25000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "ØµØ¯ÙŠØ¯ ÙŠØ®Ø±Ø¬ Ù…Ù† ÙˆØ±Ø§Ø¡ Ø·Ø¨Ù„Ø© Ø§Ù„Ø§Ø°Ù† ÙŠÙˆÙ…ÙŠØ§ Ù…Ù† Ø§ÙƒØ«Ø± Ù…Ù† Ø¹Ø§Ù… Ù„ÙˆÙ†Ù‡ Ø§ØµÙØ± Ø³Ù…ÙŠÙƒ \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 25500/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† ÙˆØ¬Ø¹ Ø´Ø¯ÙŠØ¯ ÙÙŠ Ù…Ø¤Ø®Ø±Ø© Ø§Ù„Ø±Ø§Ø³ ÙŠÙ…ØªØ¯Ø¯ Ø§Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø© Ø§Ù„ÙŠØ³Ø±Ù‰ Ù…Ù† Ø§Ù„Ø§Ø°Ù† ÙˆÙˆØ¬ ÙÙŠ Ø§Ù„Ø±Ù‚Ø¨Ù‡ ÙˆÙ…Ù† Ø´Ø¯Ø© Ø§Ù„Ø§Ù„Ù… Ø§Ù„Ù‚Ù„Ø¨ ÙŠÙˆØ¬Ø¹ Ù…Ø¹ Ø³ÙØ¦Ù‡ Ø¨Ø§Ù„Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø§ÙŠØ³Ø±\n",
      "Ø¬Ø²Ø§ÙƒÙ… Ø§Ù„Ù„Ù‡ Ø®ÙŠØ± \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 26000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø¹Ù…Ø±ÙŠ 35, Ø¹Ø¯Ø¯ Ù†Ø¨Ø¶Ø§Øª Ø§Ù„Ù‚Ù„Ø¨ Ø·Ø¨ÙŠØ¹ÙŠØ© Ø¨ÙŠÙ† 60 Ùˆ 100 Ø¶Ø±Ø¨Ø© ÙÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©ØŒ Ø§Ù„Ø¶ØºØ· Ø·Ø¨ÙŠØ¹ÙŠ. Ùˆ Ù„ÙƒÙ† ÙÙŠ Ù…Ø¹Ø¸Ù… Ø§Ù„Ø£ÙˆÙ‚Ø§Øª Ø£Ø´Ø¹Ø± Ø¨Ø¶Ø±Ø¨Ø§Øª Ù‚Ù„Ø¨ÙŠ Ùˆ Ø£Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø®ÙˆØ§Ø±Ø¬ Ø§Ù„Ø§Ù†Ù‚Ø¨Ø§Ø¶. Ø§Ù„ÙØ­Øµ Ùˆ... \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 26500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø´Ø¹Ø± Ø¨Ø§Ù„Ø­ÙƒÙ‡ ÙÙŠ Ø§Ù„Ù…Ù‡Ø¨Ù„Ù„ Ù…Ù† Ø§Ù„Ø¯Ø§Ø®Ù„ ÙˆØ§Ù†Ø§ Ø¨Ù†Øª Ù…Ø§Ø°Ø§ ÙŠØ¬Ø¨ Ø§Ù† Ø§Ø³ØªØ¹Ù…Ù„ ÙƒØ¯ÙˆØ§Ø¡ ÙˆØ´ÙƒØ±Ø§\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 27000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… Ø§Ù†Ø§ Ù…Ù† Ø§Ù„Ø³ÙˆØ¯Ø§Ù†\n",
      "Ù…Ø´ÙƒÙ„ØªÙŠ Ø§Ù†ÙŠ Ù…Ø§ Ø§Ø³Ù…Ø¹ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¬ÙŠØ¯Ø© Ø§Ø³Ù…Ø¹ ØµÙˆØª Ø¨Ø³ Ù…Ø§ Ø§Ù‚Ø¯Ø± Ø§Ù…ÙŠØ² Ø§Ù„ÙƒÙ„Ø§Ù… \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 27500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ø§Ø®Ø° Ø­Ø¨ÙˆØ¨ Ù…Ù†Ø¹ Ø§Ù„Ø­Ù…Ù„ Ø´Ø±ÙŠØ· ÙˆÙ†Øµ ÙˆÙ‚Ø¨Ù„ ÙŠÙˆÙ…ÙŠÙ† ØªÙ… Ø§Ù†Ù‚Ø·Ø§Ø¹ Ø­Ø¨ÙˆØ¨ Ù…Ù†Ø¹ Ø§Ù„Ø­Ù…Ù„ Ø¨Ø·Ù†ÙŠ Ù…Ù†ÙØ®Ù‡ ÙˆÙ„Ù… ØªÙ†Ø²Ù„ Ø§ÙŠ Ø¹Ù„Ø§Ù…Ù‡ Ù…Ù† Ø¯ÙˆØ±Ù‡ Ù…Ø§Ø°Ø§ Ø§ÙØ¹Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 28000/39789\n",
      "================================================================================\n",
      "Input text: Ø¹Ù†Ø¯Ù…Ø§ Ø§Ù„Ù…Ø³ ÙÙƒÙŠ Ø§Ù„Ø³ÙÙ„ÙŠ Ù…Ù† Ø§Ù„Ø¬Ù‡Ù‡ Ø§Ù„ÙŠÙ…Ù†ÙŠ Ù…Ù† ÙÙ…ÙŠ ÙØ§Ù†Ù†ÙŠ Ø§ØµØ§Ø¨ Ø¨Ø§Ù„Ø­Ø§Ø²ÙˆÙ‚Ù‡ ÙˆÙ„Ø§ Ø§Ø¯Ø±ÙŠ Ù„Ù…Ø§Ø°Ø§ Ù…Ø¹ Ø§Ù„Ø¹Ù„Ù… Ø§Ù†Ù†ÙŠ ÙØªØ§Ù‡ ÙˆØ¹Ù…Ø±ÙŠ 17 Ø³Ù†Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 28500/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø¹Ù…Ø±ÙŠ 35 Ø³ Ø¶ØºØ·ÙŠ Ø¨Ø¯Ø§ ÙŠØ±ØªÙØ¹ ÙŠØ¶Ø¨Ø­ Ø§Ù„Ø¹Ø§Ù„ÙŠ14 ÙˆØ§ÙˆØ§Ø·ÙŠ Ø¨ÙŠÙ† 8 Ùˆ 7 ÙˆÙ„Ø¯ÙŠ Ø¯ÙˆØ®ÙŠ Ø¨Ø³ÙŠØ·Ø© ..Ù‡Ù„ Ø³Ø¨Ø¨Ù‡ Ø§Ù„Ø¶ØºØ· Ø§Ùˆ Ù‡Ù†Ø§Ùƒ Ø³Ø¨Ø¨ Ø§Ø®Ø± .Ø±Ø§Ø¬Ø¹Øª Ø·Ø¨ÙŠØ¨ Ù‚Ø§Ù„ Ø§Ù„Ø¯ÙˆØ®Ø© Ø³Ø¨Ø¨Ù‡ Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ø¸ØºØ·... \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 29000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø°Ø§ Ø­ØµÙ„ Ø¬Ù…Ø§Ø¹ Ø¨Ø¹Ø¯ 10 Ø§ÙŠØ§Ù… Ù…Ù† Ø§Ù„Ø¯ÙˆØ±Ù‡ Ù„Ù…Ø¯Ù‡ Ø§Ø³Ø¨ÙˆØºÙŠÙ† ÙˆØºØ§Ø¨Øª Ø§Ù„Ø¯ÙˆØ±Ù‡ Ù…ØªÙŠ ÙŠØªÙ… ÙØ­Øµ Ø§Ù„Ø­Ù…Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 29500/39789\n",
      "================================================================================\n",
      "Input text: ÙƒÙŠÙ Ø§Ø¹Ø±Ù Ø­Ø¬Ù… ØªÙƒÙŠØ³ Ø§Ù„Ù…Ø¨ÙŠØ¶ ÙˆÙ‡Ù„ Ø§Ø¨Ø± Ø§Ù„ØªÙØ¬ÙŠØ± ØªØ³Ø§Ø¹Ø¯ Ø¹Ù„ÙŠ Ø§Ù„Ø­Ù…Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 30000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "ÙƒØ³Ù„ ÙÙŠ Ø§Ù„Ø¹ÙŠÙ† Ù…Ø§ Ø¹Ù„Ø§Ø­Ù‡Ø§ ØŸ \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 30500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø­Ø³ Ø¨Ø­ÙƒÙ‡ ÙÙŠ Ù…Ù†Ø·Ù‚Ù‡ Ø§Ù„Ù…Ù‡Ø¨Ù„Ù„ ÙƒÙ„Ù‡Ø§ Ø¨Ø¹Ø¯ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø¯ÙˆØ±Ù‡ Ø¨Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒØ±Ù…Ø§Øª ÙˆÙ„ÙƒÙ† Ø¨Ø¹Ø¯ ÙƒÙ… Ø³Ø§Ø¹Ù‡ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙƒÙ‡ Ø§ØµØ¹Ø¨ Ù…Ù† Ø§Ù„Ù…Ø±Ù‡ Ø§Ù„ÙŠ Ù‚Ø¨Ù„Ù‡Ø§\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 31000/39789\n",
      "================================================================================\n",
      "Input text: ØªØ³Ø¹ Ø§Ø³Ø§Ø¨ÙŠØ¹ Ù…Ù† Ø§Ù„Ø­Ù…Ù„ ÙƒÙ… Ø´Ù‡Ø± ÙŠØ³Ø§ÙˆÙŠ\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 31500/39789\n",
      "================================================================================\n",
      "Input text: Ù…Ø§Ù‡Ùˆ Ø¹Ù„Ø§Ø¬ ØªÙˆØ±Ù… Ø§Ù„ÙŠØ¯ÙŠÙ†Ù† Ø¨Ø³Ø¨Ø¨ Ø§Ù„ÙƒØ¯Ù…Ø§Øª\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 32000/39789\n",
      "================================================================================\n",
      "Input text: Ù…Ø§ Ù‡Ùˆ Ø¹Ø¯Ø¯ Ø¶Ø±Ø¨Ø§Øª Ø§Ù„Ù‚Ù„Ø¨ Ø§Ø°Ø§ ØªØ¬Ø§ÙˆØ²Ù‡ Ø§Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ±Ø§Ø­Ù‡ ÙˆØ¹Ø¯Ù… Ø¨Ø°Ù„ Ø§Ù„Ù…Ø¬Ù‡ÙˆØ¯ ÙŠØ¹ØªØ¨Ø± Ø¹Ù„Ø§Ù…Ù‡ Ù…Ù‡Ù…Ù‡ ÙˆÙŠØ«ÙŠØ± Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 32500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ø´Ø§Ø¨ Ø§Ø¨Ù„Øº Ù…Ù† Ø§Ù„Ø¹Ù…Ø± 27 Ø¹Ø§Ù…Ø§ Ù…Ø¯Ø®Ù† Ø§Ø´Ø¹Ø± Ø¹Ù†Ø¯ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù…Ø¬Ù‡ÙˆØ¯ ÙƒØ¨ÙŠØ± Ø¨ØªØ¹Ø¨ Ø´Ø¯ÙŠØ¯ ÙˆØ³Ø±Ø¹Ù‡ ÙÙŠ Ø§Ù„ØªÙ†ÙØ³ Ø¹Ù†Ø¯ ØµØ¹ÙˆØ¯ Ø§Ù„Ø¯Ø±Ø¬ Ø§Ùˆ Ù…Ø§ Ø´Ø§Ø¨Ù‡ Ù‡Ù„ Ù‡Ø°Ø§ Ø·Ø¨ÙŠØ¹ÙŠ Ø§Ù… Ù„Ø§\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 33000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ ØµØ±Ù„ÙŠ Ø´Ù‡Ø± Ù…ØªØ²ÙˆØ¬Ù‡ Ø§Ø¬Øª Ø§Ù„Ø¯ÙˆØ±Ù‡ Ø§Ù„Ø´Ù‡Ø±ÙŠÙ‡ ÙÙŠ 14102017 Ø¨Ø¹Ø¯ Ø¨ÙŠ Ø§Ø³Ø¨ÙˆØ¹ Ø¹Ù…Ù„Ù†Ø§ Ø¹Ù„Ø§Ù‚Ù‡ ÙˆØ§Ù„Ø§Ù† Ø¹Ù… Ø¯ÙˆØ® ÙˆÙ„Ø¹ÙŠØ§Ù† Ù†ÙØ³ Ù‚ÙˆÙŠÙ‡ ÙˆØ¬Ø¹ Ø¶Ù‡Ø±\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 33500/39789\n",
      "================================================================================\n",
      "Input text: Ø¨Ø¹Ø¯ Ø®Ø±ÙˆØ¬ÙŠ Ù…Ù† Ø§Ù„Ù†ÙØ§Ø³ Ù„Ù… ÙŠÙ„ØªØ¦Ù… Ø¬Ø±Ø­ Ø§Ù„Ø®ÙŠØ§Ø·Ù‡ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠÙ‡ Ø¨Ù‚ÙŠ Ø§Ø¬Ø²Ø§Ø¡ Ù„Ù… ØªÙ„ØªØ§Ù… Ù…Ø§Ù‡Ùˆ Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§ÙŠØ¶Ø§ Ø§Ø±ÙŠØ¯ Ø­Ù„ÙˆÙ„ Ù…Ù† ØºÙŠØ± Ø§Ø¹Ø§Ø¯Ù‡ Ø§Ù„Ø®ÙŠØ§Ø·Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 34000/39789\n",
      "================================================================================\n",
      "Input text: ØªÙ†Ø§ÙˆÙ„Øª Ø¯ÙˆØ§ Ø¹Ù„Ø§Ù‚Ù‡Ø§Ø¹Ù…Ù„ÙŠ Ø­Ø¨Ù‡ ÙˆØ§Ø­Ø¯Ù‡ ÙˆØ¨Ø¹Ø¯Ù‡Ø§ Ø¹Ù†Ù„Øª Ø§Ø®ØªØ¨Ø§Ø± Ø­Ù…Ù„ ÙˆØ·Ù„Ø¹Øª Ø­Ø§Ù…Ù„ Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø®Ø·ÙˆØ±Ù‡ Ø¹Ù„ Ø§Ù„Ø¬Ù†ÙŠÙ† ÙˆÙ‡Ù„ Ù…Ù…ÙƒÙ† Ø§Ù„ØªØ¹Ø±Ø¶ Ù„Ù„Ø§Ø¬Ù‡Ø§Ø¶ Ø§Ø±Ø¬Ùˆ Ø§Ù„Ø±Ø¯\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 34500/39789\n",
      "================================================================================\n",
      "Input text: Ø¹Ù…Ø±ÙŠ 25 Ø§Ø¹Ø²Ø¨Ø¡ Ø§Ø´Ø¹Ø± Ø¨Ø­Ø±Ø§Ø±Ù‡Ù‡ ÙÙŠ Ù…Ø¹Ø¯ØªÙŠ ÙˆÙŠØ±Ø§ÙÙ‚Ù‡Ø§ Ù‡Ø¨ÙˆØ· ÙˆØ´Ø¹ÙˆØ± Ø¨Ø§Ù„ØºØ«ÙŠØ§Ù† ØªÙ… ØªØ´Ø®ÙŠØµÙŠ Ø¨Ø§Ù„Ø³Ø§Ø¨Ù‚ Ø¨Ø§Ù„Ø§Ù„ØªÙ‡Ø§Ø¨ Ø§Ù…Ø¹Ø§Ø¡ ÙˆØ§Ø®Ø°Øª Ø§Ù„Ø¹Ù„Ø§Ø¬ ÙˆÙ„ÙƒÙ† Ø§Ù„Ø§Ø¹Ø±Ø§Ø¶ Ø¸Ù‡Ø±Øª Ù…Ù† Ø¬Ø¯ÙŠØ¯\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 35000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ ÙˆØµÙØ§Øª Ø¹Ø´Ø¨ÙŠØ© ØªØ³Ø§Ø¹Ø¯ Ù…Ø´Ø§ÙƒÙ„ Ø¶Ø¹Ù Ø§Ù„Ø¨ØµØ± Ø§Ù„Ù…Ø³ØªØ¹ØµÙŠØ© Ø¹Ù„Ù‰ Ø§Ø·Ø¨Ø§Ø¡ Ø§Ù„Ø¹ÙŠÙˆÙ† \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 35500/39789\n",
      "================================================================================\n",
      "Input text: Ø¨ÙŠÙ† Ø¯ÙˆØ±ØªÙŠ ÙˆØ¯ÙˆØ±ØªÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠÙ‡ 31 ÙŠÙˆÙ… ÙˆØ§Ø³ØªØ®Ø¯Ù…Øª ÙƒÙ„ÙˆÙ…ÙŠØ¯ Ù„Ø§ÙˆÙ„ Ù…Ø±Ù‡ Ù„ØªÙ†Ø´ÙŠØ· Ø§Ù„Ù…Ø¨Ø§ÙŠØ¶ ÙˆØ§Ù„Ù„ÙŠÙˆÙ… Ø§Ù„ 14 Ù…Ù† Ø§Ù„Ø¯ÙˆØ±Ù‡ ÙˆØ­Ø¬Ù… Ø¨ÙˆÙŠØ¶ØªÙŠ 14 Ù‡Ù„ Ù‡Ø°Ø§ Ø­Ø¬Ù…Ù‡Ø§ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ Ù„ Ø§Ù„Ù„ÙŠÙˆÙ… Ø§Ùˆ Ø³ØªÙƒØ¨Ø± ÙØ§Ù„ÙŠÙˆÙ…ÙŠÙ† Ø§Ù„Ù…Ù‚Ø¨Ù„Ù‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 36000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø¬Ø±ÙŠØª Ø¹Ù…Ù„ÙŠÙ‡ ØªØ¬Ù…ÙŠÙ„ Ø§Ù„Ø§Ù†Ù Ù…Ù†Ø° Ø´Ù‡Ø± ÙˆØ§Ø±ÙŠØ¯ Ø§Ù„Ø­Ù…Ù„ ÙƒÙ… ÙŠØ¬Ø¨ Ø¹Ù„ÙŠ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠÙ‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 36500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø§Ù„Ù… ÙÙŠ Ø§Ù„Ù„Ø«Ù‡ Ù…Ø¹ Ø§Ù†Ø³Ø¯Ø¯ ÙÙŠ Ø§Ù„Ø§Ø°Ù† ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ø­ÙŠØ§Ù† Ù…Ø¹ Ø§Ù„Ù… Ø®ÙÙŠÙ ÙÙŠ Ø§Ù„Ø®Ø¯ Ù‚Ø±ÙŠØ¨ Ø§Ù„Ù„Ø«Ù‡ Ù…Ø¹ Ø§Ù„Ù… ÙÙŠ Ø§Ù„Ø¹ÙŠÙ†\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 37000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø­Ø³Ø³Øª Ù„Ù„ØªÙˆ Ø¨Ø§Ù„Ù… Ø·ÙÙŠÙ Ù†ÙˆØ¹Ø§ Ù…Ø§ ÙÙŠ Ø´Ø±Ø§ÙŠÙ† ÙŠØ¯ÙŠ Ø§Ù„ÙŠØ³Ø±ÙŠ Ù…Ù† Ø§Ù„Ù…Ø±ÙÙ‚ Ø§Ù„ÙŠ Ø§Ù„ÙŠØ¯ Ù…Ø§ Ø§Ù„Ø³Ø¨Ø¨ Ù…Ø¹ Ø§Ù„Ø¹Ù„Ù… Ø§Ù† Ø§Ù„Ø§Ù„Ù… ÙŠØ¯Ù‡Ø¨ ÙˆÙŠØ±Ø­Ø¹\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 37500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ù†Ø§ Ø¹Ø±ÙˆØ³Ù‡ Ø¬Ø¯ÙŠØ¯Ù‡ ÙˆÙ„Ø§ Ø§Ø¹Ø±Ù ÙƒÙŠÙ Ø§Ø³ØªØ®Ø¯Ù… Ù…Ù†Ø¹ Ø§Ù„Ø­Ù…Ù„ ÙˆÙ…Ø§ Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ø§Ø®Ø°Ù‡ Ø§Ø±Ø¬Ùˆ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„ØªÙ‚Ø§Ø¶ÙŠÙ„ Ù…Ø§Ø°Ø§ Ø§ÙØ¹Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 38000/39789\n",
      "================================================================================\n",
      "Input text: \n",
      "Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø·Ø±Ù Ù…Ø³ØªÙ…Ø± ÙÙŠ Ø¹ÙŠÙ†ÙŠ Ø§Ù„Ø§Ø«Ù†ØªÙŠÙ† ( Ø§Ù„Ø¹ÙŠÙ†Ø§Ù† ØªØ·Ø±ÙØ§Ù† Ø§Ø­ÙŠØ§Ù†Ø§ Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø± ) Ø±ØºÙ… Ø§Ù†ÙŠ Ù„Ø§ Ø§ØªÙ†Ø§ÙˆÙ„ Ø§Ù„Ù…Ù†Ø¨Ù‡Ø§Øª ÙˆØ°Ù„Ùƒ Ù…Ù† ÙØªØ±Ø© Ø­ÙˆØ§Ù„ÙŠ Ø´Ù‡Ø± ØªÙ‚Ø±ÙŠØ¨Ø§ Ùˆ Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø­Ù„ Ø§Ù„Ø§ÙØ¶Ù„ Ù…Ù†... \n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 38500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø¨Ù†ÙŠ Ø¹Ù…Ø±Ù‡ 11 Ø³Ù†Ù‡ Ù„Ù… ØªØ³Ù‚Ø· Ù„Ù‡ Ø§Ø³Ù†Ø§Ù†Ù‡ Ø§Ù„Ù„Ø¨Ù†ÙŠÙ‡ Ù…Ø°Ø§ ÙŠØ¬Ø¨ Ø§Ù† Ø§ÙØ¹Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 39000/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø¨Ù„Øº Ù…Ù† Ø§Ù„Ø¹Ù…Ø± 37 Ø³Ù†Ù‡ ÙˆÙ‚Ø¯ Ø§Ù†Ø¬Ø¨Øª ØªÙˆØ§Ù… Ù‚Ø¨Ù„ Ø³ØªÙ‡ Ø§Ø´Ù‡Ø± ÙˆØ®Ù„Ø§Ù„ Ø§Ù„Ø­Ù…Ù„ Ø²Ø§Ø¯ ÙˆØ²Ù†ÙŠ 36 ÙƒÙŠÙ„Ùˆ ÙˆØ§Ù„Ø§Ù† Ø§ØµØ¨Ø­ ÙˆØ²Ù†ÙŠ 80 Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø§Ù„Ø§Ù… Ù‚ÙˆÙŠÙ‡ ÙÙŠ Ø§Ù„Ø±ÙƒØ¨ØªÙŠÙ†\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 39500/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† ÙƒØ­Ù‡ Ù…Ø³ØªÙ…Ø±Ù‡ Ù…ØµØ­ÙˆØ¨Ù‡ ÙŠØ¨Ù„ØºÙ… Ù…Ø¹ Ø§Ø­Ø³Ø§Ø³ Ø¨ØµÙÙŠØ± ÙÙŠ Ø§Ù„Ø±Ø¦Ù‡ Ø§Ù„ÙŠØ³Ø±ÙŠ ÙˆØ­Ø³Ø§Ø³ÙŠÙ‡ Ù…ÙˆØ³Ù…ÙŠÙ‡\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): Ø­Ø±Ø¬\n",
      "True severity: Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Processing sample 39789/39789\n",
      "================================================================================\n",
      "Input text: Ø§Ø®ØªÙŠ ØªØ¹Ø§Ù†ÙŠ Ù…Ù† Ù†Ù‚Øµ ÙÙŠ Ø§Ù„ÙˆØ²Ù† ÙˆØ¹Ù†Ø¯ Ù‚ÙŠØ§Ù…Ù‡Ø§ Ø¨Ø§ÙŠ Ù…Ø¬Ù‡ÙˆØ¯ ÙŠØµÙŠØ¨Ù‡Ø§ Ø§Ù„Ù… ÙÙŠ Ù‚Ù„Ø¨Ù‡Ø§ ÙˆØªØ¹Ø¨ ÙˆØ§ØµÙØ±Ø§Ø± Ø¯Ø§Ø¦Ù… ÙÙŠ Ø§Ù„ÙˆØ¬Ù‡ ÙÙ…Ø§ Ø§Ù„Ø­Ù„\n",
      "\n",
      "Individual model predictions:\n",
      "- bert-base-arabert-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- BioBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- DistilBERT-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- bert-base-multilingual-cased-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "- XLM-RoBERTa-Severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "\n",
      "Ensemble prediction (soft voting): ØºÙŠØ± Ø­Ø±Ø¬\n",
      "True severity: ØºÙŠØ± Ø­Ø±Ø¬\n",
      "Correct: True\n",
      "================================================================================\n",
      "\n",
      "âœ… All severity predictions saved to 'ensemble_individual_prediction_severity.csv'.\n",
      "\n",
      "âœ… Model accuracy results saved to 'model_accuracies_severity.csv'.\n",
      "\n",
      "ğŸ”¹ Sample Predictions:\n",
      "                                                Text True_Severity  \\\n",
      "0  \\nÙ‡Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙˆØ§Ø± ÙŠÙˆØ±ÙˆØ³ÙˆÙ„ÙÙŠÙ† ÙŠØ¤Ø«Ø± Ø¹Ù„ÙŠ Ø§Ø±ØªÙØ§Ø¹ Ø¶...       ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "1  Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† Ù†Ø²ÙŠÙ Ù Ø§Ù„Ø§Ù†Ù Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ø­ÙŠØ§Ù† ØªÙ„Ù‚Ø§Ø¦ÙŠØ§ Ù…Ø§Ù‡Ùˆ...       ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "2  Ø§Ø­Ø³ Ø¨Ù†ØºØ§Ø²Ø§Øª ÙÙŠ Ø§Ù„Ø¬Ù‡Ù‡ Ø§Ù„ÙŠØ³Ø±ÙŠ Ù…Ù† Ø§Ù„ØµØ¯Ø± ÙˆÙ„Ø§ Ø§Ø¹Ø±Ù ...       ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "3  \\nØ¹Ù†Ø¯Ù…Ø§ ÙƒÙ†Øª Ø·ÙÙ„Ø§ ÙƒÙ†Øª Ø£Ø±Ø¶ ÙƒØ«ÙŠØ±Ø§ Ø¨Ù…Ø±Ø¶ Ø§Ù„Ù„ÙˆØ²ØªÙŠÙ† Ù…...           Ø­Ø±Ø¬   \n",
      "4                           Ø§Ø¹Ø§Ù†ÙŠ Ù…Ù† Ø³Ù‚ÙˆØ· Ù Ø§Ù„Ù…Ø³ØªÙ‚ÙŠÙ…       ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "\n",
      "  bert-base-arabert-Severity_Prediction BioBERT-Severity_Prediction  \\\n",
      "0                               ØºÙŠØ± Ø­Ø±Ø¬                     ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "1                               ØºÙŠØ± Ø­Ø±Ø¬                     ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "2                               ØºÙŠØ± Ø­Ø±Ø¬                         Ø­Ø±Ø¬   \n",
      "3                                   Ø­Ø±Ø¬                         Ø­Ø±Ø¬   \n",
      "4                               ØºÙŠØ± Ø­Ø±Ø¬                     ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "\n",
      "  DistilBERT-Severity_Prediction  \\\n",
      "0                        ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "1                        ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "2                        ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "3                            Ø­Ø±Ø¬   \n",
      "4                        ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "\n",
      "  bert-base-multilingual-cased-Severity_Prediction  \\\n",
      "0                                          ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "1                                          ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "2                                              Ø­Ø±Ø¬   \n",
      "3                                              Ø­Ø±Ø¬   \n",
      "4                                          ØºÙŠØ± Ø­Ø±Ø¬   \n",
      "\n",
      "  XLM-RoBERTa-Severity_Prediction Ensemble_Prediction  Correct  \n",
      "0                         ØºÙŠØ± Ø­Ø±Ø¬             ØºÙŠØ± Ø­Ø±Ø¬     True  \n",
      "1                         ØºÙŠØ± Ø­Ø±Ø¬             ØºÙŠØ± Ø­Ø±Ø¬     True  \n",
      "2                         ØºÙŠØ± Ø­Ø±Ø¬             ØºÙŠØ± Ø­Ø±Ø¬     True  \n",
      "3                             Ø­Ø±Ø¬                 Ø­Ø±Ø¬     True  \n",
      "4                         ØºÙŠØ± Ø­Ø±Ø¬             ØºÙŠØ± Ø­Ø±Ø¬     True  \n",
      "\n",
      "ğŸ”¹ Model Accuracy Summary:\n",
      "                                   Model  Accuracy\n",
      "0                               Ensemble  0.960768\n",
      "1             bert-base-arabert-Severity  0.940335\n",
      "2                       BioBERT-Severity  0.889266\n",
      "3                    DistilBERT-Severity  0.925708\n",
      "4  bert-base-multilingual-cased-Severity  0.959160\n",
      "5                   XLM-RoBERTa-Severity  0.917389\n",
      "\n",
      "ğŸ”¹ Generating visualizations for research paper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118/2331064987.py:266: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_118/2331064987.py:266: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_118/2331064987.py:266: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_118/2331064987.py:266: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_118/2331064987.py:266: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All visualizations generated and saved in 'visualizations' directory\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import os\n",
    "\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "\n",
    "valid_categories = [\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ù†Ø³Ø§Ø¦ÙŠØ©\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹Ø¶Ù„Ø§Øª ÙˆØ§Ù„Ø¹Ø¸Ø§Ù… Ùˆ Ø§Ù„Ù…ÙØ§ØµÙ„\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ\",\n",
    "    \"Ø§Ù„Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù†Ø³ÙŠØ©\",\n",
    "    \"Ø·Ø¨ Ø§Ù„Ø§Ø³Ù†Ø§Ù†\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨ Ùˆ Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ†\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹ÙŠÙˆÙ†\",\n",
    "    \"Ø§Ù†Ù Ø§Ø°Ù† ÙˆØ­Ù†Ø¬Ø±Ø©\",\n",
    "    \"Ø¬Ø±Ø§Ø­Ø© ØªØ¬Ù…ÙŠÙ„\",\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¯Ù…\"\n",
    "]\n",
    "\n",
    "def load_and_process_test_data(test_path):\n",
    "    test_df = pd.read_excel(test_path)\n",
    "    test_df = test_df[['q_body', 'severity', 'category']]\n",
    "    test_df = test_df[test_df[\"category\"].isin(valid_categories)]\n",
    "    test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    test_df.to_csv(\"shuffled_test_data.csv\", index=False)\n",
    "    print(\"\\nğŸ”¹ Test Dataset Severity Distribution (Shuffled):\")\n",
    "    print(test_df[\"severity\"].value_counts())\n",
    "    return test_df\n",
    "\n",
    "def load_test_data_for_ensemble():\n",
    "    test_df = pd.read_csv(\"shuffled_test_data.csv\")\n",
    "    print(f\"\\nâœ… Loaded shuffled test dataset with {len(test_df)} samples.\")\n",
    "    return test_df\n",
    "\n",
    "class CustomModel(torch.nn.Module):\n",
    "    def __init__(self, base_model, num_labels):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.base_model = base_model \n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(base_model.config.hidden_size, num_labels)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "def load_complete_model(model_path):\n",
    "    base_model = AutoModel.from_pretrained(model_path)\n",
    "    classifier_state = torch.load(f\"{model_path}/classifier_state.pt\", map_location=torch.device('cpu'))\n",
    "    model = CustomModel(base_model, classifier_state['num_labels'])\n",
    "    model.classifier.load_state_dict(classifier_state['classifier_state'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model_paths = [\n",
    "    \"/kaggle/input/ensemble_camelbert/other/default/16/bert-base-arabert-Severity\",\n",
    "    \"/kaggle/input/ensemble_camelbert/other/default/16/BioBERT-Severity\",\n",
    "    \"/kaggle/input/ensemble_camelbert/other/default/16/DistilBERT-Severity\",\n",
    "    \"/kaggle/input/ensemble_camelbert/other/default/16/bert-base-multilingual-cased-Severity\",\n",
    "    \"/kaggle/input/ensemble_camelbert/other/default/16/XLM-RoBERTa-Severity\"\n",
    "]\n",
    "model_names = [path.split('/')[-1] for path in model_paths]\n",
    "\n",
    "models, tokenizers, severity_mappings = [], [], []\n",
    "\n",
    "for path in model_paths:\n",
    "    tokenizers.append(AutoTokenizer.from_pretrained(path))\n",
    "    model = load_complete_model(path)\n",
    "    models.append(model)\n",
    "\n",
    "    with open(f\"{path}/severity_mapping.pkl\", \"rb\") as f:\n",
    "        severity_mapping = pickle.load(f)\n",
    "    severity_mappings.append(severity_mapping)\n",
    "\n",
    "if not all(severity_mappings[0] == mapping for mapping in severity_mappings):\n",
    "    print(\"Warning: Severity mappings are different. Using the first mapping.\")\n",
    "\n",
    "severity_mapping = severity_mappings[0]\n",
    "severity_mapping_reverse = {v: k for k, v in severity_mapping.items()}\n",
    "\n",
    "def get_model_prediction(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "    logits = outputs[\"logits\"].cpu().numpy()\n",
    "    prediction = np.argmax(logits[0])\n",
    "    return severity_mapping_reverse[prediction]\n",
    "\n",
    "def get_ensemble_prediction(text, individual_predictions=None, voting='soft'):\n",
    "    all_logits = []\n",
    "    if individual_predictions is None:\n",
    "        individual_predictions = []\n",
    "\n",
    "    for i, (model, tokenizer) in enumerate(zip(models, tokenizers)):\n",
    "        inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs[\"logits\"].cpu().numpy()\n",
    "        all_logits.append(logits[0])\n",
    "        pred = severity_mapping_reverse[np.argmax(logits[0])]\n",
    "        if i >= len(individual_predictions):\n",
    "            individual_predictions.append(pred)\n",
    "        else:\n",
    "            individual_predictions[i] = pred\n",
    "\n",
    "    if voting == 'hard':\n",
    "        predictions = [np.argmax(logits) for logits in all_logits]\n",
    "        vote_counts = np.bincount(predictions, minlength=len(severity_mapping))\n",
    "        ensemble_prediction = np.argmax(vote_counts)\n",
    "    else:\n",
    "        probs = [np.exp(logits) / np.sum(np.exp(logits)) for logits in all_logits]\n",
    "        avg_probs = np.mean(probs, axis=0)\n",
    "        ensemble_prediction = np.argmax(avg_probs)\n",
    "\n",
    "    return severity_mapping_reverse[ensemble_prediction], individual_predictions\n",
    "\n",
    "def apply_ensemble_on_test_data(print_interval=500):\n",
    "    test_df = load_test_data_for_ensemble()\n",
    "\n",
    "    results_columns = [\n",
    "        \"Text\", \n",
    "        \"True_Severity\"\n",
    "    ] + [f\"{name}_Prediction\" for name in model_names] + [\n",
    "        \"Ensemble_Prediction\",\n",
    "        \"Correct\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    total_samples = len(test_df)\n",
    "\n",
    "    print(f\"\\nğŸ”¹ Running ensemble and individual model predictions on test dataset ({total_samples} samples)...\")\n",
    "\n",
    "    for idx, row in test_df.iterrows():\n",
    "        text, true_severity = row[\"q_body\"], row[\"severity\"]\n",
    "        individual_predictions = []\n",
    "        ensemble_prediction, individual_predictions = get_ensemble_prediction(text, individual_predictions)\n",
    "        \n",
    "        result_row = {\n",
    "            \"Text\": text,\n",
    "            \"True_Severity\": true_severity\n",
    "        }\n",
    "        for i, model_name in enumerate(model_names):\n",
    "            result_row[f\"{model_name}_Prediction\"] = individual_predictions[i]\n",
    "        result_row[\"Ensemble_Prediction\"] = ensemble_prediction\n",
    "        result_row[\"Correct\"] = true_severity == ensemble_prediction\n",
    "        results.append(result_row)\n",
    "\n",
    "        if (idx + 1) % print_interval == 0 or idx == total_samples - 1:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(f\"Processing sample {idx + 1}/{total_samples}\")\n",
    "            print(\"=\"*80)\n",
    "            print(f\"Input text: {text}\\n\")\n",
    "            print(\"Individual model predictions:\")\n",
    "            for i, model_name in enumerate(model_names):\n",
    "                print(f\"- {model_name}: {individual_predictions[i]}\")\n",
    "            print(\"\\nEnsemble prediction (soft voting):\", ensemble_prediction)\n",
    "            print(\"True severity:\", true_severity)\n",
    "            print(\"Correct:\", true_severity == ensemble_prediction)\n",
    "            print(\"=\"*80)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(\"ensemble_individual_prediction_severity.csv\", index=False)\n",
    "    print(\"\\nâœ… All severity predictions saved to 'ensemble_individual_prediction_severity.csv'.\")\n",
    "\n",
    "    accuracy_results = {\n",
    "        \"Model\": [\"Ensemble\"] + model_names,\n",
    "        \"Accuracy\": [\n",
    "            (results_df[\"True_Severity\"] == results_df[\"Ensemble_Prediction\"]).mean()\n",
    "        ]\n",
    "    }\n",
    "    for model_name in model_names:\n",
    "        accuracy = (results_df[\"True_Severity\"] == results_df[f\"{model_name}_Prediction\"]).mean()\n",
    "        accuracy_results[\"Accuracy\"].append(accuracy)\n",
    "    \n",
    "    accuracy_df = pd.DataFrame(accuracy_results)\n",
    "    accuracy_df.to_csv(\"model_accuracies_severity.csv\", index=False)\n",
    "    print(\"\\nâœ… Model accuracy results saved to 'model_accuracies_severity.csv'.\")\n",
    "\n",
    "    # Print sample results\n",
    "    print(\"\\nğŸ”¹ Sample Predictions:\")\n",
    "    print(results_df.head())\n",
    "\n",
    "    # Print accuracy summary\n",
    "    print(\"\\nğŸ”¹ Model Accuracy Summary:\")\n",
    "    print(accuracy_df)\n",
    "\n",
    "\n",
    "\n",
    "    generate_visualizations(results_df)\n",
    "\n",
    "def generate_visualizations(results_df):\n",
    "    \"\"\"\n",
    "    Generate and save visualizations for research paper\n",
    "    \n",
    "    Parameters:\n",
    "    - results_df: DataFrame containing all predictions\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ”¹ Generating visualizations for research paper...\")\n",
    "\n",
    "    generate_confusion_matrices(results_df)\n",
    "\n",
    "    generate_accuracy_comparison(results_df)\n",
    "\n",
    "    generate_severity_performance(results_df)\n",
    "\n",
    "    generate_model_agreement_heatmap(results_df)\n",
    "\n",
    "    generate_ensemble_improvement_chart(results_df)\n",
    "\n",
    "    print(\"\\nâœ… All visualizations generated and saved in 'visualizations' directory\")\n",
    "\n",
    "\n",
    "def generate_confusion_matrices(results_df):\n",
    "    \"\"\"Generate and save confusion matrices for each model and the ensemble\"\"\"\n",
    "    models_to_plot = model_names + [\"Ensemble\"]\n",
    "    num_models = len(models_to_plot)\n",
    "    rows = (num_models + 1) // 2\n",
    "\n",
    "    plt.figure(figsize=(20, 4 * rows))\n",
    "\n",
    "    for i, model_name in enumerate(models_to_plot):\n",
    "        plt.subplot(rows, 2, i + 1)\n",
    "\n",
    "        if model_name == \"Ensemble\":\n",
    "            y_true = results_df[\"True_Severity\"]\n",
    "            y_pred = results_df[\"Ensemble_Prediction\"]\n",
    "        else:\n",
    "            y_true = results_df[\"True_Severity\"]\n",
    "            y_pred = results_df[f\"{model_name}_Prediction\"]\n",
    "\n",
    "        labels = sorted(results_df[\"True_Severity\"].unique())\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "        plt.title(f\"{model_name} - Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.yticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"visualizations/confusion_matrices_all.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    for model_name in models_to_plot:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "\n",
    "        if model_name == \"Ensemble\":\n",
    "            y_true = results_df[\"True_Severity\"]\n",
    "            y_pred = results_df[\"Ensemble_Prediction\"]\n",
    "        else:\n",
    "            y_true = results_df[\"True_Severity\"]\n",
    "            y_pred = results_df[f\"{model_name}_Prediction\"]\n",
    "\n",
    "        labels = sorted(results_df[\"True_Severity\"].unique())\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "        plt.title(f\"{model_name} Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.yticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig(f\"visualizations/confusion_matrix_{model_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def generate_accuracy_comparison(results_df):\n",
    "    \"\"\"Generate bar chart comparing accuracy of all models\"\"\"\n",
    "    accuracies = []\n",
    "    model_labels = []\n",
    "\n",
    "    for model_name in model_names:\n",
    "        accuracy = (results_df[\"True_Severity\"] == results_df[f\"{model_name}_Prediction\"]).mean()\n",
    "        accuracies.append(accuracy)\n",
    "        model_labels.append(model_name)\n",
    "\n",
    "    ensemble_accuracy = (results_df[\"True_Severity\"] == results_df[\"Ensemble_Prediction\"]).mean()\n",
    "    accuracies.append(ensemble_accuracy)\n",
    "    model_labels.append(\"Ensemble\")\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.bar(model_labels, accuracies, color=['skyblue'] * len(model_names) + ['darkblue'])\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2., height + 0.01, f'{height:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    plt.title(\"Model Accuracy Comparison\", fontsize=16)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "    plt.xlabel(\"Model\", fontsize=14)\n",
    "    plt.ylim(0, max(accuracies) * 1.15)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"visualizations/accuracy_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def generate_severity_performance(results_df):\n",
    "    \"\"\"Generate per-severity performance chart for all models\"\"\"\n",
    "    performance = {}\n",
    "\n",
    "    valid_severities = sorted(results_df[\"True_Severity\"].unique())\n",
    "    for severity in valid_severities:\n",
    "        performance[severity] = {}\n",
    "\n",
    "    all_models = model_names + [\"Ensemble\"]\n",
    "    for model_name in all_models:\n",
    "        for severity in valid_severities:\n",
    "            mask = results_df[\"True_Severity\"] == severity\n",
    "            if model_name == \"Ensemble\":\n",
    "                correct = results_df.loc[mask, \"Ensemble_Prediction\"] == severity\n",
    "            else:\n",
    "                correct = results_df.loc[mask, f\"{model_name}_Prediction\"] == severity\n",
    "\n",
    "            accuracy = correct.sum() / sum(mask) if sum(mask) > 0 else 0\n",
    "            performance[severity][model_name] = accuracy\n",
    "\n",
    "    severity_df = pd.DataFrame(performance).T\n",
    "\n",
    "    severity_df.plot(kind='bar', figsize=(15, 10))\n",
    "    plt.title(\"Model Performance by Severity\", fontsize=16)\n",
    "    plt.xlabel(\"Severity\", fontsize=14)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.legend(title=\"Model\", loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"visualizations/severity_performance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    severity_df.to_csv(\"visualizations/severity_performance.csv\")\n",
    "\n",
    "\n",
    "def generate_model_agreement_heatmap(results_df):\n",
    "    \"\"\"Generate heatmap showing agreement between models\"\"\"\n",
    "    agreement_matrix = {}\n",
    "\n",
    "    all_models = model_names + [\"Ensemble\"]\n",
    "    for model1 in all_models:\n",
    "        agreement_matrix[model1] = {}\n",
    "        for model2 in all_models:\n",
    "            pred1 = results_df[f\"{model1}_Prediction\"] if model1 != \"Ensemble\" else results_df[\"Ensemble_Prediction\"]\n",
    "            pred2 = results_df[f\"{model2}_Prediction\"] if model2 != \"Ensemble\" else results_df[\"Ensemble_Prediction\"]\n",
    "            agreement_matrix[model1][model2] = np.mean(pred1 == pred2)\n",
    "\n",
    "    agreement_df = pd.DataFrame(agreement_matrix)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(agreement_df, annot=True, fmt=\".3f\", cmap=\"YlGnBu\", vmin=0, vmax=1)\n",
    "    plt.title(\"Model Agreement Heatmap\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"visualizations/model_agreement.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def generate_ensemble_improvement_chart(results_df):\n",
    "    \"\"\"Generate chart showing where ensemble improves over individual models\"\"\"\n",
    "    improvements = {}\n",
    "\n",
    "    for model_name in model_names:\n",
    "        ensemble_correct = results_df[\"True_Severity\"] == results_df[\"Ensemble_Prediction\"]\n",
    "        model_wrong = results_df[\"True_Severity\"] != results_df[f\"{model_name}_Prediction\"]\n",
    "        improvements[model_name] = (ensemble_correct & model_wrong).sum()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(improvements.keys(), improvements.values(), color='green')\n",
    "    plt.title(\"Cases Where Ensemble Corrects Individual Model Errors\", fontsize=16)\n",
    "    plt.ylabel(\"Number of Improvements\", fontsize=14)\n",
    "    plt.xlabel(\"Base Model\", fontsize=14)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    for i, (model, count) in enumerate(improvements.items()):\n",
    "        plt.text(i, count + 2, str(count), ha='center', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/ensemble_improvements.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    total_samples = len(results_df)\n",
    "    improvement_df = pd.DataFrame({\n",
    "        'Model': list(improvements.keys()),\n",
    "        'Improvement_Count': list(improvements.values()),\n",
    "        'Improvement_Percentage': [count / total_samples * 100 for count in improvements.values()]\n",
    "    })\n",
    "    improvement_df.to_csv(\"visualizations/ensemble_improvement_stats.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_path = \"/kaggle/input/maqa-unbalanced-with-severity/MAQA_Severity_Test.xlsx\"\n",
    "\n",
    "    test_df = load_and_process_test_data(test_path)\n",
    "\n",
    "    apply_ensemble_on_test_data(print_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-06-18T23:40:08.428977Z",
     "iopub.status.busy": "2025-06-18T23:40:08.428622Z",
     "iopub.status.idle": "2025-06-18T23:40:09.320087Z",
     "shell.execute_reply": "2025-06-18T23:40:09.319423Z",
     "shell.execute_reply.started": "2025-06-18T23:40:08.428954Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ Creating zip file: ensemble_results_20250618_234008.zip\n",
      "  âœ… Added directory: visualizations and its contents\n",
      "  âŒ Item not found: ensemble_individual_prediction.csv\n",
      "  âŒ Item not found: model_accuracies.csv\n",
      "  âœ… Added file: shuffled_test_data.csv\n",
      "âœ… Zip file created successfully: ensemble_results_20250618_234008.zip (3.74 MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <a href=\"./files/ensemble_results_20250618_234008.zip\" download=\"ensemble_results_20250618_234008.zip\" \n",
       "           style=\"display: inline-block; padding: 10px 15px; \n",
       "                  background-color: #4CAF50; color: white; \n",
       "                  text-align: center; text-decoration: none; \n",
       "                  font-size: 16px; border-radius: 5px;\">\n",
       "           Download Results (3.74 MB)\n",
       "        </a>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import IPython.display\n",
    "from datetime import datetime\n",
    "\n",
    "def create_zip_and_download_link():\n",
    "    \"\"\"\n",
    "    Compresses all generated files and folders into a single zip file\n",
    "    and creates a download link.\n",
    "    \n",
    "    Returns:\n",
    "        IPython.display.HTML: HTML download link for the zip file\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    zip_filename = f\"ensemble_results_{timestamp}.zip\"\n",
    "    \n",
    "    items_to_zip = [\n",
    "        \"visualizations\",  \n",
    "        \"ensemble_individual_prediction.csv\",\n",
    "        \"model_accuracies.csv\",\n",
    "        \"shuffled_test_data.csv\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"ğŸ”¹ Creating zip file: {zip_filename}\")\n",
    "    \n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for item in items_to_zip:\n",
    "            if os.path.isfile(item):\n",
    "                zipf.write(item)\n",
    "                print(f\"  âœ… Added file: {item}\")\n",
    "            elif os.path.isdir(item):\n",
    "                for root, _, files in os.walk(item):\n",
    "                    for file in files:\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        \n",
    "                        zipf.write(file_path)\n",
    "                print(f\"  âœ… Added directory: {item} and its contents\")\n",
    "            else:\n",
    "                print(f\"  âŒ Item not found: {item}\")\n",
    "    \n",
    "    file_size = os.path.getsize(zip_filename) / (1024 * 1024)  # Size in MB\n",
    "    \n",
    "    print(f\"âœ… Zip file created successfully: {zip_filename} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        from google.colab import files\n",
    "        print(\"ğŸ“¥ Starting download...\")\n",
    "        files.download(zip_filename)\n",
    "        return f\"Download initiated for {zip_filename}\"\n",
    "    else:\n",
    "        html_code = f'''\n",
    "        <a href=\"./files/{zip_filename}\" download=\"{zip_filename}\" \n",
    "           style=\"display: inline-block; padding: 10px 15px; \n",
    "                  background-color: #4CAF50; color: white; \n",
    "                  text-align: center; text-decoration: none; \n",
    "                  font-size: 16px; border-radius: 5px;\">\n",
    "           Download Results ({file_size:.2f} MB)\n",
    "        </a>\n",
    "        '''\n",
    "        return IPython.display.HTML(html_code)\n",
    "\n",
    "download_link = create_zip_and_download_link()\n",
    "display(download_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-06-18T23:47:53.024890Z",
     "iopub.status.busy": "2025-06-18T23:47:53.024587Z",
     "iopub.status.idle": "2025-06-18T23:50:58.900245Z",
     "shell.execute_reply": "2025-06-18T23:50:58.899469Z",
     "shell.execute_reply.started": "2025-06-18T23:47:53.024865Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ Reshaping Arabic text in CSV files...\n",
      "  âœ… Reshaped Arabic text in: shuffled_test_data.csv\n",
      "ğŸ”¹ Creating zip file: arabic_ensemble_results_20250618_234753.zip\n",
      "  âœ… Added directory: visualizations and its contents\n",
      "  âš ï¸ Item not found (skipped): reshaped_ensemble_individual_prediction.csv\n",
      "  âš ï¸ Item not found (skipped): reshaped_model_accuracies.csv\n",
      "  âœ… Added file: reshaped_shuffled_test_data.csv\n",
      "  âš ï¸ Item not found (skipped): ensemble_individual_prediction.csv\n",
      "  âš ï¸ Item not found (skipped): model_accuracies.csv\n",
      "  âœ… Added file: shuffled_test_data.csv\n",
      "âœ… Zip file created successfully: arabic_ensemble_results_20250618_234753.zip (6.36 MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <a href=\"arabic_ensemble_results_20250618_234753.zip\" download=\"arabic_ensemble_results_20250618_234753.zip\" \n",
       "           style=\"display: inline-block; padding: 10px 15px; \n",
       "                  background-color: #4CAF50; color: white; \n",
       "                  text-align: center; text-decoration: none; \n",
       "                  font-size: 16px; border-radius: 5px;\">\n",
       "           Download Results (6.36 MB)\n",
       "        </a>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import IPython.display\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "\n",
    "def setup_arabic_plots():\n",
    "    \"\"\"Configure matplotlib to properly display Arabic text\"\"\"\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    \n",
    "    print(\"âœ… Matplotlib configured for Arabic text display\")\n",
    "\n",
    "def reshape_arabic_text(text):\n",
    "    \"\"\"\n",
    "    Reshape Arabic text for proper display in matplotlib\n",
    "    \n",
    "    Args:\n",
    "        text (str): Arabic text to reshape\n",
    "        \n",
    "    Returns:\n",
    "        str: Reshaped and reordered text ready for display\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        reshaped_text = arabic_reshaper.reshape(text)\n",
    "        bidi_text = get_display(reshaped_text)\n",
    "        return bidi_text\n",
    "    return text\n",
    "\n",
    "def generate_confusion_matrices_arabic(results_df, valid_categories):\n",
    "    \"\"\"\n",
    "    Generate confusion matrices with correctly displayed Arabic labels\n",
    "    \n",
    "    Args:\n",
    "        results_df (pd.DataFrame): DataFrame with predictions\n",
    "        valid_categories (list): List of category names in Arabic\n",
    "    \"\"\"\n",
    "    setup_arabic_plots()\n",
    "    \n",
    "    reshaped_categories = [reshape_arabic_text(cat) for cat in valid_categories]\n",
    "    \n",
    "    plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    models_to_plot = model_names + [\"Ensemble\"]\n",
    "    num_models = len(models_to_plot)\n",
    "    rows = (num_models + 1) // 2\n",
    "    \n",
    "    for i, model_name in enumerate(models_to_plot):\n",
    "        plt.subplot(rows, 2, i+1)\n",
    "        \n",
    "        if model_name == \"Ensemble\":\n",
    "            y_true = results_df[\"True_Category\"]\n",
    "            y_pred = results_df[\"Ensemble_Prediction\"]\n",
    "        else:\n",
    "            y_true = results_df[\"True_Category\"]\n",
    "            y_pred = results_df[f\"{model_name}_Prediction\"]\n",
    "            \n",
    "        cm = confusion_matrix(y_true, y_pred, labels=valid_categories)\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                   xticklabels=reshaped_categories, \n",
    "                   yticklabels=reshaped_categories)\n",
    "        plt.title(f\"{model_name} Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted Category\")\n",
    "        plt.ylabel(\"True Category\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.yticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(\"visualizations/confusion_matrices.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    \n",
    "    for model_name in models_to_plot:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        if model_name == \"Ensemble\":\n",
    "            y_true = results_df[\"True_Category\"]\n",
    "            y_pred = results_df[\"Ensemble_Prediction\"]\n",
    "        else:\n",
    "            y_true = results_df[\"True_Category\"]\n",
    "            y_pred = results_df[f\"{model_name}_Prediction\"]\n",
    "            \n",
    "        cm = confusion_matrix(y_true, y_pred, labels=valid_categories)\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                   xticklabels=reshaped_categories, \n",
    "                   yticklabels=reshaped_categories)\n",
    "        plt.title(f\"{model_name} Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted Category\")\n",
    "        plt.ylabel(\"True Category\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.yticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(f\"visualizations/confusion_matrix_{model_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "def reshape_dataframe_arabic(df):\n",
    "    \"\"\"\n",
    "    Reshape Arabic text in DataFrames for proper display\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing Arabic text\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with reshaped Arabic text\n",
    "    \"\"\"\n",
    "    reshaped_df = df.copy()\n",
    "    \n",
    "    for col in reshaped_df.columns:\n",
    "        if reshaped_df[col].dtype == 'object':\n",
    "            reshaped_df[col] = reshaped_df[col].apply(reshape_arabic_text)\n",
    "    \n",
    "    return reshaped_df\n",
    "\n",
    "def create_zip_with_arabic_support():\n",
    "    \"\"\"\n",
    "    Compresses all generated files and folders into a zip file and creates a download link.\n",
    "    Ensures Arabic text is properly reshaped in visualizations and CSV files.\n",
    "    \n",
    "    Returns:\n",
    "        IPython.display.HTML: HTML download link for the zip file\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    zip_filename = f\"arabic_ensemble_results_{timestamp}.zip\"\n",
    "    \n",
    "    # First, ensure all CSV files have properly reshaped Arabic text\n",
    "    csv_files = [\n",
    "        \"ensemble_individual_prediction.csv\", \n",
    "        \"model_accuracies.csv\",\n",
    "        \"shuffled_test_data.csv\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ”¹ Reshaping Arabic text in CSV files...\")\n",
    "    for csv_file in csv_files:\n",
    "        if os.path.exists(csv_file):\n",
    "            try:\n",
    "                # Read the CSV\n",
    "                df = pd.read_csv(csv_file)\n",
    "                # Reshape Arabic text\n",
    "                reshaped_df = reshape_dataframe_arabic(df)\n",
    "                # Save with a new name\n",
    "                reshaped_file = f\"reshaped_{csv_file}\"\n",
    "                reshaped_df.to_csv(reshaped_file, index=False, encoding='utf-8-sig')\n",
    "                print(f\"  âœ… Reshaped Arabic text in: {csv_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ Error reshaping {csv_file}: {e}\")\n",
    "    \n",
    "    items_to_zip = [\n",
    "        \"visualizations\",  \n",
    "        \"reshaped_ensemble_individual_prediction.csv\",\n",
    "        \"reshaped_model_accuracies.csv\",\n",
    "        \"reshaped_shuffled_test_data.csv\",\n",
    "        \"ensemble_individual_prediction.csv\", \n",
    "        \"model_accuracies.csv\",\n",
    "        \"shuffled_test_data.csv\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"ğŸ”¹ Creating zip file: {zip_filename}\")\n",
    "    \n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for item in items_to_zip:\n",
    "            if os.path.isfile(item):\n",
    "                zipf.write(item)\n",
    "                print(f\"  âœ… Added file: {item}\")\n",
    "            elif os.path.isdir(item):\n",
    "                for root, _, files in os.walk(item):\n",
    "                    for file in files:\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        arcname = os.path.relpath(file_path)\n",
    "                        zipf.write(file_path, arcname)\n",
    "                print(f\"  âœ… Added directory: {item} and its contents\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸ Item not found (skipped): {item}\")\n",
    "    \n",
    "    file_size = os.path.getsize(zip_filename) / (1024 * 1024) \n",
    "    \n",
    "    print(f\"âœ… Zip file created successfully: {zip_filename} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        # For Google Colab\n",
    "        from google.colab import files\n",
    "        print(\"ğŸ“¥ Starting download...\")\n",
    "        files.download(zip_filename)\n",
    "        return f\"Download initiated for {zip_filename}\"\n",
    "    \n",
    "    elif 'kaggle_web_client' in str(get_ipython()):\n",
    "        # For Kaggle\n",
    "        try:\n",
    "            # Make sure the file is in the output directory\n",
    "            from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "            api = KaggleApi()\n",
    "            api.authenticate()\n",
    "            \n",
    "            print(f\"âœ… File available for download in Kaggle Output tab: {zip_filename}\")\n",
    "            \n",
    "            html_code = f'''\n",
    "            <div style=\"margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;\">\n",
    "                <h3 style=\"margin-top: 0; color: #333;\">Download Instructions</h3>\n",
    "                <p>Your file <strong>{zip_filename}</strong> ({file_size:.2f} MB) has been created.</p>\n",
    "                <p>To download this file:</p>\n",
    "                <ol>\n",
    "                    <li>Go to the <strong>Output</strong> tab above</li>\n",
    "                    <li>Find <strong>{zip_filename}</strong></li>\n",
    "                    <li>Click the download button</li>\n",
    "                </ol>\n",
    "            </div>\n",
    "            '''\n",
    "            return IPython.display.HTML(html_code)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not authenticate with Kaggle API: {e}\")\n",
    "            # Fallback\n",
    "            html_code = f'''\n",
    "            <div style=\"margin: 20px 0;\">\n",
    "                <p>File created: {zip_filename} ({file_size:.2f} MB)</p>\n",
    "                <p>To download, go to the \"Output\" tab in this Kaggle notebook.</p>\n",
    "            </div>\n",
    "            '''\n",
    "            return IPython.display.HTML(html_code)\n",
    "    \n",
    "    else:\n",
    "        # For standard Jupyter environment\n",
    "        html_code = f'''\n",
    "        <a href=\"{zip_filename}\" download=\"{zip_filename}\" \n",
    "           style=\"display: inline-block; padding: 10px 15px; \n",
    "                  background-color: #4CAF50; color: white; \n",
    "                  text-align: center; text-decoration: none; \n",
    "                  font-size: 16px; border-radius: 5px;\">\n",
    "           Download Results ({file_size:.2f} MB)\n",
    "        </a>\n",
    "        '''\n",
    "        return IPython.display.HTML(html_code)\n",
    "\n",
    "# Example usage - add this to your main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Make sure valid_categories is available\n",
    "    valid_categories = [\n",
    "        \"Ø§Ù…Ø±Ø§Ø¶ Ù†Ø³Ø§Ø¦ÙŠØ©\",\n",
    "        \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹Ø¶Ù„Ø§Øª ÙˆØ§Ù„Ø¹Ø¸Ø§Ù… Ùˆ Ø§Ù„Ù…ÙØ§ØµÙ„\",\n",
    "        \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ\",\n",
    "        \"Ø§Ù„Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù†Ø³ÙŠØ©\",\n",
    "        \"Ø·Ø¨ Ø§Ù„Ø§Ø³Ù†Ø§Ù†\",\n",
    "        \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨ Ùˆ Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ†\",\n",
    "        \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹ÙŠÙˆÙ†\",\n",
    "        \"Ø§Ù†Ù Ø§Ø°Ù† ÙˆØ­Ù†Ø¬Ø±Ø©\",\n",
    "        \"Ø¬Ø±Ø§Ø­Ø© ØªØ¬Ù…ÙŠÙ„\",\n",
    "        \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¯Ù…\"\n",
    "    ]\n",
    "    \n",
    "    # Install required packages if not already installed\n",
    "    try:\n",
    "        import arabic_reshaper\n",
    "        import bidi\n",
    "    except ImportError:\n",
    "        print(\"ğŸ”¹ Installing Arabic reshaper packages...\")\n",
    "        !pip install arabic-reshaper python-bidi\n",
    "        import arabic_reshaper\n",
    "        from bidi.algorithm import get_display\n",
    "        print(\"âœ… Arabic reshaper packages installed\")\n",
    "    \n",
    "    # Assuming you've already generated your results_df and visualizations\n",
    "    # Regenerate confusion matrices with Arabic reshaping\n",
    "    # Uncomment and modify as needed:\n",
    "    # results_df = pd.read_csv(\"ensemble_individual_prediction.csv\")\n",
    "    # generate_confusion_matrices_arabic(results_df, valid_categories)\n",
    "    \n",
    "    # Create the zip file with Arabic support and get download link\n",
    "    download_link = create_zip_with_arabic_support()\n",
    "    display(download_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-06-18T23:47:43.877042Z",
     "iopub.status.busy": "2025-06-18T23:47:43.876292Z",
     "iopub.status.idle": "2025-06-18T23:47:51.560929Z",
     "shell.execute_reply": "2025-06-18T23:47:51.560060Z",
     "shell.execute_reply.started": "2025-06-18T23:47:43.877014Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arabic-reshaper\n",
      "  Downloading arabic_reshaper-3.0.0-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: arabic-reshaper\n",
      "Successfully installed arabic-reshaper-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install arabic-reshaper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-06-18T23:51:44.637292Z",
     "iopub.status.busy": "2025-06-18T23:51:44.636982Z",
     "iopub.status.idle": "2025-06-18T23:51:44.670892Z",
     "shell.execute_reply": "2025-06-18T23:51:44.670251Z",
     "shell.execute_reply.started": "2025-06-18T23:51:44.637269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "# Create visualization folder\n",
    "os.makedirs(\"visualizations\", exist_ok=True)\n",
    "\n",
    "# ğŸ”¹ Valid categories\n",
    "valid_categories = [\n",
    "    \"Ø§Ù…Ø±Ø§Ø¶ Ù†Ø³Ø§Ø¦ÙŠØ©\", \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹Ø¶Ù„Ø§Øª ÙˆØ§Ù„Ø¹Ø¸Ø§Ù… Ùˆ Ø§Ù„Ù…ÙØ§ØµÙ„\", \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù‡Ø¶Ù…ÙŠ\",\n",
    "    \"Ø§Ù„Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¬Ù†Ø³ÙŠØ©\", \"Ø·Ø¨ Ø§Ù„Ø§Ø³Ù†Ø§Ù†\", \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ù‚Ù„Ø¨ Ùˆ Ø§Ù„Ø´Ø±Ø§ÙŠÙŠÙ†\", \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹ÙŠÙˆÙ†\",\n",
    "    \"Ø§Ù†Ù Ø§Ø°Ù† ÙˆØ­Ù†Ø¬Ø±Ø©\", \"Ø¬Ø±Ø§Ø­Ø© ØªØ¬Ù…ÙŠÙ„\", \"Ø§Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¯Ù…\"\n",
    "]\n",
    "\n",
    "def load_and_process_test_data(test_path):\n",
    "    test_df = pd.read_excel(test_path)\n",
    "    test_df = test_df[['q_body', 'severity', 'category']]\n",
    "    test_df = test_df[test_df[\"category\"].isin(valid_categories)]\n",
    "    test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    test_df.to_csv(\"shuffled_test_data.csv\", index=False)\n",
    "    print(\"\\nğŸ”¹ Test Dataset Severity Distribution (Shuffled):\")\n",
    "    print(test_df[\"severity\"].value_counts())\n",
    "    return test_df\n",
    "\n",
    "def load_test_data_for_ensemble():\n",
    "    test_df = pd.read_csv(\"shuffled_test_data.csv\")\n",
    "    print(f\"\\nâœ… Loaded shuffled test dataset with {len(test_df)} samples.\")\n",
    "    return test_df\n",
    "\n",
    "class CustomModel(torch.nn.Module):\n",
    "    def __init__(self, base_model, num_labels):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(base_model.config.hidden_size, num_labels)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        loss = self.loss_fn(logits, labels) if labels is not None else None\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "model_paths = [\n",
    "    \"/kaggle/input/ensemblee/other/default/1/AraBert\",\n",
    "    \"/kaggle/input/ensemblee/other/default/1/BioBert (2)\",\n",
    "    \"/kaggle/input/ensemblee/other/default/1/distilBert\",\n",
    "    \"/kaggle/input/ensemblee/other/default/1/multiBert\",\n",
    "    \"/kaggle/input/ensemblee/other/default/1/xlmRoBERTaa\"\n",
    "]\n",
    "model_names = [path.split('/')[-1] for path in model_paths]\n",
    "model_weights = [0.3, 0.25, 0.15, 0.15, 0.15]\n",
    "\n",
    "models, tokenizers, severity_mappings = [], [], []\n",
    "for path in model_paths:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "    tokenizers.append(tokenizer)\n",
    "\n",
    "    base_model = AutoModel.from_pretrained(path)\n",
    "    classifier_state = torch.load(f\"{path}/classifier_state.pt\", map_location=torch.device('cpu'))\n",
    "    model = CustomModel(base_model, classifier_state['num_labels'])\n",
    "    model.classifier.load_state_dict(classifier_state['classifier_state'])\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "    with open(f\"{path}/severity_mapping.pkl\", \"rb\") as f:\n",
    "        severity_mappings.append(pickle.load(f))\n",
    "\n",
    "severity_mapping = severity_mappings[0]\n",
    "severity_mapping_reverse = {v: k for k, v in severity_mapping.items()}\n",
    "\n",
    "def get_ensemble_prediction(text, individual_predictions=None):\n",
    "    all_logits = []\n",
    "    if individual_predictions is None:\n",
    "        individual_predictions = []\n",
    "\n",
    "    for i, (model, tokenizer) in enumerate(zip(models, tokenizers)):\n",
    "        inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        logits = outputs[\"logits\"].cpu().numpy()\n",
    "        all_logits.append(logits[0])\n",
    "        pred = severity_mapping_reverse[np.argmax(logits[0])]\n",
    "        if i >= len(individual_predictions):\n",
    "            individual_predictions.append(pred)\n",
    "        else:\n",
    "            individual_predictions[i] = pred\n",
    "\n",
    "    probs = [np.exp(logits) / np.sum(np.exp(logits)) for logits in all_logits]\n",
    "    weighted_probs = np.sum([w * p for w, p in zip(model_weights, probs)], axis=0)\n",
    "    ensemble_prediction = np.argmax(weighted_probs)\n",
    "\n",
    "    return severity_mapping_reverse[ensemble_prediction], individual_predictions\n",
    "\n",
    "def apply_ensemble_on_test_data(print_interval=500):\n",
    "    test_df = load_test_data_for_ensemble()\n",
    "\n",
    "    results = []\n",
    "    for idx, row in test_df.iterrows():\n",
    "        text, true_severity = row[\"q_body\"], row[\"severity\"]\n",
    "        individual_predictions = []\n",
    "        ensemble_prediction, individual_predictions = get_ensemble_prediction(text, individual_predictions)\n",
    "\n",
    "        result_row = {\n",
    "            \"Text\": text,\n",
    "            \"True_Severity\": true_severity,\n",
    "            \"Ensemble_Prediction\": ensemble_prediction,\n",
    "            \"Correct\": true_severity == ensemble_prediction\n",
    "        }\n",
    "        for i, model_name in enumerate(model_names):\n",
    "            result_row[f\"{model_name}_Prediction\"] = individual_predictions[i]\n",
    "        results.append(result_row)\n",
    "\n",
    "        if (idx + 1) % print_interval == 0 or idx == len(test_df) - 1:\n",
    "            print(f\"Processed {idx + 1}/{len(test_df)}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(\"ensemble_individual_prediction_severity.csv\", index=False)\n",
    "\n",
    "    acc_data = {\n",
    "        \"Model\": [\"Ensemble\"] + model_names,\n",
    "        \"Accuracy\": [(results_df[\"True_Severity\"] == results_df[\"Ensemble_Prediction\"]).mean()]\n",
    "    }\n",
    "    for model_name in model_names:\n",
    "        acc = (results_df[\"True_Severity\"] == results_df[f\"{model_name}_Prediction\"]).mean()\n",
    "        acc_data[\"Accuracy\"].append(acc)\n",
    "\n",
    "    accuracy_df = pd.DataFrame(acc_data)\n",
    "    accuracy_df.to_csv(\"model_accuracies_severity.csv\", index=False)\n",
    "\n",
    "    generate_visualizations(results_df)\n",
    "\n",
    "# ğŸ”¹ Visualization Functions\n",
    "def generate_visualizations(results_df):\n",
    "    print(\"\\nğŸ”¹ Generating visualizations...\")\n",
    "    generate_confusion_matrices(results_df)\n",
    "    generate_accuracy_comparison(results_df)\n",
    "    generate_severity_performance(results_df)\n",
    "    generate_model_agreement_heatmap(results_df)\n",
    "    generate_ensemble_improvement_chart(results_df)\n",
    "    print(\"\\nâœ… All visualizations saved.\")\n",
    "\n",
    "def generate_confusion_matrices(results_df):\n",
    "    models_to_plot = model_names + [\"Ensemble\"]\n",
    "    rows = (len(models_to_plot) + 1) // 2\n",
    "    plt.figure(figsize=(20, 4 * rows))\n",
    "\n",
    "    for i, model_name in enumerate(models_to_plot):\n",
    "        plt.subplot(rows, 2, i + 1)\n",
    "        y_true = results_df[\"True_Severity\"]\n",
    "        y_pred = results_df[\"Ensemble_Prediction\"] if model_name == \"Ensemble\" else results_df[f\"{model_name}_Prediction\"]\n",
    "        labels = sorted(results_df[\"True_Severity\"].unique())\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "        plt.title(f\"{model_name} - Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"visualizations/confusion_matrices_all.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def generate_accuracy_comparison(results_df):\n",
    "    accuracies = []\n",
    "    model_labels = []\n",
    "    for model_name in model_names:\n",
    "        acc = (results_df[\"True_Severity\"] == results_df[f\"{model_name}_Prediction\"]).mean()\n",
    "        accuracies.append(acc)\n",
    "        model_labels.append(model_name)\n",
    "    ensemble_acc = (results_df[\"True_Severity\"] == results_df[\"Ensemble_Prediction\"]).mean()\n",
    "    accuracies.append(ensemble_acc)\n",
    "    model_labels.append(\"Ensemble\")\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.bar(model_labels, accuracies, color=['skyblue'] * len(model_names) + ['darkblue'])\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01, f'{height:.4f}', ha='center', va='bottom')\n",
    "    plt.title(\"Model Accuracy Comparison\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/accuracy_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def generate_severity_performance(results_df):\n",
    "    performance = {}\n",
    "    valid_severities = sorted(results_df[\"True_Severity\"].unique())\n",
    "    for s in valid_severities:\n",
    "        performance[s] = {}\n",
    "\n",
    "    for model_name in model_names + [\"Ensemble\"]:\n",
    "        for s in valid_severities:\n",
    "            mask = results_df[\"True_Severity\"] == s\n",
    "            pred = results_df[\"Ensemble_Prediction\"] if model_name == \"Ensemble\" else results_df[f\"{model_name}_Prediction\"]\n",
    "            acc = (pred[mask] == s).mean()\n",
    "            performance[s][model_name] = acc\n",
    "\n",
    "    df = pd.DataFrame(performance).T\n",
    "    df.plot(kind=\"bar\", figsize=(15, 10))\n",
    "    plt.title(\"Model Performance by Severity\")\n",
    "    plt.xlabel(\"Severity\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/severity_performance.png\", dpi=300)\n",
    "    plt.close()\n",
    "    df.to_csv(\"visualizations/severity_performance.csv\")\n",
    "\n",
    "def generate_model_agreement_heatmap(results_df):\n",
    "    agreement = {}\n",
    "    all_models = model_names + [\"Ensemble\"]\n",
    "    for m1 in all_models:\n",
    "        agreement[m1] = {}\n",
    "        for m2 in all_models:\n",
    "            p1 = results_df[f\"{m1}_Prediction\"] if m1 != \"Ensemble\" else results_df[\"Ensemble_Prediction\"]\n",
    "            p2 = results_df[f\"{m2}_Prediction\"] if m2 != \"Ensemble\" else results_df[\"Ensemble_Prediction\"]\n",
    "            agreement[m1][m2] = (p1 == p2).mean()\n",
    "\n",
    "    df = pd.DataFrame(agreement)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(df, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", vmin=0, vmax=1)\n",
    "    plt.title(\"Model Agreement Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/model_agreement.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def generate_ensemble_improvement_chart(results_df):\n",
    "    improvements = {}\n",
    "    for model_name in model_names:\n",
    "        ensemble_correct = results_df[\"True_Severity\"] == results_df[\"Ensemble_Prediction\"]\n",
    "        model_wrong = results_df[\"True_Severity\"] != results_df[f\"{model_name}_Prediction\"]\n",
    "        improvements[model_name] = (ensemble_correct & model_wrong).sum()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(improvements.keys(), improvements.values(), color='green')\n",
    "    plt.title(\"Ensemble Improvements Over Base Models\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.ylabel(\"Improved Cases\")\n",
    "    for i, (model, val) in enumerate(improvements.items()):\n",
    "        plt.text(i, val + 1, str(val), ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"visualizations/ensemble_improvements.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    total = len(results_df)\n",
    "    pd.DataFrame({\n",
    "        \"Model\": list(improvements.keys()),\n",
    "        \"Improvement_Count\": list(improvements.values()),\n",
    "        \"Improvement_Percentage\": [v / total * 100 for v in improvements.values()]\n",
    "    }).to_csv(\"visualizations/ensemble_improvement_stats.csv\", index=False)\n",
    "\n",
    "# ğŸ”¹ Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    test_path = \"/kaggle/input/maqa-unbalanced-with-severity/MAQA_Severity_Test.xlsx\"\n",
    "    load_and_process_test_data(test_path)\n",
    "    apply_ensemble_on_test_data(print_interval=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7671547,
     "sourceId": 12180580,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 345738,
     "modelInstanceId": 324904,
     "sourceId": 438640,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
