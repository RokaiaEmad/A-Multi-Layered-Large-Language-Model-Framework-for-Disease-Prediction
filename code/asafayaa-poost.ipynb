{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10033022,"sourceType":"datasetVersion","datasetId":6179515},{"sourceId":10043659,"sourceType":"datasetVersion","datasetId":6187325},{"sourceId":10201160,"sourceType":"datasetVersion","datasetId":6303826},{"sourceId":10316648,"sourceType":"datasetVersion","datasetId":6386939},{"sourceId":10321512,"sourceType":"datasetVersion","datasetId":6390488}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install Pytorch\n%pip install \"torch==2.2.2\" tensorboard\n\n# Install Hugging Face libraries\n%pip install  --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:11:24.282485Z","iopub.execute_input":"2024-12-29T13:11:24.282690Z","iopub.status.idle":"2024-12-29T13:13:58.228111Z","shell.execute_reply.started":"2024-12-29T13:11:24.282670Z","shell.execute_reply":"2024-12-29T13:13:58.227178Z"}},"outputs":[{"name":"stdout","text":"Collecting torch==2.2.2\n  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch==2.2.2)\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\nRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (71.0.4)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2) (1.3.0)\nDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m972.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.1+cu121\n    Uninstalling torch-2.4.1+cu121:\n      Successfully uninstalled torch-2.4.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\ntorchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 triton-2.2.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting transformers==4.40.0\n  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting datasets==2.18.0\n  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\nCollecting accelerate==0.29.3\n  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\nCollecting evaluate==0.4.1\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting bitsandbytes==0.43.1\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nCollecting huggingface_hub==0.22.2\n  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\nCollecting trl==0.8.6\n  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\nCollecting peft==0.10.0\n  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (4.66.5)\nRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (18.1.0)\nRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (2.1.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.70.16)\nCollecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0)\n  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.10.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (2.2.2)\nCollecting responses<0.19 (from evaluate==0.4.1)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.22.2) (4.12.2)\nCollecting tyro>=0.5.11 (from trl==0.8.6)\n  Downloading tyro-0.9.5-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3) (12.6.85)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (13.8.1)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.8.6)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (4.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\nDownloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nDownloading tyro-0.9.5-py3-none-any.whl (112 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, fsspec, responses, huggingface_hub, tyro, transformers, bitsandbytes, accelerate, peft, datasets, trl, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.6.1\n    Uninstalling fsspec-2024.6.1:\n      Successfully uninstalled fsspec-2024.6.1\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.2.0\n    Uninstalling datasets-3.2.0:\n      Successfully uninstalled datasets-3.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ndistributed 2024.8.0 requires dask==2024.8.0, but you have dask 2024.12.1 which is incompatible.\ngcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.2.0 which is incompatible.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\ntorchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.29.3 bitsandbytes-0.43.1 datasets-2.18.0 evaluate-0.4.1 fsspec-2024.2.0 huggingface_hub-0.22.2 peft-0.10.0 responses-0.18.0 shtab-1.7.1 transformers-4.40.0 trl-0.8.6 tyro-0.9.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"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\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:13:58.232674Z","iopub.execute_input":"2024-12-29T13:13:58.232920Z","iopub.status.idle":"2024-12-29T13:13:58.747259Z","shell.execute_reply.started":"2024-12-29T13:13:58.232898Z","shell.execute_reply":"2024-12-29T13:13:58.746545Z"}},"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"c26df6b59bfb128917e73bbb00a79ca7e9324a11\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:13:58.748463Z","iopub.execute_input":"2024-12-29T13:13:58.748739Z","iopub.status.idle":"2024-12-29T13:14:07.065965Z","shell.execute_reply.started":"2024-12-29T13:13:58.748715Z","shell.execute_reply":"2024-12-29T13:14:07.065331Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkokyloka2003\u001b[0m (\u001b[33mkokyloka2003-msa\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import os\nimport random\nimport functools\nimport csv\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport evaluate\nimport bitsandbytes as bnb\nimport accelerate\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n\nfrom datasets import Dataset, DatasetDict\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:20.691128Z","iopub.execute_input":"2024-12-29T13:14:20.691382Z","iopub.status.idle":"2024-12-29T13:14:20.695988Z","shell.execute_reply.started":"2024-12-29T13:14:20.691359Z","shell.execute_reply":"2024-12-29T13:14:20.695302Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T06:10:26.362642Z","iopub.execute_input":"2024-12-28T06:10:26.363311Z","iopub.status.idle":"2024-12-28T06:10:29.598772Z","shell.execute_reply.started":"2024-12-28T06:10:26.363281Z","shell.execute_reply":"2024-12-28T06:10:29.597742Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install bitsandbytes accelerate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:07:53.816900Z","iopub.execute_input":"2024-12-14T18:07:53.817173Z","iopub.status.idle":"2024-12-14T18:08:02.272181Z","shell.execute_reply.started":"2024-12-14T18:07:53.817148Z","shell.execute_reply":"2024-12-14T18:08:02.271129Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.85)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"!pip install peft\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T18:08:02.273643Z","iopub.execute_input":"2024-12-14T18:08:02.273986Z","iopub.status.idle":"2024-12-14T18:08:10.721422Z","shell.execute_reply.started":"2024-12-14T18:08:02.273958Z","shell.execute_reply":"2024-12-14T18:08:10.720591Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.10.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.2.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.40.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.29.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.85)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"import csv\nimport pandas as pd\ndf = pd.read_excel(\"/kaggle/input/exceldata/reshaped_output2 (6).xlsx\")\n\n# Slice the first 1951 rows\ndf = df.iloc[:1592]\n\n# Display the DataFrame or its information\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:23.164722Z","iopub.execute_input":"2024-12-29T13:14:23.165010Z","iopub.status.idle":"2024-12-29T13:14:23.555963Z","shell.execute_reply.started":"2024-12-29T13:14:23.164987Z","shell.execute_reply":"2024-12-29T13:14:23.555037Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     Image type                                               Post Severity  \\\n0       Unknown  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...      حرج   \n1       Unknown          يخوان شو الحل مع القولون العصبي مشان الله  غير حرج   \n2       Unknown  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...      حرج   \n3       Unknown  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...  غير حرج   \n4       Unknown  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...  غير حرج   \n...         ...                                                ...      ...   \n1587        NaN                    شعرى وقع من الامام فقط اعمل ايه  غير حرج   \n1588        NaN  لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...  غير حرج   \n1589        NaN  عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...      حرج   \n1590        NaN  بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...  غير حرج   \n1591        NaN                              علاج للاكزيما العصبية      حرج   \n\n                  Diagnosis             Type  \\\n0                 مخ واعصاب        مخ واعصاب   \n1                قولون عصبي            باطنه   \n2             كدمه في الوجه  انف واذن وحنجره   \n3                       ضغط            باطنه   \n4     عدم التركيز و النسيان        مخ واعصاب   \n...                     ...              ...   \n1587            تساقط الشعر   جلديه وتناسليه   \n1588            هالات سوداء   جلديه وتناسليه   \n1589            تساقط الشعر   جلديه وتناسليه   \n1590           اكسده البشره   جلديه وتناسليه   \n1591         اكزيما العصبيه   جلديه وتناسليه   \n\n                                                    NER  \\\n0     ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1                                        ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ   \n2                           \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ   \n3      \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4     \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n...                                                 ...   \n1587                             شعرى وقع من الامام فقط   \n1588       كريم خافي للعيوب كونسيلر طبي للهالات السوداء   \n1589                                        ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ   \n1590                       ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة   \n1591                                    ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ   \n\n                                             Summarised  \\\n0     ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...   \n1                                            ﻗﻮﻟﻮﻥ عصبي   \n2     ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...   \n3     ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...   \n4                 ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة   \n...                                                 ...   \n1587                             شعرى وقع من الامام فقط   \n1588  هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...   \n1589                                        ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ   \n1590                       ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة   \n1591                                    ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ   \n\n                                                 Refine  \\\n0     \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1     قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2     \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3     صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4     \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n...                                                 ...   \n1587                                                NaN   \n1588                                                NaN   \n1589                       \\n\\n تساقط الشعر بدرجة كبيرة   \n1590                                                NaN   \n1591                                                NaN   \n\n                                                 Post.1  \\\n0     السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...   \n1             يخوان شو الحل مع القولون العصبي مشان الله   \n2     لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...   \n3     حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...   \n4     عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...   \n...                                                 ...   \n1587                    شعرى وقع من الامام فقط اعمل ايه   \n1588  لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...   \n1589  عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...   \n1590  بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...   \n1591                              علاج للاكزيما العصبية   \n\n                                                Refined  \\\n0     \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1     قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2     \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3     صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4     \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n...                                                 ...   \n1587                    شعرى وقع من الامام فقط اعمل ايه   \n1588   لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونس...   \n1589  \\n\\n تساقط الشعر بدرجة كبيرة عندي تساقط الشعر ...   \n1590   بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف ال...   \n1591                              علاج للاكزيما العصبية   \n\n                                               NER_POST  \\\n0     ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1     ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...   \n2      \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...   \n3      \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4     \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n...                                                 ...   \n1587  شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...   \n1588  كريم خافي للعيوب كونسيلر طبي للهالات السوداء ل...   \n1589  ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...   \n1590  ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...   \n1591              ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية   \n\n                                        Summarised_POST  \n0     ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...  \n1     ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...  \n2     ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...  \n3     ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...  \n4     ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...  \n...                                                 ...  \n1587  شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...  \n1588  هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...  \n1589  ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...  \n1590  ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...  \n1591              ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية  \n\n[1592 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image type</th>\n      <th>Post</th>\n      <th>Severity</th>\n      <th>Diagnosis</th>\n      <th>Type</th>\n      <th>NER</th>\n      <th>Summarised</th>\n      <th>Refine</th>\n      <th>Post.1</th>\n      <th>Refined</th>\n      <th>NER_POST</th>\n      <th>Summarised_POST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Unknown</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>حرج</td>\n      <td>مخ واعصاب</td>\n      <td>مخ واعصاب</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unknown</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>غير حرج</td>\n      <td>قولون عصبي</td>\n      <td>باطنه</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Unknown</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>حرج</td>\n      <td>كدمه في الوجه</td>\n      <td>انف واذن وحنجره</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Unknown</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>غير حرج</td>\n      <td>ضغط</td>\n      <td>باطنه</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unknown</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>غير حرج</td>\n      <td>عدم التركيز و النسيان</td>\n      <td>مخ واعصاب</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1587</th>\n      <td>NaN</td>\n      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n      <td>غير حرج</td>\n      <td>تساقط الشعر</td>\n      <td>جلديه وتناسليه</td>\n      <td>شعرى وقع من الامام فقط</td>\n      <td>شعرى وقع من الامام فقط</td>\n      <td>NaN</td>\n      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n      <td>شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...</td>\n      <td>شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...</td>\n    </tr>\n    <tr>\n      <th>1588</th>\n      <td>NaN</td>\n      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...</td>\n      <td>غير حرج</td>\n      <td>هالات سوداء</td>\n      <td>جلديه وتناسليه</td>\n      <td>كريم خافي للعيوب كونسيلر طبي للهالات السوداء</td>\n      <td>هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...</td>\n      <td>NaN</td>\n      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...</td>\n      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونس...</td>\n      <td>كريم خافي للعيوب كونسيلر طبي للهالات السوداء ل...</td>\n      <td>هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...</td>\n    </tr>\n    <tr>\n      <th>1589</th>\n      <td>NaN</td>\n      <td>عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...</td>\n      <td>حرج</td>\n      <td>تساقط الشعر</td>\n      <td>جلديه وتناسليه</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ</td>\n      <td>\\n\\n تساقط الشعر بدرجة كبيرة</td>\n      <td>عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...</td>\n      <td>\\n\\n تساقط الشعر بدرجة كبيرة عندي تساقط الشعر ...</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...</td>\n    </tr>\n    <tr>\n      <th>1590</th>\n      <td>NaN</td>\n      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...</td>\n      <td>غير حرج</td>\n      <td>اكسده البشره</td>\n      <td>جلديه وتناسليه</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة</td>\n      <td>NaN</td>\n      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...</td>\n      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف ال...</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...</td>\n    </tr>\n    <tr>\n      <th>1591</th>\n      <td>NaN</td>\n      <td>علاج للاكزيما العصبية</td>\n      <td>حرج</td>\n      <td>اكزيما العصبيه</td>\n      <td>جلديه وتناسليه</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ</td>\n      <td>NaN</td>\n      <td>علاج للاكزيما العصبية</td>\n      <td>علاج للاكزيما العصبية</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية</td>\n    </tr>\n  </tbody>\n</table>\n<p>1592 rows × 12 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df['Severity'] = df['Severity'].astype('category')\ndf['target'] = df['Severity'].cat.codes\n\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:23.784808Z","iopub.execute_input":"2024-12-29T13:14:23.785052Z","iopub.status.idle":"2024-12-29T13:14:23.799626Z","shell.execute_reply.started":"2024-12-29T13:14:23.785031Z","shell.execute_reply":"2024-12-29T13:14:23.798815Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"  Image type                                               Post Severity  \\\n0    Unknown  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...      حرج   \n1    Unknown          يخوان شو الحل مع القولون العصبي مشان الله  غير حرج   \n2    Unknown  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...      حرج   \n3    Unknown  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...  غير حرج   \n4    Unknown  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...  غير حرج   \n\n               Diagnosis             Type  \\\n0              مخ واعصاب        مخ واعصاب   \n1             قولون عصبي            باطنه   \n2          كدمه في الوجه  انف واذن وحنجره   \n3                    ضغط            باطنه   \n4  عدم التركيز و النسيان        مخ واعصاب   \n\n                                                 NER  \\\n0  ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1                                     ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ   \n2                        \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ   \n3   \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4  \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n\n                                          Summarised  \\\n0  ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...   \n1                                         ﻗﻮﻟﻮﻥ عصبي   \n2  ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...   \n3  ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...   \n4              ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة   \n\n                                              Refine  \\\n0  \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1  قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2  \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3  صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4  \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n\n                                              Post.1  \\\n0  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...   \n1          يخوان شو الحل مع القولون العصبي مشان الله   \n2  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...   \n3  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...   \n4  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...   \n\n                                             Refined  \\\n0  \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1  قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2  \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3  صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4  \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n\n                                            NER_POST  \\\n0  ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1  ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...   \n2   \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...   \n3   \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4  \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n\n                                     Summarised_POST  target  \n0  ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...       0  \n1  ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...       1  \n2  ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...       0  \n3  ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...       1  \n4  ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image type</th>\n      <th>Post</th>\n      <th>Severity</th>\n      <th>Diagnosis</th>\n      <th>Type</th>\n      <th>NER</th>\n      <th>Summarised</th>\n      <th>Refine</th>\n      <th>Post.1</th>\n      <th>Refined</th>\n      <th>NER_POST</th>\n      <th>Summarised_POST</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Unknown</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>حرج</td>\n      <td>مخ واعصاب</td>\n      <td>مخ واعصاب</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unknown</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>غير حرج</td>\n      <td>قولون عصبي</td>\n      <td>باطنه</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Unknown</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>حرج</td>\n      <td>كدمه في الوجه</td>\n      <td>انف واذن وحنجره</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Unknown</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>غير حرج</td>\n      <td>ضغط</td>\n      <td>باطنه</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unknown</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>غير حرج</td>\n      <td>عدم التركيز و النسيان</td>\n      <td>مخ واعصاب</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df['Severity'].cat.categories\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:27.277026Z","iopub.execute_input":"2024-12-29T13:14:27.277453Z","iopub.status.idle":"2024-12-29T13:14:27.284078Z","shell.execute_reply.started":"2024-12-29T13:14:27.277420Z","shell.execute_reply":"2024-12-29T13:14:27.283064Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Index(['حرج', 'غير حرج'], dtype='object')"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"category_map = {code: category for code, category in enumerate(df['Severity'].cat.categories)}\ncategory_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:27.833900Z","iopub.execute_input":"2024-12-29T13:14:27.834194Z","iopub.status.idle":"2024-12-29T13:14:28.774566Z","shell.execute_reply.started":"2024-12-29T13:14:27.834172Z","shell.execute_reply":"2024-12-29T13:14:28.773535Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{0: 'حرج', 1: 'غير حرج'}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"\ntrain_end_point = int(df.shape[0]*0.6)\nval_end_point = int(df.shape[0]*0.8)\ndf_train = df.iloc[:train_end_point,:]\ndf_val = df.iloc[train_end_point:val_end_point,:]\ndf_test = df.iloc[val_end_point:,:]\nprint(df_train.shape, df_test.shape, df_val.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:28.775947Z","iopub.execute_input":"2024-12-29T13:14:28.776341Z","iopub.status.idle":"2024-12-29T13:14:28.789480Z","shell.execute_reply.started":"2024-12-29T13:14:28.776312Z","shell.execute_reply":"2024-12-29T13:14:28.788606Z"}},"outputs":[{"name":"stdout","text":"(955, 13) (319, 13) (318, 13)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Drop 'type', 'severity', and 'age' columns along with 'label'\ndataset_train = Dataset.from_pandas(df_train.drop(['Type', 'Severity','Diagnosis', 'Image type','Refined','NER','Summarised','Refine','Post.1','Summarised_POST','NER_POST'], axis=1))\ndataset_val = Dataset.from_pandas(df_val.drop(['Type', 'Severity','Diagnosis', 'Image type', 'Refined','NER','Summarised','Refine','Post.1','Summarised_POST','NER_POST'], axis=1))\ndataset_test = Dataset.from_pandas(df_test.drop(['Type', 'Severity','Diagnosis', 'Image type', 'Refined','NER','Summarised','Refine','Post.1','Summarised_POST','NER_POST'], axis=1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:28.850722Z","iopub.execute_input":"2024-12-29T13:14:28.850986Z","iopub.status.idle":"2024-12-29T13:14:28.911263Z","shell.execute_reply.started":"2024-12-29T13:14:28.850963Z","shell.execute_reply":"2024-12-29T13:14:28.910183Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"dataset_train_shuffled = dataset_train.shuffle(seed=42)  # Using a seed for reproducibility\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:30.266144Z","iopub.execute_input":"2024-12-29T13:14:30.266494Z","iopub.status.idle":"2024-12-29T13:14:30.282971Z","shell.execute_reply.started":"2024-12-29T13:14:30.266467Z","shell.execute_reply":"2024-12-29T13:14:30.282314Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\n# Combine them into a single DatasetDict\ndataset = DatasetDict({\n    'train': dataset_train_shuffled,\n    'val': dataset_val,\n    'test': dataset_test\n})\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:30.731839Z","iopub.execute_input":"2024-12-29T13:14:30.732107Z","iopub.status.idle":"2024-12-29T13:14:30.737444Z","shell.execute_reply.started":"2024-12-29T13:14:30.732084Z","shell.execute_reply":"2024-12-29T13:14:30.736582Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Post', 'target'],\n        num_rows: 955\n    })\n    val: Dataset({\n        features: ['Post', 'target'],\n        num_rows: 318\n    })\n    test: Dataset({\n        features: ['Post', 'target'],\n        num_rows: 319\n    })\n})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"dataset['train']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:32.432914Z","iopub.execute_input":"2024-12-29T13:14:32.433267Z","iopub.status.idle":"2024-12-29T13:14:32.438236Z","shell.execute_reply.started":"2024-12-29T13:14:32.433208Z","shell.execute_reply":"2024-12-29T13:14:32.437579Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Post', 'target'],\n    num_rows: 955\n})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"print(df_train['Severity'].unique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:32.881468Z","iopub.execute_input":"2024-12-29T13:14:32.881726Z","iopub.status.idle":"2024-12-29T13:14:32.887292Z","shell.execute_reply.started":"2024-12-29T13:14:32.881706Z","shell.execute_reply":"2024-12-29T13:14:32.886422Z"}},"outputs":[{"name":"stdout","text":"['حرج', 'غير حرج']\nCategories (2, object): ['حرج', 'غير حرج']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"df_train.target.value_counts(normalize=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:33.335922Z","iopub.execute_input":"2024-12-29T13:14:33.336214Z","iopub.status.idle":"2024-12-29T13:14:33.346358Z","shell.execute_reply.started":"2024-12-29T13:14:33.336186Z","shell.execute_reply":"2024-12-29T13:14:33.345456Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"target\n1    0.548691\n0    0.451309\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"\nclass_weights=(1/df_train.target.value_counts(normalize=True).sort_index()).tolist()\nclass_weights=torch.tensor(class_weights)\nclass_weights=class_weights/class_weights.sum()\nclass_weights\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:35.271463Z","iopub.execute_input":"2024-12-29T13:14:35.271830Z","iopub.status.idle":"2024-12-29T13:14:35.284418Z","shell.execute_reply.started":"2024-12-29T13:14:35.271798Z","shell.execute_reply":"2024-12-29T13:14:35.283643Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"tensor([0.5487, 0.4513])"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"model_name = \"asafaya/bert-base-arabic\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:35.754965Z","iopub.execute_input":"2024-12-29T13:14:35.755309Z","iopub.status.idle":"2024-12-29T13:14:35.759144Z","shell.execute_reply.started":"2024-12-29T13:14:35.755276Z","shell.execute_reply":"2024-12-29T13:14:35.758345Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enable 4-bit quantization\n    bnb_4bit_quant_type='nf4',  # Quantization type\n    bnb_4bit_use_double_quant=True,  # Double quantization\n    bnb_4bit_compute_dtype=torch.bfloat16  # Compute in bfloat16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:36.188912Z","iopub.execute_input":"2024-12-29T13:14:36.189241Z","iopub.status.idle":"2024-12-29T13:14:36.194444Z","shell.execute_reply.started":"2024-12-29T13:14:36.189191Z","shell.execute_reply":"2024-12-29T13:14:36.193703Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,\n    lora_alpha=8,\n    target_modules=['query', 'key', 'value', 'dense'],  # Simplified layer names\n    lora_dropout=0.05,\n    bias='none',\n    task_type='SEQ_CLS'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:36.618934Z","iopub.execute_input":"2024-12-29T13:14:36.619293Z","iopub.status.idle":"2024-12-29T13:14:36.623469Z","shell.execute_reply.started":"2024-12-29T13:14:36.619246Z","shell.execute_reply":"2024-12-29T13:14:36.622627Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=len(category_map)\n)\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:38.638029Z","iopub.execute_input":"2024-12-29T13:14:38.638385Z","iopub.status.idle":"2024-12-29T13:14:44.980388Z","shell.execute_reply.started":"2024-12-29T13:14:38.638351Z","shell.execute_reply":"2024-12-29T13:14:44.979472Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c38da0b740647b9aec8b15e31247529"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99e3d3bae79445c2819d803a2d2ca6c9"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at asafaya/bert-base-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"PeftModelForSequenceClassification(\n  (base_model): LoraModel(\n    (model): BertForSequenceClassification(\n      (bert): BertModel(\n        (embeddings): BertEmbeddings(\n          (word_embeddings): Embedding(32000, 768, padding_idx=0)\n          (position_embeddings): Embedding(512, 768)\n          (token_type_embeddings): Embedding(2, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): BertEncoder(\n          (layer): ModuleList(\n            (0-11): 12 x BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (key): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (value): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=768, out_features=3072, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=768, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3072, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3072, out_features=768, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3072, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=768, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (pooler): BertPooler(\n          (dense): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.05, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=768, out_features=16, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=16, out_features=768, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n          )\n          (activation): Tanh()\n        )\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n      (classifier): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=768, out_features=2, bias=True)\n        (modules_to_save): ModuleDict(\n          (default): Linear(in_features=768, out_features=2, bias=True)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"!pip install -U bitsandbytes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:44.981811Z","iopub.execute_input":"2024-12-29T13:14:44.982153Z","iopub.status.idle":"2024-12-29T13:14:51.173949Z","shell.execute_reply.started":"2024-12-29T13:14:44.982127Z","shell.execute_reply":"2024-12-29T13:14:51.172907Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\n  Attempting uninstall: bitsandbytes\n    Found existing installation: bitsandbytes 0.43.1\n    Uninstalling bitsandbytes-0.43.1:\n      Successfully uninstalled bitsandbytes-0.43.1\nSuccessfully installed bitsandbytes-0.45.0\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"!pip uninstall bitsandbytes -y\n!pip install bitsandbytes\n!pip install -U accelerate\n!pip install bitsandbytes transformers accelerate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:43:04.563305Z","iopub.execute_input":"2024-12-28T18:43:04.563573Z","iopub.status.idle":"2024-12-28T18:43:17.927240Z","shell.execute_reply.started":"2024-12-28T18:43:04.563551Z","shell.execute_reply":"2024-12-28T18:43:17.926186Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: bitsandbytes 0.45.0\nUninstalling bitsandbytes-0.45.0:\n  Successfully uninstalled bitsandbytes-0.45.0\nCollecting bitsandbytes\n  Using cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\nUsing cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\nInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.0\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\nCollecting accelerate\n  Using cached accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.2)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.85)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nUsing cached accelerate-1.2.1-py3-none-any.whl (336 kB)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.29.3\n    Uninstalling accelerate-0.29.3:\n      Successfully uninstalled accelerate-0.29.3\nSuccessfully installed accelerate-1.2.1\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.85)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}],"execution_count":241},{"cell_type":"code","source":"# Initialize the tokenizer with `add_prefix_space` if necessary for the specific model\ntokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n\n# Assign the `eos_token` to be used as the padding token\nif tokenizer.pad_token is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id  # Use eos_token_id for padding\n    tokenizer.pad_token = tokenizer.eos_token       # Assign eos_token as pad_token\n\n# Update the model configuration to use the tokenizer's pad_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False  # Prevent caching during training for better compatibility\n\n# Resize model embeddings if a new pad_token was added\nif len(tokenizer) != model.config.vocab_size:\n    model.resize_token_embeddings(len(tokenizer))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:51.175610Z","iopub.execute_input":"2024-12-29T13:14:51.175881Z","iopub.status.idle":"2024-12-29T13:14:51.678935Z","shell.execute_reply.started":"2024-12-29T13:14:51.175859Z","shell.execute_reply":"2024-12-29T13:14:51.678249Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08e2a6df884d45298506566f5d95c8cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/334k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118a8186d3e74d54998d31c7f8dc36cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08211c8fe72b4f688e7c5909bb56cbdb"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"batch_size = 4  # You can adjust this based on your system's memory capacity\ntext = df_test['Post'].tolist()\n\n# Initialize an empty list to store the model outputs\nall_outputs = []\n\n# Process the sentences in batches\nfor i in range(0, len(text), batch_size):\n    # Get the batch of sentences\n    batch_sentences = text[i:i + batch_size]\n\n    # Tokenize the batch\n    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n    # Move tensors to the device where the model is (e.g., GPU or CPU)\n    inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n\n    # Perform inference and store the logits\n    with torch.no_grad():\n        outputs = model(**inputs)\n        all_outputs.append(outputs['logits'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:51.679996Z","iopub.execute_input":"2024-12-29T13:14:51.680332Z","iopub.status.idle":"2024-12-29T13:14:55.689553Z","shell.execute_reply.started":"2024-12-29T13:14:51.680305Z","shell.execute_reply":"2024-12-29T13:14:55.688403Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"final_outputs = torch.cat(all_outputs, dim=0)\nfinal_outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:55.690582Z","iopub.execute_input":"2024-12-29T13:14:55.690918Z","iopub.status.idle":"2024-12-29T13:14:55.790716Z","shell.execute_reply.started":"2024-12-29T13:14:55.690881Z","shell.execute_reply":"2024-12-29T13:14:55.789889Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1.6301e-03,  2.0435e-01],\n        [ 2.9344e-02,  1.8921e-01],\n        [-3.4920e-02,  7.6767e-02],\n        [ 1.5204e-01,  4.0093e-02],\n        [-2.3411e-02,  1.7408e-01],\n        [ 3.1962e-01,  1.8694e-01],\n        [ 1.2301e-01,  7.3086e-02],\n        [ 1.6688e-01,  9.6853e-02],\n        [ 1.6522e-02,  1.9202e-01],\n        [ 1.2470e-02,  5.1780e-02],\n        [ 1.5483e-02,  2.1494e-01],\n        [ 8.1894e-02,  1.6469e-01],\n        [-1.1984e-01,  1.0547e-01],\n        [ 4.0777e-02, -4.5961e-02],\n        [ 2.7708e-01,  1.2362e-01],\n        [ 2.6277e-01,  6.4855e-02],\n        [ 3.2298e-01,  1.6593e-01],\n        [ 1.3725e-01,  2.2538e-01],\n        [ 2.3981e-01,  3.3561e-03],\n        [-3.8028e-02,  1.0612e-01],\n        [-1.1339e-01,  8.3482e-02],\n        [-6.5688e-02,  6.7890e-02],\n        [ 8.8417e-02,  2.3033e-01],\n        [ 1.8602e-01,  5.9405e-03],\n        [-2.9519e-02,  1.5062e-01],\n        [ 3.3333e-01,  7.8394e-02],\n        [ 2.8021e-01,  1.1384e-01],\n        [ 1.7198e-01,  3.6931e-02],\n        [ 2.8331e-01,  7.3290e-02],\n        [-4.1255e-02,  2.3190e-01],\n        [ 2.5652e-01,  7.2577e-02],\n        [ 4.0362e-01,  1.1912e-01],\n        [ 2.5180e-01,  6.8960e-02],\n        [ 2.6733e-01,  8.4405e-02],\n        [ 1.1938e-01,  8.9006e-02],\n        [ 2.0990e-01,  5.3943e-02],\n        [ 1.0637e-01,  6.8658e-02],\n        [-2.7497e-02,  1.3623e-01],\n        [ 4.1635e-02,  1.6060e-01],\n        [-4.1933e-02,  2.2717e-01],\n        [ 8.1548e-02,  1.4561e-01],\n        [ 7.3917e-04,  1.5332e-01],\n        [ 6.6636e-02,  7.2810e-02],\n        [ 7.6640e-02,  8.0542e-02],\n        [ 4.3552e-02,  1.5995e-01],\n        [ 7.2627e-02,  2.2625e-01],\n        [ 6.5459e-02,  3.3535e-02],\n        [-1.1076e-01,  1.2082e-01],\n        [ 7.1103e-02,  2.1325e-01],\n        [-3.1093e-02,  2.0269e-01],\n        [ 1.1795e-01,  1.5534e-01],\n        [-4.7338e-02,  1.6258e-02],\n        [-3.2428e-02,  1.4813e-01],\n        [ 9.3932e-03,  1.1636e-01],\n        [ 1.3976e-01,  2.5471e-01],\n        [ 9.4814e-02, -8.1255e-02],\n        [-2.3354e-01,  9.3053e-03],\n        [ 2.1440e-01,  8.7181e-02],\n        [-1.0079e-01,  9.2410e-02],\n        [ 5.7189e-03,  6.5398e-02],\n        [-9.1651e-02,  3.3102e-02],\n        [-5.4918e-02, -1.4339e-03],\n        [ 4.1169e-02,  1.0478e-01],\n        [ 1.5531e-03,  1.9379e-02],\n        [ 2.8838e-01,  5.8672e-02],\n        [ 5.9846e-02,  4.4962e-02],\n        [ 1.2619e-02,  1.1252e-01],\n        [ 1.8571e-01,  1.3279e-02],\n        [-4.6295e-02,  1.2732e-01],\n        [ 2.5523e-01,  2.8436e-02],\n        [ 8.0567e-02,  9.5879e-02],\n        [ 3.4427e-02,  1.7083e-01],\n        [ 1.1537e-02,  2.6668e-01],\n        [-9.1080e-02,  3.1827e-01],\n        [ 3.1559e-01,  6.6092e-02],\n        [ 2.7389e-01,  5.1209e-02],\n        [ 1.8386e-01,  1.1946e-01],\n        [ 2.0859e-01, -2.0750e-03],\n        [ 1.2135e-01,  2.3692e-01],\n        [ 2.9554e-01,  8.2222e-02],\n        [ 1.8273e-01,  1.7733e-01],\n        [-8.0378e-03,  1.4397e-01],\n        [ 7.7291e-02,  1.6875e-01],\n        [ 2.3820e-01, -5.6015e-02],\n        [ 8.2799e-02, -1.4030e-01],\n        [ 7.4484e-02,  3.9674e-02],\n        [ 3.7278e-03,  2.2403e-01],\n        [-3.8515e-02,  1.8635e-01],\n        [ 4.2318e-02,  2.2043e-01],\n        [ 5.7896e-02,  1.8308e-01],\n        [-3.7924e-02,  2.7393e-01],\n        [-1.6122e-03,  2.1243e-01],\n        [ 1.9589e-01,  6.2557e-02],\n        [ 9.4487e-02,  2.6470e-01],\n        [ 1.8058e-01,  9.9958e-02],\n        [ 2.6601e-02,  3.7907e-02],\n        [ 3.1801e-01,  1.0148e-01],\n        [ 6.1332e-02,  1.5093e-01],\n        [ 4.0123e-02,  8.7318e-02],\n        [ 1.1207e-01,  1.7681e-01],\n        [-2.2333e-02,  1.0550e-01],\n        [ 8.4786e-02,  1.3478e-01],\n        [ 7.7892e-02,  1.6959e-01],\n        [-5.7581e-02,  1.3728e-01],\n        [ 2.2921e-01,  9.7198e-02],\n        [-8.1288e-02,  2.0253e-01],\n        [ 1.7420e-01,  6.4122e-02],\n        [ 4.0747e-02,  8.9835e-02],\n        [ 5.4114e-04,  5.3640e-02],\n        [ 2.7751e-01,  3.6712e-02],\n        [ 1.3957e-01,  1.7617e-01],\n        [-1.1002e-01, -4.4376e-02],\n        [ 1.4775e-01,  9.4277e-02],\n        [ 9.2317e-02,  5.2351e-02],\n        [ 4.8705e-02,  4.0486e-02],\n        [ 7.8003e-03,  8.4788e-02],\n        [-1.2209e-02,  1.8612e-01],\n        [ 1.3774e-01, -6.0989e-02],\n        [ 3.3131e-01,  9.1533e-04],\n        [ 2.9811e-01, -1.9196e-02],\n        [ 4.2190e-02,  2.5733e-01],\n        [ 7.7822e-02,  1.8997e-01],\n        [-4.5066e-03,  6.2135e-02],\n        [-5.6927e-02,  1.2206e-01],\n        [-1.3714e-01,  3.2422e-01],\n        [ 2.4060e-01, -4.0553e-03],\n        [ 2.0746e-01,  9.7887e-02],\n        [ 5.9994e-03,  7.3816e-02],\n        [ 4.1544e-02, -1.1496e-01],\n        [ 5.3066e-03,  1.8878e-01],\n        [ 2.5119e-01, -7.0830e-02],\n        [-8.8360e-02,  6.2507e-02],\n        [-1.3413e-01,  1.9798e-01],\n        [ 8.3901e-02,  2.4176e-01],\n        [ 7.4271e-03,  8.1599e-02],\n        [ 8.6524e-02,  3.2714e-02],\n        [-6.9685e-02,  1.0591e-01],\n        [ 3.7989e-01,  1.1500e-02],\n        [ 7.3170e-02,  1.2617e-01],\n        [ 1.7232e-01,  1.1283e-01],\n        [ 1.5850e-01,  3.1718e-02],\n        [ 2.8883e-01, -6.7435e-02],\n        [ 3.3910e-01,  2.7288e-02],\n        [ 3.1616e-02,  1.2622e-01],\n        [ 6.9421e-02,  1.3079e-02],\n        [ 4.5276e-02,  8.1227e-02],\n        [-8.5350e-03,  1.6127e-01],\n        [ 1.8462e-01, -1.8205e-01],\n        [-1.7514e-01,  1.1998e-01],\n        [ 2.1390e-01, -5.2328e-02],\n        [ 2.4150e-01,  7.3102e-02],\n        [-3.3011e-02,  1.2609e-01],\n        [-6.4273e-02,  1.8856e-01],\n        [ 2.9388e-01,  3.4952e-02],\n        [-2.0013e-02,  1.4513e-01],\n        [-5.7387e-02,  9.4134e-02],\n        [ 7.0660e-02,  1.6523e-01],\n        [-5.1544e-02,  1.4819e-01],\n        [ 2.5018e-03,  1.2561e-01],\n        [ 6.7194e-02,  1.5843e-01],\n        [-7.0195e-02,  1.4325e-01],\n        [-1.2270e-02,  1.7090e-01],\n        [ 6.9717e-02,  1.4185e-01],\n        [ 1.1680e-01, -2.5432e-02],\n        [ 1.8462e-01, -1.8205e-01],\n        [-1.7514e-01,  1.1998e-01],\n        [ 1.9917e-01, -9.3620e-02],\n        [ 1.0550e-01,  2.5560e-01],\n        [ 4.0719e-02, -2.9728e-02],\n        [ 2.7701e-01,  6.5323e-02],\n        [ 1.6783e-01, -2.6798e-02],\n        [ 2.4964e-01,  8.5509e-02],\n        [ 2.4982e-02,  2.9663e-02],\n        [ 8.4862e-02, -6.9906e-02],\n        [-2.1813e-02,  1.2272e-01],\n        [ 2.2306e-01, -1.2806e-01],\n        [-1.4316e-03, -1.6851e-01],\n        [ 4.2354e-01,  1.5669e-01],\n        [ 7.8043e-03,  3.9986e-03],\n        [-2.2205e-02,  7.3546e-02],\n        [ 8.2607e-02,  1.7578e-03],\n        [ 1.0569e-01,  1.6031e-01],\n        [ 1.7338e-01, -2.2852e-02],\n        [ 3.1615e-01,  9.5359e-02],\n        [ 2.1494e-01, -1.6027e-01],\n        [ 3.3117e-01,  1.5022e-01],\n        [ 4.2997e-01,  1.3554e-01],\n        [ 1.5871e-01,  1.1360e-01],\n        [ 3.5495e-01, -1.5188e-02],\n        [-1.1667e-02,  6.2477e-02],\n        [ 1.7905e-01, -7.9891e-02],\n        [-6.0921e-02,  4.7154e-02],\n        [ 4.1083e-01, -1.2992e-01],\n        [ 2.7503e-01, -3.7038e-02],\n        [-7.3164e-02,  3.5652e-02],\n        [ 2.8600e-01, -1.1797e-01],\n        [ 1.0028e-01, -7.6200e-02],\n        [ 5.5387e-02, -5.2356e-03],\n        [ 3.7888e-03, -7.2965e-02],\n        [ 1.7679e-01, -5.6667e-02],\n        [ 1.0934e-01, -3.2805e-02],\n        [ 2.1250e-01,  1.2657e-01],\n        [ 6.0759e-02,  1.8048e-01],\n        [ 2.7391e-01, -4.8009e-02],\n        [ 3.3683e-02,  1.2604e-01],\n        [ 1.5472e-01, -4.4164e-02],\n        [ 1.4195e-01,  1.9501e-02],\n        [ 2.4452e-01,  5.0955e-03],\n        [ 2.2409e-01, -4.6280e-02],\n        [ 1.2077e-01,  1.5164e-01],\n        [ 2.3583e-01,  9.5208e-02],\n        [ 1.4063e-01, -3.0484e-03],\n        [ 3.6802e-01,  4.4874e-02],\n        [ 3.6431e-01, -9.7363e-02],\n        [-9.9708e-03,  1.0320e-01],\n        [ 3.4677e-01, -4.4331e-02],\n        [ 3.0658e-01,  1.2692e-01],\n        [ 2.2913e-02, -6.4364e-02],\n        [ 7.7616e-02,  3.1806e-02],\n        [ 2.5215e-01, -1.5398e-02],\n        [ 1.7117e-01,  1.1764e-01],\n        [ 4.0075e-01,  2.9176e-02],\n        [ 7.9545e-03, -3.5673e-02],\n        [ 4.1223e-02,  8.3135e-02],\n        [ 3.8157e-01, -7.2774e-02],\n        [ 2.2173e-01,  9.3526e-02],\n        [ 3.1277e-01,  8.7331e-03],\n        [ 1.6525e-01,  9.2471e-02],\n        [ 3.1487e-01,  1.1713e-01],\n        [ 3.0384e-01,  7.3544e-02],\n        [ 4.1074e-01,  5.6052e-02],\n        [ 6.4889e-02,  4.6312e-02],\n        [ 3.3042e-01,  9.9296e-02],\n        [ 1.1708e-01,  1.0512e-01],\n        [-7.2439e-02,  5.0680e-02],\n        [ 1.8772e-02,  1.6460e-01],\n        [ 2.1718e-01, -1.6470e-02],\n        [ 3.6381e-01,  2.6455e-02],\n        [ 9.4517e-02,  3.6162e-02],\n        [ 1.9978e-01,  6.2874e-02],\n        [ 8.4406e-02,  5.8288e-02],\n        [ 4.4993e-01, -7.7593e-03],\n        [ 1.0425e-01,  5.5171e-02],\n        [-3.0163e-02,  1.2154e-01],\n        [ 1.5399e-01,  1.2873e-01],\n        [ 8.3490e-02,  1.4459e-01],\n        [ 2.0385e-01,  9.6721e-02],\n        [ 1.2656e-01,  1.5149e-01],\n        [ 1.3037e-01,  1.2809e-01],\n        [-1.5791e-01, -6.7785e-02],\n        [ 1.9920e-01, -5.3309e-02],\n        [-6.9479e-02,  1.0501e-02],\n        [ 5.4891e-02,  2.6494e-03],\n        [ 1.6931e-01, -8.9364e-02],\n        [ 2.6960e-01,  5.3402e-02],\n        [ 3.5095e-01, -1.3383e-02],\n        [ 3.6900e-01, -1.2015e-02],\n        [ 1.8141e-01, -3.6003e-02],\n        [ 3.2245e-01,  2.4473e-02],\n        [-1.5096e-01,  1.4260e-01],\n        [ 1.3590e-01,  2.1057e-01],\n        [ 1.9341e-01, -4.8917e-02],\n        [-1.5571e-03,  8.0136e-02],\n        [ 1.2175e-01,  1.2625e-01],\n        [-8.5649e-02,  6.5767e-02],\n        [ 4.0489e-01,  3.2032e-02],\n        [ 7.1169e-02,  1.3745e-01],\n        [ 6.8864e-02, -6.5500e-03],\n        [ 7.6720e-03,  1.3780e-01],\n        [ 2.5873e-01,  6.0000e-02],\n        [ 2.1790e-01, -2.9996e-02],\n        [ 6.5953e-02,  9.2975e-02],\n        [ 2.2265e-01,  1.3817e-01],\n        [ 2.6386e-01, -5.2832e-02],\n        [ 1.8827e-01,  6.7508e-02],\n        [ 1.5651e-01,  1.8411e-01],\n        [-5.0087e-03,  1.0889e-01],\n        [ 2.9242e-01, -6.8653e-02],\n        [ 3.5466e-02,  1.8613e-01],\n        [ 4.3431e-03,  5.4895e-02],\n        [ 6.3788e-02,  8.6708e-05],\n        [ 1.2638e-01,  1.3230e-01],\n        [ 1.7032e-01,  5.7042e-03],\n        [ 4.6378e-01,  2.4890e-02],\n        [ 3.9737e-01,  2.4457e-02],\n        [ 3.4451e-01, -8.5840e-02],\n        [ 1.2649e-01, -6.3170e-02],\n        [-3.3394e-03, -2.3026e-02],\n        [-5.6768e-02,  1.7806e-01],\n        [ 2.1393e-02,  7.4614e-02],\n        [-1.6463e-01, -5.8356e-02],\n        [ 7.5527e-02,  1.5263e-01],\n        [-2.2892e-02, -3.8527e-03],\n        [-2.2252e-02, -1.1895e-01],\n        [-1.7556e-02,  3.4674e-02],\n        [ 3.3705e-01,  7.1340e-02],\n        [ 1.1863e-01, -1.1384e-01],\n        [ 3.7098e-01, -3.0360e-03],\n        [ 1.6636e-01,  8.4886e-02],\n        [ 1.9464e-01, -4.2968e-03],\n        [ 4.8975e-02,  8.7240e-02],\n        [ 3.7375e-02,  9.2791e-02],\n        [ 1.0890e-01,  3.8410e-02],\n        [ 7.9447e-02, -8.5324e-02],\n        [ 7.5076e-02,  3.6159e-02],\n        [ 6.8563e-02, -8.7110e-02],\n        [ 3.0442e-01,  1.2328e-01],\n        [ 4.7521e-01,  1.3988e-02],\n        [ 8.8512e-02, -2.2952e-01],\n        [ 1.4029e-01,  2.1998e-01],\n        [ 2.6079e-01,  4.7719e-02],\n        [ 2.7727e-01,  1.0075e-01],\n        [ 3.3283e-01, -1.2689e-01],\n        [ 3.5826e-01, -3.4221e-03],\n        [ 2.7165e-01, -1.2200e-02],\n        [ 1.7456e-01, -1.3708e-02],\n        [ 2.2724e-01,  5.7924e-02],\n        [-1.0975e-01, -9.5719e-02],\n        [ 3.1149e-02, -2.1970e-03]], device='cuda:0')"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"final_outputs.argmax(axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:55.791594Z","iopub.execute_input":"2024-12-29T13:14:55.791847Z","iopub.status.idle":"2024-12-29T13:14:55.809030Z","shell.execute_reply.started":"2024-12-29T13:14:55.791826Z","shell.execute_reply":"2024-12-29T13:14:55.808311Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n        1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n        1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n        1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n        0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n        0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n        1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n        1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n        0, 0, 0, 0, 0, 1, 0], device='cuda:0')"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"df_test['Severity'].value_counts()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:55.810854Z","iopub.execute_input":"2024-12-29T13:14:55.811072Z","iopub.status.idle":"2024-12-29T13:14:55.819399Z","shell.execute_reply.started":"2024-12-29T13:14:55.811053Z","shell.execute_reply":"2024-12-29T13:14:55.818455Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"Severity\nغير حرج    191\nحرج        128\nName: count, dtype: int64"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\ndf_test['predictions']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:55.820443Z","iopub.execute_input":"2024-12-29T13:14:55.820682Z","iopub.status.idle":"2024-12-29T13:14:55.836001Z","shell.execute_reply.started":"2024-12-29T13:14:55.820660Z","shell.execute_reply":"2024-12-29T13:14:55.835264Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-30-7c1d2547ae19>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"1273    1\n1274    1\n1275    1\n1276    0\n1277    1\n       ..\n1587    0\n1588    0\n1589    0\n1590    1\n1591    0\nName: predictions, Length: 319, dtype: int64"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"def get_performance_metrics(df_test):\n  y_test = df_test.target\n  y_pred = df_test.predictions\n\n  print(\"Confusion Matrix:\")\n  print(confusion_matrix(y_test, y_pred))\n\n  print(\"\\nClassification Report:\")\n  print(classification_report(y_test, y_pred))\n\n  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:55.836964Z","iopub.execute_input":"2024-12-29T13:14:55.837301Z","iopub.status.idle":"2024-12-29T13:14:55.847406Z","shell.execute_reply.started":"2024-12-29T13:14:55.837268Z","shell.execute_reply":"2024-12-29T13:14:55.846677Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"get_performance_metrics(df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:14:55.848181Z","iopub.execute_input":"2024-12-29T13:14:55.848511Z","iopub.status.idle":"2024-12-29T13:14:55.879296Z","shell.execute_reply.started":"2024-12-29T13:14:55.848477Z","shell.execute_reply":"2024-12-29T13:14:55.878676Z"}},"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[ 61  67]\n [115  76]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.35      0.48      0.40       128\n           1       0.53      0.40      0.46       191\n\n    accuracy                           0.43       319\n   macro avg       0.44      0.44      0.43       319\nweighted avg       0.46      0.43      0.43       319\n\nBalanced Accuracy Score: 0.4372341295811518\nAccuracy Score: 0.42946708463949845\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"MAX_LEN = 512\ncol_to_delete = ['Post']\n\ndef llama_preprocessing_function(examples):\n    return tokenizer(examples['Post'], truncation=True, max_length=MAX_LEN)\n\ntokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\ntokenized_datasets = tokenized_datasets.rename_column(\"target\", \"label\")\ntokenized_datasets.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:15:05.274195Z","iopub.execute_input":"2024-12-29T13:15:05.274531Z","iopub.status.idle":"2024-12-29T13:15:05.568261Z","shell.execute_reply.started":"2024-12-29T13:15:05.274503Z","shell.execute_reply":"2024-12-29T13:15:05.567308Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/955 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01c7c84ad4944a5eb3993f5b77448b1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/318 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e1e6b4442049219a83910f733132c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a91e966bd6447c88275fd9030954b6e"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:15:05.857991Z","iopub.execute_input":"2024-12-29T13:15:05.858323Z","iopub.status.idle":"2024-12-29T13:15:05.861889Z","shell.execute_reply.started":"2024-12-29T13:15:05.858290Z","shell.execute_reply":"2024-12-29T13:15:05.861096Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:15:06.421159Z","iopub.execute_input":"2024-12-29T13:15:06.421561Z","iopub.status.idle":"2024-12-29T13:15:06.425838Z","shell.execute_reply.started":"2024-12-29T13:15:06.421528Z","shell.execute_reply":"2024-12-29T13:15:06.424741Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"class CustomTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Ensure label_weights is a tensor\n        if class_weights is not None:\n            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n        else:\n            self.class_weights = None\n\n        # Initialize an empty list to store epoch results\n        self.epoch_logs = []\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        # Extract labels and convert them to long type for cross_entropy\n        labels = inputs.pop(\"labels\").long()\n\n        # Forward pass\n        outputs = model(**inputs)\n\n        # Extract logits assuming they are directly outputted by the model\n        logits = outputs.get('logits')\n\n        # Compute custom loss with class weights for imbalanced data handling\n        if self.class_weights is not None:\n            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n        else:\n            loss = F.cross_entropy(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss\n\n    def log_metrics(self, metrics, epoch):\n        # Custom function to log and save metrics\n        print(f\"Epoch {epoch}: {metrics}\")  # Print metrics\n        self.epoch_logs.append(metrics)  # Store the results\n\n    def training_epoch_end(self, outputs):\n        # Overriding to log after each epoch\n        metrics = self.evaluate()  # Evaluate after each epoch\n        self.log_metrics(metrics, epoch=len(self.epoch_logs))  # Log metrics\n\n# Setup the trainer with your model and datasets\n\n\n# Save the logged epoch results to a CSV file\nimport csv\n\nwith open(\"epoch_results.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerow([\"epoch\", \"metric_name\", \"value\"])  # Define your columns\n    for epoch, metrics in enumerate(trainer.epoch_logs):\n        for key, value in metrics.items():\n            writer.writerow([epoch + 1, key, value])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:15:22.013554Z","iopub.execute_input":"2024-12-29T13:15:22.013870Z","iopub.status.idle":"2024-12-29T13:15:22.022353Z","shell.execute_reply.started":"2024-12-29T13:15:22.013845Z","shell.execute_reply":"2024-12-29T13:15:22.021549Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='sentiment_classification',\n    logging_dir='./logs',  # Directory to save logs\n    logging_steps=10,  # Adjust the frequency of logging steps\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    num_train_epochs=25,\n    learning_rate=1e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:15:12.542070Z","iopub.execute_input":"2024-12-29T13:15:12.542435Z","iopub.status.idle":"2024-12-29T13:15:12.579964Z","shell.execute_reply.started":"2024-12-29T13:15:12.542403Z","shell.execute_reply":"2024-12-29T13:15:12.579321Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"\ntrainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = tokenized_datasets['train'],\n    eval_dataset = tokenized_datasets['val'],\n    tokenizer = tokenizer,\n    data_collator = collate_fn,\n    compute_metrics = compute_metrics,\n    class_weights=class_weights,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:15:18.669293Z","iopub.execute_input":"2024-12-29T13:15:18.669715Z","iopub.status.idle":"2024-12-29T13:15:18.802091Z","shell.execute_reply.started":"2024-12-29T13:15:18.669677Z","shell.execute_reply":"2024-12-29T13:15:18.801283Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-38-c8295c069935>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"from accelerate import Accelerator\n\naccelerator = Accelerator()\nprint(accelerator.state)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:15:24.832548Z","iopub.execute_input":"2024-12-29T13:15:24.832886Z","iopub.status.idle":"2024-12-29T13:15:24.839814Z","shell.execute_reply.started":"2024-12-29T13:15:24.832863Z","shell.execute_reply":"2024-12-29T13:15:24.838733Z"}},"outputs":[{"name":"stdout","text":"Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n\nMixed precision type: no\n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"train_result = trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:15:25.350422Z","iopub.execute_input":"2024-12-29T13:15:25.350763Z","iopub.status.idle":"2024-12-29T13:35:00.445793Z","shell.execute_reply.started":"2024-12-29T13:15:25.350730Z","shell.execute_reply":"2024-12-29T13:35:00.445116Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241229_131525-j654zr52</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/kokyloka2003-msa/huggingface/runs/j654zr52' target=\"_blank\">deep-fire-33</a></strong> to <a href='https://wandb.ai/kokyloka2003-msa/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/kokyloka2003-msa/huggingface' target=\"_blank\">https://wandb.ai/kokyloka2003-msa/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/kokyloka2003-msa/huggingface/runs/j654zr52' target=\"_blank\">https://wandb.ai/kokyloka2003-msa/huggingface/runs/j654zr52</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 19:26, Epoch 25/25]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Balanced Accuracy</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.697400</td>\n      <td>0.683661</td>\n      <td>0.598120</td>\n      <td>0.512579</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.686500</td>\n      <td>0.681184</td>\n      <td>0.625579</td>\n      <td>0.547170</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.673600</td>\n      <td>0.668295</td>\n      <td>0.590839</td>\n      <td>0.578616</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.648000</td>\n      <td>0.665495</td>\n      <td>0.590944</td>\n      <td>0.594340</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.631100</td>\n      <td>0.650581</td>\n      <td>0.600364</td>\n      <td>0.603774</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.628400</td>\n      <td>0.649795</td>\n      <td>0.646984</td>\n      <td>0.644654</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.673600</td>\n      <td>0.649137</td>\n      <td>0.650052</td>\n      <td>0.625786</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.570400</td>\n      <td>0.691606</td>\n      <td>0.644476</td>\n      <td>0.591195</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.576600</td>\n      <td>0.662304</td>\n      <td>0.663766</td>\n      <td>0.663522</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.456600</td>\n      <td>0.697328</td>\n      <td>0.626653</td>\n      <td>0.628931</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.463400</td>\n      <td>0.721754</td>\n      <td>0.631867</td>\n      <td>0.619497</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.458300</td>\n      <td>0.774190</td>\n      <td>0.628030</td>\n      <td>0.616352</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.430900</td>\n      <td>0.790003</td>\n      <td>0.632928</td>\n      <td>0.635220</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.408000</td>\n      <td>0.849615</td>\n      <td>0.622190</td>\n      <td>0.616352</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.358700</td>\n      <td>0.932468</td>\n      <td>0.622405</td>\n      <td>0.622642</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.345400</td>\n      <td>0.915803</td>\n      <td>0.615025</td>\n      <td>0.610063</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.314600</td>\n      <td>0.989534</td>\n      <td>0.613913</td>\n      <td>0.616352</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.278900</td>\n      <td>1.084918</td>\n      <td>0.604532</td>\n      <td>0.606918</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.239400</td>\n      <td>1.129660</td>\n      <td>0.604809</td>\n      <td>0.606918</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.258600</td>\n      <td>1.147955</td>\n      <td>0.623159</td>\n      <td>0.625786</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.280500</td>\n      <td>1.172945</td>\n      <td>0.610863</td>\n      <td>0.613208</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.199800</td>\n      <td>1.197873</td>\n      <td>0.605461</td>\n      <td>0.606918</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.219800</td>\n      <td>1.220327</td>\n      <td>0.611129</td>\n      <td>0.613208</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.187500</td>\n      <td>1.230611</td>\n      <td>0.620251</td>\n      <td>0.622642</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.219900</td>\n      <td>1.237691</td>\n      <td>0.616978</td>\n      <td>0.619497</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"metrics = trainer.evaluate(eval_dataset=tokenized_datasets['test'])\nprint(\"Test Set Metrics:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:35:05.146110Z","iopub.execute_input":"2024-12-29T13:35:05.146453Z","iopub.status.idle":"2024-12-29T13:35:09.269353Z","shell.execute_reply.started":"2024-12-29T13:35:05.146424Z","shell.execute_reply":"2024-12-29T13:35:09.268638Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Test Set Metrics: {'eval_loss': 0.6681362390518188, 'eval_balanced_accuracy': 0.6401771336553945, 'eval_accuracy': 0.6520376175548589, 'eval_runtime': 4.113, 'eval_samples_per_second': 77.559, 'eval_steps_per_second': 4.863, 'epoch': 25.0}\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"df_train['target'].value_counts(normalize=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:35:09.270497Z","iopub.execute_input":"2024-12-29T13:35:09.270826Z","iopub.status.idle":"2024-12-29T13:35:09.278095Z","shell.execute_reply.started":"2024-12-29T13:35:09.270791Z","shell.execute_reply":"2024-12-29T13:35:09.277442Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"target\n1    0.548691\n0    0.451309\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"df_test['target'].value_counts(normalize=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:35:09.279771Z","iopub.execute_input":"2024-12-29T13:35:09.279989Z","iopub.status.idle":"2024-12-29T13:35:09.295771Z","shell.execute_reply.started":"2024-12-29T13:35:09.279969Z","shell.execute_reply":"2024-12-29T13:35:09.295035Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"target\n1    0.598746\n0    0.401254\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"df_val['target'].value_counts(normalize=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:35:09.296687Z","iopub.execute_input":"2024-12-29T13:35:09.296970Z","iopub.status.idle":"2024-12-29T13:35:09.308846Z","shell.execute_reply.started":"2024-12-29T13:35:09.296940Z","shell.execute_reply":"2024-12-29T13:35:09.308121Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"target\n1    0.537736\n0    0.462264\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"def make_predictions(model, df_test):\n\n    # Convert summaries to a list\n    sentences = df_test['Post'].tolist()\n\n    # Define the batch size\n    batch_size = 4  # You can adjust this based on your system's memory capacity\n\n    # Initialize an empty list to store the model outputs\n    all_outputs = []\n\n    # Process the sentences in batches\n    for i in range(0, len(sentences), batch_size):\n        # Get the batch of sentences\n        batch_sentences = sentences[i:i + batch_size]\n\n        # Tokenize the batch\n        inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n        # Move tensors to the device where the model is (e.g., GPU or CPU)\n        inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n\n        # Perform inference and store the logits\n        with torch.no_grad():\n            outputs = model(**inputs)\n            all_outputs.append(outputs['logits'])\n\n    final_outputs = torch.cat(all_outputs, dim=0)\n\n    # Update using .loc to avoid SettingWithCopyWarning\n    df_test.loc[:, 'predictions'] = final_outputs.argmax(axis=1).cpu().numpy()\n\n    # Apply category mapping\n    df_test.loc[:, 'predictions'] = df_test['predictions'].apply(lambda l: category_map[l])\n\n# Make predictions\nmake_predictions(model, df_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:35:09.452067Z","iopub.execute_input":"2024-12-29T13:35:09.452397Z","iopub.status.idle":"2024-12-29T13:35:13.066210Z","shell.execute_reply.started":"2024-12-29T13:35:09.452366Z","shell.execute_reply":"2024-12-29T13:35:13.065198Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def get_performance_metrics(df_test):\n    # Convert both target and predictions back to numeric using category_map\n    reverse_category_map = {v: k for k, v in category_map.items()}  # Reverse the category_map to map strings to numbers\n    y_test = df_test['target']\n    y_pred = df_test['predictions'].apply(lambda x: reverse_category_map[x])\n\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_test, y_pred))\n\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n\n    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n\n# Run the function again\nget_performance_metrics(df_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:35:13.067521Z","iopub.execute_input":"2024-12-29T13:35:13.067839Z","iopub.status.idle":"2024-12-29T13:35:13.089961Z","shell.execute_reply.started":"2024-12-29T13:35:13.067809Z","shell.execute_reply":"2024-12-29T13:35:13.089103Z"}},"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[ 76  52]\n [ 59 132]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.56      0.59      0.58       128\n           1       0.72      0.69      0.70       191\n\n    accuracy                           0.65       319\n   macro avg       0.64      0.64      0.64       319\nweighted avg       0.66      0.65      0.65       319\n\nBalanced Accuracy Score: 0.6424247382198953\nAccuracy Score: 0.6520376175548589\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"import os\n\n# Directory to save the model (inside /kaggle/outputs for persistence)\nsave_directory = \"/kaggle/working/asafayabertPost\"\n\n# Create the directory if it does not exist\nos.makedirs(save_directory, exist_ok=True)\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved successfully to '{save_directory}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:35:27.911095Z","iopub.execute_input":"2024-12-29T13:35:27.911470Z","iopub.status.idle":"2024-12-29T13:35:28.077351Z","shell.execute_reply.started":"2024-12-29T13:35:27.911437Z","shell.execute_reply":"2024-12-29T13:35:28.076596Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved successfully to '/kaggle/working/asafayabertPost'\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"!zip -r asafayabertPost_model.zip /kaggle/working/asafayabertPost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:35:28.869868Z","iopub.execute_input":"2024-12-29T13:35:28.870147Z","iopub.status.idle":"2024-12-29T13:35:29.717640Z","shell.execute_reply.started":"2024-12-29T13:35:28.870124Z","shell.execute_reply":"2024-12-29T13:35:29.716888Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/asafayabertPost/ (stored 0%)\n  adding: kaggle/working/asafayabertPost/vocab.txt (deflated 63%)\n  adding: kaggle/working/asafayabertPost/tokenizer.json","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":" (deflated 73%)\n  adding: kaggle/working/asafayabertPost/adapter_config.json (deflated 52%)\n  adding: kaggle/working/asafayabertPost/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/asafayabertPost/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/asafayabertPost/special_tokens_map.json (deflated 42%)\n  adding: kaggle/working/asafayabertPost/README.md (deflated 66%)\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'asafayabertPost_model.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:35:29.719193Z","iopub.execute_input":"2024-12-29T13:35:29.719488Z","iopub.status.idle":"2024-12-29T13:35:29.725670Z","shell.execute_reply.started":"2024-12-29T13:35:29.719466Z","shell.execute_reply":"2024-12-29T13:35:29.725044Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/asafayabertPost_model.zip","text/html":"<a href='asafayabertPost_model.zip' target='_blank'>asafayabertPost_model.zip</a><br>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}