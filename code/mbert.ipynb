{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8962508,"sourceType":"datasetVersion","datasetId":5394582}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments\nfrom datasets import Dataset\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport logging\nimport pickle\nimport numpy as np\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:24:08.180100Z","iopub.execute_input":"2025-02-24T15:24:08.180366Z","iopub.status.idle":"2025-02-24T15:24:30.094810Z","shell.execute_reply.started":"2025-02-24T15:24:08.180336Z","shell.execute_reply":"2025-02-24T15:24:30.094131Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, base_model, num_labels):  # FIX: Correct __init__ method\n        super(CustomModel, self).__init__()  # FIX: Correct super() call\n        self.base_model = base_model \n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(base_model.config.hidden_size, num_labels)\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n\n        loss = None\n        if labels is not None:\n            loss = self.loss_fn(logits, labels)\n        return {\"loss\": loss, \"logits\": logits}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:24:46.758892Z","iopub.execute_input":"2025-02-24T15:24:46.759308Z","iopub.status.idle":"2025-02-24T15:24:46.767646Z","shell.execute_reply.started":"2025-02-24T15:24:46.759271Z","shell.execute_reply":"2025-02-24T15:24:46.766612Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load data\ntrain_path = \"/kaggle/input/maqa-dataset/Unbalanced/Unbalanced/MAQA_Train.xlsx\"\ntest_path = \"/kaggle/input/maqa-dataset/Unbalanced/Unbalanced/MAQA_Test.xlsx\"\ntrain_df = pd.read_excel(train_path)\ntest_df = pd.read_excel(test_path)\nall_data = pd.concat([train_df, test_df], ignore_index=True)\nall_data = all_data[['q_body', 'category']]\n\nvalid_categories = [\n    \"ÿßŸÖÿ±ÿßÿ∂ ŸÜÿ≥ÿßÿ¶Ÿäÿ©\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿπÿ∂ŸÑÿßÿ™ ŸàÿßŸÑÿπÿ∏ÿßŸÖ Ÿà ÿßŸÑŸÖŸÅÿßÿµŸÑ\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑŸáÿ∂ŸÖŸä\",\n    \"ÿßŸÑÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿ¨ŸÜÿ≥Ÿäÿ©\",\n    \"ÿ∑ÿ® ÿßŸÑÿßÿ≥ŸÜÿßŸÜ\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑŸÇŸÑÿ® Ÿà ÿßŸÑÿ¥ÿ±ÿßŸäŸäŸÜ\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿπŸäŸàŸÜ\",\n    \"ÿßŸÜŸÅ ÿßÿ∞ŸÜ Ÿàÿ≠ŸÜÿ¨ÿ±ÿ©\",\n    \"ÿ¨ÿ±ÿßÿ≠ÿ© ÿ™ÿ¨ŸÖŸäŸÑ\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿØŸÖ\"\n]\n\nall_data = all_data[all_data[\"category\"].isin(valid_categories)]\nall_data = all_data.sample(frac=1, random_state=42).reset_index(drop=True)\ntrain_df, test_df = train_test_split(all_data, test_size=0.2, random_state=42, stratify=all_data['category'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:24:50.236012Z","iopub.execute_input":"2025-02-24T15:24:50.236352Z","iopub.status.idle":"2025-02-24T15:25:21.533639Z","shell.execute_reply.started":"2025-02-24T15:24:50.236328Z","shell.execute_reply":"2025-02-24T15:25:21.532722Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df[\"text\"] = train_df[\"q_body\"]\ntest_df[\"text\"] = test_df[\"q_body\"]\n\ncategory_mapping = {cat: i for i, cat in enumerate(valid_categories)}\ntrain_df['label'] = train_df['category'].map(category_mapping)\ntest_df['label'] = test_df['category'].map(category_mapping)\n\nmodel_name = \"bert-base-multilingual-cased\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_dataset = Dataset.from_dict({\"text\": train_df[\"text\"].tolist(), \"label\": train_df[\"label\"].tolist()})\ntest_dataset = Dataset.from_dict({\"text\": test_df[\"text\"].tolist(), \"label\": test_df[\"label\"].tolist()})\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:25:55.118375Z","iopub.execute_input":"2025-02-24T15:25:55.119025Z","iopub.status.idle":"2025-02-24T15:26:25.898287Z","shell.execute_reply.started":"2025-02-24T15:25:55.118998Z","shell.execute_reply":"2025-02-24T15:26:25.897443Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ac0377433f4fc88200de37c50a199e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"776de6795d09464388a71f25662247ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b339e59ee84585974748d5b5398cb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6835d5bf0e4d49aa9a52777b59685b49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/159143 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b49e6b4df8ba4fe29408b12eaf9e0473"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/39786 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ab56f254d944baa9fceb07682cf0cf4"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"base_model = AutoModel.from_pretrained(model_name)\nmodel = CustomModel(base_model, 10)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    per_device_train_batch_size=96,\n    per_device_eval_batch_size=96,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    learning_rate=3e-5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\"\n)\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n    acc = accuracy_score(labels, predictions)\n    return {\n        \"accuracy\": acc,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1\n    }\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:26:46.881324Z","iopub.execute_input":"2025-02-24T15:26:46.882050Z","iopub.status.idle":"2025-02-24T15:26:52.226104Z","shell.execute_reply.started":"2025-02-24T15:26:46.882017Z","shell.execute_reply":"2025-02-24T15:26:52.225222Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"815e10e3412848d9a65f66b93ebbc979"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n<ipython-input-6-b4ae84f841c3>:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Train\nprint(\"\\nStarting training...\")\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:28:28.802867Z","iopub.execute_input":"2025-02-24T15:28:28.803184Z","iopub.status.idle":"2025-02-24T20:52:31.505325Z","shell.execute_reply.started":"2025-02-24T15:28:28.803161Z","shell.execute_reply":"2025-02-24T20:52:31.504503Z"}},"outputs":[{"name":"stdout","text":"\nStarting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16580' max='16580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16580/16580 5:24:01, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.313600</td>\n      <td>0.305495</td>\n      <td>0.908234</td>\n      <td>0.908522</td>\n      <td>0.908234</td>\n      <td>0.907673</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.256800</td>\n      <td>0.271403</td>\n      <td>0.916101</td>\n      <td>0.915336</td>\n      <td>0.916101</td>\n      <td>0.915218</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.217400</td>\n      <td>0.262756</td>\n      <td>0.920047</td>\n      <td>0.919482</td>\n      <td>0.920047</td>\n      <td>0.919249</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.182200</td>\n      <td>0.260527</td>\n      <td>0.921304</td>\n      <td>0.921504</td>\n      <td>0.921304</td>\n      <td>0.921325</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.149400</td>\n      <td>0.271456</td>\n      <td>0.923968</td>\n      <td>0.923638</td>\n      <td>0.923968</td>\n      <td>0.923421</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.100800</td>\n      <td>0.293499</td>\n      <td>0.925476</td>\n      <td>0.924774</td>\n      <td>0.925476</td>\n      <td>0.924706</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.077600</td>\n      <td>0.315360</td>\n      <td>0.925652</td>\n      <td>0.925248</td>\n      <td>0.925652</td>\n      <td>0.925315</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.076900</td>\n      <td>0.336829</td>\n      <td>0.925401</td>\n      <td>0.925098</td>\n      <td>0.925401</td>\n      <td>0.925149</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.042900</td>\n      <td>0.365252</td>\n      <td>0.926783</td>\n      <td>0.926325</td>\n      <td>0.926783</td>\n      <td>0.926421</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.024500</td>\n      <td>0.377646</td>\n      <td>0.926431</td>\n      <td>0.925893</td>\n      <td>0.926431</td>\n      <td>0.926096</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=16580, training_loss=0.15933053550210446, metrics={'train_runtime': 19441.6522, 'train_samples_per_second': 81.857, 'train_steps_per_second': 0.853, 'total_flos': 0.0, 'train_loss': 0.15933053550210446, 'epoch': 10.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Evaluate\ntrain_metrics = trainer.evaluate(train_dataset)\nprint(\"\\Train Metrics:\", train_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T20:53:04.278656Z","iopub.execute_input":"2025-02-24T20:53:04.278930Z","iopub.status.idle":"2025-02-24T21:02:51.692705Z","shell.execute_reply.started":"2025-02-24T20:53:04.278910Z","shell.execute_reply":"2025-02-24T21:02:51.691857Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\\Train Metrics: {'eval_loss': 0.016327695921063423, 'eval_accuracy': 0.9961041327611017, 'eval_precision': 0.9961060475960296, 'eval_recall': 0.9961041327611017, 'eval_f1': 0.9961030414344039, 'eval_runtime': 587.4023, 'eval_samples_per_second': 270.927, 'eval_steps_per_second': 2.823, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"test_metrics = trainer.evaluate(test_dataset)\n\nprint(\"\\nTest Metrics:\", test_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:03:15.717827Z","iopub.execute_input":"2025-02-24T21:03:15.718171Z","iopub.status.idle":"2025-02-24T21:05:42.778206Z","shell.execute_reply.started":"2025-02-24T21:03:15.718143Z","shell.execute_reply":"2025-02-24T21:05:42.777368Z"}},"outputs":[{"name":"stdout","text":"\nTest Metrics: {'eval_loss': 0.3652516007423401, 'eval_accuracy': 0.9267832906047353, 'eval_precision': 0.9263253547977085, 'eval_recall': 0.9267832906047353, 'eval_f1': 0.9264208214631784, 'eval_runtime': 147.0501, 'eval_samples_per_second': 270.561, 'eval_steps_per_second': 2.822, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Get predictions\npredictions = trainer.predict(test_dataset)\npreds = np.argmax(predictions.predictions, axis=1)\nlabels = predictions.label_ids\n\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(labels, preds))\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(labels, preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:05:53.088272Z","iopub.execute_input":"2025-02-24T21:05:53.088556Z","iopub.status.idle":"2025-02-24T21:08:20.325727Z","shell.execute_reply.started":"2025-02-24T21:05:53.088533Z","shell.execute_reply":"2025-02-24T21:08:20.325034Z"}},"outputs":[{"name":"stdout","text":"\nConfusion Matrix:\n[[13494    54    72   257    28    36     9    32    34    16]\n [   60  3434    33    21    14    87    12    30    13     8]\n [   98    38  2810    16    22    83     9    69    12    20]\n [  353    30    29  1770     5     9     5    10     4     4]\n [   13    12    14     3  2127     2     2    26     2     0]\n [   28    66    70    12     1  2834     6    43     5   124]\n [    6     5    10     1     1    12  3567    29    18    11]\n [   18    17    48     5    28    35    27  3695    30     9]\n [   28    16    16     7     9    19    38    39  1775    22]\n [   23    15    29    19     2   160    23    39    38  1367]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96     14032\n           1       0.93      0.93      0.93      3712\n           2       0.90      0.88      0.89      3177\n           3       0.84      0.80      0.82      2219\n           4       0.95      0.97      0.96      2201\n           5       0.86      0.89      0.88      3189\n           6       0.96      0.97      0.97      3660\n           7       0.92      0.94      0.93      3912\n           8       0.92      0.90      0.91      1969\n           9       0.86      0.80      0.83      1715\n\n    accuracy                           0.93     39786\n   macro avg       0.91      0.90      0.91     39786\nweighted avg       0.93      0.93      0.93     39786\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"72d0e227429bd347553a5563b7396b82cb04a364\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:26:32.036027Z","iopub.execute_input":"2025-02-24T15:26:32.036368Z","iopub.status.idle":"2025-02-24T15:26:41.578061Z","shell.execute_reply.started":"2025-02-24T15:26:32.036344Z","shell.execute_reply":"2025-02-24T15:26:41.577182Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrokaia-emad\u001b[0m (\u001b[33mrokaia-emad-modern-sciences-and-arts-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def save_complete_model(model, tokenizer, category_mapping, save_path):\n    model.base_model.save_pretrained(save_path)\n    tokenizer.save_pretrained(save_path)\n    \n    classifier_state = {\n        'classifier_state': model.classifier.state_dict(),\n        'num_labels': model.classifier.out_features\n    }\n    torch.save(classifier_state, f\"{save_path}/classifier_state.pt\")\n    \n    with open(f\"{save_path}/category_mapping.pkl\", \"wb\") as f:\n        pickle.dump(category_mapping, f)\n\n# Save the model\nsave_complete_model(trainer.model, tokenizer, category_mapping, \"mBert\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:10:50.372441Z","iopub.execute_input":"2025-02-24T21:10:50.372731Z","iopub.status.idle":"2025-02-24T21:10:52.161037Z","shell.execute_reply.started":"2025-02-24T21:10:50.372711Z","shell.execute_reply":"2025-02-24T21:10:52.160401Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer\n\n# Define the function to load the complete model\ndef load_complete_model(model_path):\n    base_model = AutoModel.from_pretrained(model_path)\n\n    # Load classifier weights\n    classifier_state = torch.load(f\"{model_path}/classifier_state.pt\", map_location=torch.device('cpu'))\n\n    # Recreate the model\n    model = CustomModel(base_model, classifier_state['num_labels'])\n\n    # Load classifier weights into the model\n    model.classifier.load_state_dict(classifier_state['classifier_state'])\n\n    # Set to evaluation mode\n    model.eval()\n    return model\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"mBert\")\n\n# Load the model\nmodel2 = load_complete_model(\"mBert\")\n\nprint(\"Model loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:11:11.123415Z","iopub.execute_input":"2025-02-24T21:11:11.123693Z","iopub.status.idle":"2025-02-24T21:11:11.317533Z","shell.execute_reply.started":"2025-02-24T21:11:11.123664Z","shell.execute_reply":"2025-02-24T21:11:11.316623Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully!\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-13-39cbc3a56c3c>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  classifier_state = torch.load(f\"{model_path}/classifier_state.pt\", map_location=torch.device('cpu'))\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n# Function to make predictions\ndef predict_category(text, model, tokenizer, category_mapping):\n    # Tokenize the input text\n    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n\n    # Move inputs to model\n    with torch.no_grad():  # No need for gradients during inference\n        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n    \n    # Get the predicted class\n    logits = outputs[\"logits\"]\n    predicted_label = torch.argmax(logits, dim=-1).item()\n\n    # Reverse mapping from index to category\n    category_mapping_reverse = {v: k for k, v in category_mapping.items()}\n    predicted_category = category_mapping_reverse[predicted_label]\n\n    return predicted_category\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:11:14.394308Z","iopub.execute_input":"2025-02-24T21:11:14.394592Z","iopub.status.idle":"2025-02-24T21:11:14.400832Z","shell.execute_reply.started":"2025-02-24T21:11:14.394570Z","shell.execute_reply":"2025-02-24T21:11:14.400133Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import pickle\n\n# Load the category mapping\nwith open(\"mBert/category_mapping.pkl\", \"rb\") as f:\n    category_mapping = pickle.load(f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:11:17.931148Z","iopub.execute_input":"2025-02-24T21:11:17.931424Z","iopub.status.idle":"2025-02-24T21:11:17.936047Z","shell.execute_reply.started":"2025-02-24T21:11:17.931403Z","shell.execute_reply":"2025-02-24T21:11:17.935263Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Example text\ntext = \"ŸÜŸÇÿµ ÿ≠ÿØŸäÿØ\"\n\n# Predict category\npredicted_category = predict_category(text, model2, tokenizer, category_mapping)\n\n# Print result\nprint(f\"Predicted Category: {predicted_category}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:12:21.805527Z","iopub.execute_input":"2025-02-24T21:12:21.805798Z","iopub.status.idle":"2025-02-24T21:12:21.928222Z","shell.execute_reply.started":"2025-02-24T21:12:21.805778Z","shell.execute_reply":"2025-02-24T21:12:21.927326Z"}},"outputs":[{"name":"stdout","text":"Predicted Category: ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿØŸÖ\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import shutil\n\n# Define the folder and output zip file\nfolder_path = \"mBert\"\nzip_file_name = \"mBert.zip\"\n\n# Create a zip archive\nshutil.make_archive(zip_file_name.replace(\".zip\", \"\"), 'zip', folder_path)\n\nprint(f\"‚úÖ Folder {folder_path} compressed successfully as {zip_file_name}!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:12:24.780220Z","iopub.execute_input":"2025-02-24T21:12:24.780652Z","iopub.status.idle":"2025-02-24T21:12:59.568941Z","shell.execute_reply.started":"2025-02-24T21:12:24.780612Z","shell.execute_reply":"2025-02-24T21:12:59.568044Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Folder mBert compressed successfully as mBert.zip!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from google.colab import files\n\n# Download the zip file\nfiles.download(zip_file_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:38:03.041918Z","iopub.execute_input":"2025-02-24T14:38:03.042224Z","iopub.status.idle":"2025-02-24T14:38:03.049328Z","shell.execute_reply.started":"2025-02-24T14:38:03.042202Z","shell.execute_reply":"2025-02-24T14:38:03.048676Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"download(\"download_a45430e4-824b-497c-97e6-cd7f63fa7c89\", \"arabic_text_classifier_final.zip\", 502435153)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import shutil\n\n# Zip the folder\nshutil.make_archive(\"mBert\", 'zip', \"mBert\")\n\n# Print the file path\nprint(\"Download your file from: /kaggle/working/mBert.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:13:19.532031Z","iopub.execute_input":"2025-02-24T21:13:19.532341Z","iopub.status.idle":"2025-02-24T21:13:54.443572Z","shell.execute_reply.started":"2025-02-24T21:13:19.532319Z","shell.execute_reply":"2025-02-24T21:13:54.442838Z"}},"outputs":[{"name":"stdout","text":"Download your file from: /kaggle/working/mBert.zip\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from google.colab import files\n\n# Download the zip file\nfiles.download(zip_file_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:40:54.605748Z","iopub.execute_input":"2025-02-24T14:40:54.606059Z","iopub.status.idle":"2025-02-24T14:40:54.613296Z","shell.execute_reply.started":"2025-02-24T14:40:54.606038Z","shell.execute_reply":"2025-02-24T14:40:54.612533Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"download(\"download_6ba59225-f724-429f-8938-2a46af272951\", \"arabic_text_classifier_final.zip\", 502435153)"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'mBert.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T21:14:20.786709Z","iopub.execute_input":"2025-02-24T21:14:20.786985Z","iopub.status.idle":"2025-02-24T21:14:20.792755Z","shell.execute_reply.started":"2025-02-24T21:14:20.786964Z","shell.execute_reply":"2025-02-24T21:14:20.791893Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/mBert.zip","text/html":"<a href='mBert.zip' target='_blank'>mBert.zip</a><br>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}