{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8962508,"sourceType":"datasetVersion","datasetId":5394582}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments\nfrom datasets import Dataset\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport logging\nimport pickle\nimport numpy as np\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:48:54.965273Z","iopub.execute_input":"2025-02-24T16:48:54.965565Z","iopub.status.idle":"2025-02-24T16:48:54.971271Z","shell.execute_reply.started":"2025-02-24T16:48:54.965542Z","shell.execute_reply":"2025-02-24T16:48:54.970245Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"c26df6b59bfb128917e73bbb00a79ca7e9324a11\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:48:55.975297Z","iopub.execute_input":"2025-02-24T16:48:55.975562Z","iopub.status.idle":"2025-02-24T16:48:55.982472Z","shell.execute_reply.started":"2025-02-24T16:48:55.975541Z","shell.execute_reply":"2025-02-24T16:48:55.981827Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, base_model, num_labels):  # FIX: Correct __init__ method\n        super(CustomModel, self).__init__()  # FIX: Correct super() call\n        self.base_model = base_model \n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(base_model.config.hidden_size, num_labels)\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n\n        loss = None\n        if labels is not None:\n            loss = self.loss_fn(logits, labels)\n        return {\"loss\": loss, \"logits\": logits}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:48:57.064884Z","iopub.execute_input":"2025-02-24T16:48:57.065164Z","iopub.status.idle":"2025-02-24T16:48:57.070983Z","shell.execute_reply.started":"2025-02-24T16:48:57.065139Z","shell.execute_reply":"2025-02-24T16:48:57.070303Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Load data\ntrain_path = \"/kaggle/input/maqa-dataset/Unbalanced/Unbalanced/MAQA_Train.xlsx\"\ntest_path = \"/kaggle/input/maqa-dataset/Unbalanced/Unbalanced/MAQA_Test.xlsx\"\ntrain_df = pd.read_excel(train_path)\ntest_df = pd.read_excel(test_path)\nall_data = pd.concat([train_df, test_df], ignore_index=True)\nall_data = all_data[['q_body', 'category']]\n\nvalid_categories = [\n    \"ÿßŸÖÿ±ÿßÿ∂ ŸÜÿ≥ÿßÿ¶Ÿäÿ©\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿπÿ∂ŸÑÿßÿ™ ŸàÿßŸÑÿπÿ∏ÿßŸÖ Ÿà ÿßŸÑŸÖŸÅÿßÿµŸÑ\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑŸáÿ∂ŸÖŸä\",\n    \"ÿßŸÑÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿ¨ŸÜÿ≥Ÿäÿ©\",\n    \"ÿ∑ÿ® ÿßŸÑÿßÿ≥ŸÜÿßŸÜ\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑŸÇŸÑÿ® Ÿà ÿßŸÑÿ¥ÿ±ÿßŸäŸäŸÜ\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿπŸäŸàŸÜ\",\n    \"ÿßŸÜŸÅ ÿßÿ∞ŸÜ Ÿàÿ≠ŸÜÿ¨ÿ±ÿ©\",\n    \"ÿ¨ÿ±ÿßÿ≠ÿ© ÿ™ÿ¨ŸÖŸäŸÑ\",\n    \"ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿØŸÖ\"\n]\n\nall_data = all_data[all_data[\"category\"].isin(valid_categories)]\nall_data = all_data.sample(frac=1, random_state=42).reset_index(drop=True)\ntrain_df, test_df = train_test_split(all_data, test_size=0.2, random_state=42, stratify=all_data['category'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:49:00.164874Z","iopub.execute_input":"2025-02-24T16:49:00.165212Z","iopub.status.idle":"2025-02-24T16:49:29.694973Z","shell.execute_reply.started":"2025-02-24T16:49:00.165185Z","shell.execute_reply":"2025-02-24T16:49:29.694083Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"train_df[\"text\"] = train_df[\"q_body\"]\ntest_df[\"text\"] = test_df[\"q_body\"]\n\ncategory_mapping = {cat: i for i, cat in enumerate(valid_categories)}\ntrain_df['label'] = train_df['category'].map(category_mapping)\ntest_df['label'] = test_df['category'].map(category_mapping)\n\nmodel_name = \"distilbert/distilbert-base-multilingual-cased\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_dataset = Dataset.from_dict({\"text\": train_df[\"text\"].tolist(), \"label\": train_df[\"label\"].tolist()})\ntest_dataset = Dataset.from_dict({\"text\": test_df[\"text\"].tolist(), \"label\": test_df[\"label\"].tolist()})\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:49:29.696205Z","iopub.execute_input":"2025-02-24T16:49:29.696427Z","iopub.status.idle":"2025-02-24T16:49:50.713717Z","shell.execute_reply.started":"2025-02-24T16:49:29.696408Z","shell.execute_reply":"2025-02-24T16:49:50.713057Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/159143 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ad5e0a8b57547528581600c3291a7ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/39786 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6dc28f873e1494cb36e7e8d74365e49"}},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"base_model = AutoModel.from_pretrained(model_name)\nmodel = CustomModel(base_model, 10)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    per_device_train_batch_size=96,\n    per_device_eval_batch_size=96,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    learning_rate=3e-5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\"\n)\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n    acc = accuracy_score(labels, predictions)\n    return {\n        \"accuracy\": acc,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1\n    }\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:49:50.715181Z","iopub.execute_input":"2025-02-24T16:49:50.715433Z","iopub.status.idle":"2025-02-24T16:49:51.088951Z","shell.execute_reply.started":"2025-02-24T16:49:50.715411Z","shell.execute_reply":"2025-02-24T16:49:51.088320Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n<ipython-input-38-b4ae84f841c3>:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Train\nprint(\"\\nStarting training...\")\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:49:51.089724Z","iopub.execute_input":"2025-02-24T16:49:51.089937Z","iopub.status.idle":"2025-02-24T19:30:50.733699Z","shell.execute_reply.started":"2025-02-24T16:49:51.089907Z","shell.execute_reply":"2025-02-24T19:30:50.732849Z"}},"outputs":[{"name":"stdout","text":"\nStarting training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8290' max='8290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8290/8290 2:40:58, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.368900</td>\n      <td>0.320089</td>\n      <td>0.900543</td>\n      <td>0.900174</td>\n      <td>0.900543</td>\n      <td>0.899722</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.304500</td>\n      <td>0.277979</td>\n      <td>0.911677</td>\n      <td>0.911870</td>\n      <td>0.911677</td>\n      <td>0.911590</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.217300</td>\n      <td>0.264536</td>\n      <td>0.917835</td>\n      <td>0.917085</td>\n      <td>0.917835</td>\n      <td>0.917142</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.209200</td>\n      <td>0.261930</td>\n      <td>0.920374</td>\n      <td>0.919984</td>\n      <td>0.920374</td>\n      <td>0.919767</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.149000</td>\n      <td>0.263887</td>\n      <td>0.921882</td>\n      <td>0.921668</td>\n      <td>0.921882</td>\n      <td>0.921579</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.127700</td>\n      <td>0.270877</td>\n      <td>0.923290</td>\n      <td>0.923006</td>\n      <td>0.923290</td>\n      <td>0.922936</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.098100</td>\n      <td>0.277409</td>\n      <td>0.924722</td>\n      <td>0.923996</td>\n      <td>0.924722</td>\n      <td>0.924132</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.096100</td>\n      <td>0.285048</td>\n      <td>0.924220</td>\n      <td>0.923873</td>\n      <td>0.924220</td>\n      <td>0.923984</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.090500</td>\n      <td>0.289697</td>\n      <td>0.925074</td>\n      <td>0.924505</td>\n      <td>0.925074</td>\n      <td>0.924674</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.074300</td>\n      <td>0.292377</td>\n      <td>0.925225</td>\n      <td>0.924529</td>\n      <td>0.925225</td>\n      <td>0.924773</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=8290, training_loss=0.19336676957811463, metrics={'train_runtime': 9658.7492, 'train_samples_per_second': 164.766, 'train_steps_per_second': 0.858, 'total_flos': 0.0, 'train_loss': 0.19336676957811463, 'epoch': 10.0})"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"# Evaluate\ntrain_metrics = trainer.evaluate(train_dataset)\nprint(\"\\Train Metrics:\", train_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:32:22.916764Z","iopub.execute_input":"2025-02-24T19:32:22.917126Z","iopub.status.idle":"2025-02-24T19:37:51.169405Z","shell.execute_reply.started":"2025-02-24T19:32:22.917092Z","shell.execute_reply":"2025-02-24T19:37:51.168693Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\\Train Metrics: {'eval_loss': 0.03658333793282509, 'eval_accuracy': 0.9905619474309268, 'eval_precision': 0.9905316358052546, 'eval_recall': 0.9905619474309268, 'eval_f1': 0.9905201535510255, 'eval_runtime': 328.2409, 'eval_samples_per_second': 484.836, 'eval_steps_per_second': 2.526, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"test_metrics = trainer.evaluate(test_dataset)\n\nprint(\"\\nTest Metrics:\", test_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:38:02.035663Z","iopub.execute_input":"2025-02-24T19:38:02.035968Z","iopub.status.idle":"2025-02-24T19:39:24.555710Z","shell.execute_reply.started":"2025-02-24T19:38:02.035943Z","shell.execute_reply":"2025-02-24T19:39:24.554875Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nTest Metrics: {'eval_loss': 0.29237672686576843, 'eval_accuracy': 0.9252249535012316, 'eval_precision': 0.9245294639008788, 'eval_recall': 0.9252249535012316, 'eval_f1': 0.924772673176017, 'eval_runtime': 82.5095, 'eval_samples_per_second': 482.199, 'eval_steps_per_second': 2.521, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# Get predictions\npredictions = trainer.predict(test_dataset)\npreds = np.argmax(predictions.predictions, axis=1)\nlabels = predictions.label_ids\n\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(labels, preds))\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(labels, preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:39:30.962530Z","iopub.execute_input":"2025-02-24T19:39:30.962855Z","iopub.status.idle":"2025-02-24T19:40:53.480927Z","shell.execute_reply.started":"2025-02-24T19:39:30.962825Z","shell.execute_reply":"2025-02-24T19:40:53.480195Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nConfusion Matrix:\n[[13529    56    67   240    33    27     5    22    37    16]\n [   66  3453    29    24    16    73    11    18    13     9]\n [  101    45  2793    17    28    76    12    60    18    27]\n [  386    24    33  1744     2     6     5     5     8     6]\n [   19    10     4     2  2133     1     0    27     4     1]\n [   41    81    62    13     3  2786    10    51     8   134]\n [    6     5    11     2     7    12  3557    27    17    16]\n [   25    26    50     8    32    30    31  3651    37    22]\n [   31    12    17    11    11    15    36    38  1765    33]\n [   24    15    33    18     6   119    24    39    37  1400]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.96      0.96     14032\n           1       0.93      0.93      0.93      3712\n           2       0.90      0.88      0.89      3177\n           3       0.84      0.79      0.81      2219\n           4       0.94      0.97      0.95      2201\n           5       0.89      0.87      0.88      3189\n           6       0.96      0.97      0.97      3660\n           7       0.93      0.93      0.93      3912\n           8       0.91      0.90      0.90      1969\n           9       0.84      0.82      0.83      1715\n\n    accuracy                           0.93     39786\n   macro avg       0.91      0.90      0.90     39786\nweighted avg       0.92      0.93      0.92     39786\n\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"def save_complete_model(model, tokenizer, category_mapping, save_path):\n    model.base_model.save_pretrained(save_path)\n    tokenizer.save_pretrained(save_path)\n    \n    classifier_state = {\n        'classifier_state': model.classifier.state_dict(),\n        'num_labels': model.classifier.out_features\n    }\n    torch.save(classifier_state, f\"{save_path}/classifier_state.pt\")\n    \n    with open(f\"{save_path}/category_mapping.pkl\", \"wb\") as f:\n        pickle.dump(category_mapping, f)\n\n# Save the model\nsave_complete_model(trainer.model, tokenizer, category_mapping, \"arabic_text_classifier_final\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:42:01.342134Z","iopub.execute_input":"2025-02-24T19:42:01.342432Z","iopub.status.idle":"2025-02-24T19:42:02.763287Z","shell.execute_reply.started":"2025-02-24T19:42:01.342407Z","shell.execute_reply":"2025-02-24T19:42:02.762612Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer\n\n# Define the function to load the complete model\ndef load_complete_model(model_path):\n    base_model = AutoModel.from_pretrained(model_path)\n\n    # Load classifier weights\n    classifier_state = torch.load(f\"{model_path}/classifier_state.pt\", map_location=torch.device('cpu'))\n\n    # Recreate the model\n    model = CustomModel(base_model, classifier_state['num_labels'])\n\n    # Load classifier weights into the model\n    model.classifier.load_state_dict(classifier_state['classifier_state'])\n\n    # Set to evaluation mode\n    model.eval()\n    return model\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"arabic_text_classifier_final\")\n\n# Load the model\nmodel2 = load_complete_model(\"arabic_text_classifier_final\")\n\nprint(\"Model loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:42:07.971036Z","iopub.execute_input":"2025-02-24T19:42:07.971349Z","iopub.status.idle":"2025-02-24T19:42:08.132783Z","shell.execute_reply.started":"2025-02-24T19:42:07.971323Z","shell.execute_reply":"2025-02-24T19:42:08.131946Z"}},"outputs":[{"name":"stdout","text":"Model loaded successfully!\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-44-6bf29fe3f0c6>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  classifier_state = torch.load(f\"{model_path}/classifier_state.pt\", map_location=torch.device('cpu'))\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import torch\nimport numpy as np\n\n# Function to make predictions\ndef predict_category(text, model, tokenizer, category_mapping):\n    # Tokenize the input text\n    inputs = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n\n    # Move inputs to model\n    with torch.no_grad():  # No need for gradients during inference\n        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n    \n    # Get the predicted class\n    logits = outputs[\"logits\"]\n    predicted_label = torch.argmax(logits, dim=-1).item()\n\n    # Reverse mapping from index to category\n    category_mapping_reverse = {v: k for k, v in category_mapping.items()}\n    predicted_category = category_mapping_reverse[predicted_label]\n\n    return predicted_category\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:42:12.639185Z","iopub.execute_input":"2025-02-24T19:42:12.639478Z","iopub.status.idle":"2025-02-24T19:42:12.645784Z","shell.execute_reply.started":"2025-02-24T19:42:12.639455Z","shell.execute_reply":"2025-02-24T19:42:12.644827Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"import pickle\n\n# Load the category mapping\nwith open(\"arabic_text_classifier_final/category_mapping.pkl\", \"rb\") as f:\n    category_mapping = pickle.load(f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:42:27.377636Z","iopub.execute_input":"2025-02-24T19:42:27.377915Z","iopub.status.idle":"2025-02-24T19:42:27.382895Z","shell.execute_reply.started":"2025-02-24T19:42:27.377892Z","shell.execute_reply":"2025-02-24T19:42:27.382078Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# Example text\ntext = \"ÿ®ÿ±ÿØ ÿ¥ÿØŸäÿØ ŸÅŸä ÿßŸÑŸÖÿπÿØŸá\"\n\n# Predict category\npredicted_category = predict_category(text, model2, tokenizer, category_mapping)\n\n# Print result\nprint(f\"Predicted Category: {predicted_category}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:45:48.930295Z","iopub.execute_input":"2025-02-24T19:45:48.930613Z","iopub.status.idle":"2025-02-24T19:45:49.005431Z","shell.execute_reply.started":"2025-02-24T19:45:48.930585Z","shell.execute_reply":"2025-02-24T19:45:49.004691Z"}},"outputs":[{"name":"stdout","text":"Predicted Category: ÿßŸÖÿ±ÿßÿ∂ ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑŸáÿ∂ŸÖŸä\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"import shutil\n\n# Define the folder and output zip file\nfolder_path = \"arabic_text_classifier_final\"\nzip_file_name = \"arabic_text_classifier_final.zip\"\n\n# Create a zip archive\nshutil.make_archive(zip_file_name.replace(\".zip\", \"\"), 'zip', folder_path)\n\nprint(f\"‚úÖ Folder {folder_path} compressed successfully as {zip_file_name}!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:42:43.165512Z","iopub.execute_input":"2025-02-24T19:42:43.165806Z","iopub.status.idle":"2025-02-24T19:43:09.588037Z","shell.execute_reply.started":"2025-02-24T19:42:43.165781Z","shell.execute_reply":"2025-02-24T19:43:09.587256Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Folder arabic_text_classifier_final compressed successfully as arabic_text_classifier_final.zip!\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"from google.colab import files\n\n# Download the zip file\nfiles.download(zip_file_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:43:18.910174Z","iopub.execute_input":"2025-02-24T19:43:18.910448Z","iopub.status.idle":"2025-02-24T19:43:18.918035Z","shell.execute_reply.started":"2025-02-24T19:43:18.910426Z","shell.execute_reply":"2025-02-24T19:43:18.917284Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"download(\"download_91df6a03-b217-4b19-aa9e-ee2e46ce868a\", \"arabic_text_classifier_final.zip\", 501206807)"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"import shutil\n\n# Zip the folder\nshutil.make_archive(\"arabic_text_classifier_final\", 'zip', \"arabic_text_classifier_final\")\n\n# Print the file path\nprint(\"Download your file from: /kaggle/working/arabic_text_classifier_final.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:43:21.478163Z","iopub.execute_input":"2025-02-24T19:43:21.478448Z","iopub.status.idle":"2025-02-24T19:43:48.284462Z","shell.execute_reply.started":"2025-02-24T19:43:21.478426Z","shell.execute_reply":"2025-02-24T19:43:48.283467Z"}},"outputs":[{"name":"stdout","text":"Download your file from: /kaggle/working/arabic_text_classifier_final.zip\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"from google.colab import files\n\n# Download the zip file\nfiles.download(zip_file_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:43:48.285500Z","iopub.execute_input":"2025-02-24T19:43:48.285803Z","iopub.status.idle":"2025-02-24T19:43:48.292987Z","shell.execute_reply.started":"2025-02-24T19:43:48.285765Z","shell.execute_reply":"2025-02-24T19:43:48.292167Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"download(\"download_7c607ee7-d4b8-41ba-80de-315b47fb751d\", \"arabic_text_classifier_final.zip\", 501206807)"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'arabic_text_classifier_final.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T19:43:48.294304Z","iopub.execute_input":"2025-02-24T19:43:48.294517Z","iopub.status.idle":"2025-02-24T19:43:48.309473Z","shell.execute_reply.started":"2025-02-24T19:43:48.294497Z","shell.execute_reply":"2025-02-24T19:43:48.308896Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/arabic_text_classifier_final.zip","text/html":"<a href='arabic_text_classifier_final.zip' target='_blank'>arabic_text_classifier_final.zip</a><br>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}