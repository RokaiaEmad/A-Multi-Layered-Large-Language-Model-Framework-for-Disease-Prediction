{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10042820,"sourceType":"datasetVersion","datasetId":6186713},{"sourceId":10207250,"sourceType":"datasetVersion","datasetId":6308159},{"sourceId":10320693,"sourceType":"datasetVersion","datasetId":6389894}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install \"torch==2.2.2\" tensorboard\n%pip install --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n","metadata":{"_cell_guid":"1e2fe242-ff4e-4b80-a65e-86c9a4412a02","_uuid":"534b98c4-041f-416f-8871-39f66e40d1f4","collapsed":false,"execution":{"iopub.status.busy":"2024-12-28T16:23:28.457899Z","iopub.execute_input":"2024-12-28T16:23:28.458169Z","iopub.status.idle":"2024-12-28T16:26:29.534090Z","shell.execute_reply.started":"2024-12-28T16:23:28.458120Z","shell.execute_reply":"2024-12-28T16:26:29.533216Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting torch==2.2.2\n  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch==2.2.2)\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\nRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (71.0.4)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2) (1.3.0)\nDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.1+cu121\n    Uninstalling torch-2.4.1+cu121:\n      Successfully uninstalled torch-2.4.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\ntorchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 triton-2.2.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting transformers==4.40.0\n  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting datasets==2.18.0\n  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\nCollecting accelerate==0.29.3\n  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\nCollecting evaluate==0.4.1\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting bitsandbytes==0.43.1\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nCollecting huggingface_hub==0.22.2\n  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\nCollecting trl==0.8.6\n  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\nCollecting peft==0.10.0\n  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (4.66.5)\nRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (18.1.0)\nRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (2.1.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.70.16)\nCollecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0)\n  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.10.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (2.2.2)\nCollecting responses<0.19 (from evaluate==0.4.1)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.22.2) (4.12.2)\nCollecting tyro>=0.5.11 (from trl==0.8.6)\n  Downloading tyro-0.9.5-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3) (12.6.85)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (13.8.1)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.8.6)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (4.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\nDownloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nDownloading tyro-0.9.5-py3-none-any.whl (112 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, fsspec, responses, huggingface_hub, tyro, transformers, bitsandbytes, accelerate, peft, datasets, trl, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.6.1\n    Uninstalling fsspec-2024.6.1:\n      Successfully uninstalled fsspec-2024.6.1\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.24.7\n    Uninstalling huggingface-hub-0.24.7:\n      Successfully uninstalled huggingface-hub-0.24.7\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.34.2\n    Uninstalling accelerate-0.34.2:\n      Successfully uninstalled accelerate-0.34.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.2.0\n    Uninstalling datasets-3.2.0:\n      Successfully uninstalled datasets-3.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ndistributed 2024.8.0 requires dask==2024.8.0, but you have dask 2024.12.1 which is incompatible.\ngcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.2.0 which is incompatible.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\ntorchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.29.3 bitsandbytes-0.43.1 datasets-2.18.0 evaluate-0.4.1 fsspec-2024.2.0 huggingface_hub-0.22.2 peft-0.10.0 responses-0.18.0 shtab-1.7.1 transformers-4.40.0 trl-0.8.6 tyro-0.9.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-12-28T16:27:39.843055Z","iopub.execute_input":"2024-12-28T16:27:39.843396Z","iopub.status.idle":"2024-12-28T16:27:40.586509Z","shell.execute_reply.started":"2024-12-28T16:27:39.843368Z","shell.execute_reply":"2024-12-28T16:27:40.585828Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn.functional as F\nimport evaluate\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset, DatasetDict\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding\n)\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\nfrom sklearn.metrics import balanced_accuracy_score, accuracy_score, confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-12-28T16:27:42.858324Z","iopub.execute_input":"2024-12-28T16:27:42.858642Z","iopub.status.idle":"2024-12-28T16:27:55.098068Z","shell.execute_reply.started":"2024-12-28T16:27:42.858610Z","shell.execute_reply":"2024-12-28T16:27:55.097430Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.execute_input":"2024-11-28T19:01:24.063743Z","iopub.status.busy":"2024-11-28T19:01:24.063491Z","iopub.status.idle":"2024-11-28T19:01:32.789631Z","shell.execute_reply":"2024-11-28T19:01:32.788792Z","shell.execute_reply.started":"2024-11-28T19:01:24.063719Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"]}],"execution_count":207},{"cell_type":"code","source":"!pip install bitsandbytes accelerate\n","metadata":{"execution":{"iopub.execute_input":"2024-11-28T19:01:32.791262Z","iopub.status.busy":"2024-11-28T19:01:32.790978Z","iopub.status.idle":"2024-11-28T19:01:41.590924Z","shell.execute_reply":"2024-11-28T19:01:41.590082Z","shell.execute_reply.started":"2024-11-28T19:01:32.791233Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.2.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.85)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"]}],"execution_count":208},{"cell_type":"code","source":"!pip install peft\n","metadata":{"execution":{"iopub.execute_input":"2024-11-28T19:01:41.592660Z","iopub.status.busy":"2024-11-28T19:01:41.592342Z","iopub.status.idle":"2024-11-28T19:01:50.175297Z","shell.execute_reply":"2024-11-28T19:01:50.174269Z","shell.execute_reply.started":"2024-11-28T19:01:41.592630Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.10.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.2.2)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.40.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\n","Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.29.3)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.85)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"]}],"execution_count":209},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_excel(\"/kaggle/input/dataaaa/reshaped_output2 (6).xlsx\")\n# Slice the first 1951 rows\ndf = df.iloc[:1592]\n\n# Display the DataFrame or its information\ndf\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:39:47.244347Z","iopub.execute_input":"2024-12-28T18:39:47.244710Z","iopub.status.idle":"2024-12-28T18:39:47.657698Z","shell.execute_reply.started":"2024-12-28T18:39:47.244680Z","shell.execute_reply":"2024-12-28T18:39:47.656697Z"},"trusted":true},"outputs":[{"execution_count":197,"output_type":"execute_result","data":{"text/plain":"     Image type                                               Post Severity  \\\n0       Unknown  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...      حرج   \n1       Unknown          يخوان شو الحل مع القولون العصبي مشان الله  غير حرج   \n2       Unknown  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...      حرج   \n3       Unknown  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...  غير حرج   \n4       Unknown  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...  غير حرج   \n...         ...                                                ...      ...   \n1587        NaN                    شعرى وقع من الامام فقط اعمل ايه  غير حرج   \n1588        NaN  لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...  غير حرج   \n1589        NaN  عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...      حرج   \n1590        NaN  بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...  غير حرج   \n1591        NaN                              علاج للاكزيما العصبية      حرج   \n\n                  Diagnosis             Type  \\\n0                 مخ واعصاب        مخ واعصاب   \n1                قولون عصبي            باطنه   \n2             كدمه في الوجه  انف واذن وحنجره   \n3                       ضغط            باطنه   \n4     عدم التركيز و النسيان        مخ واعصاب   \n...                     ...              ...   \n1587            تساقط الشعر   جلديه وتناسليه   \n1588            هالات سوداء   جلديه وتناسليه   \n1589            تساقط الشعر   جلديه وتناسليه   \n1590           اكسده البشره   جلديه وتناسليه   \n1591         اكزيما العصبيه   جلديه وتناسليه   \n\n                                                    NER  \\\n0     ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1                                        ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ   \n2                           \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ   \n3      \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4     \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n...                                                 ...   \n1587                             شعرى وقع من الامام فقط   \n1588       كريم خافي للعيوب كونسيلر طبي للهالات السوداء   \n1589                                        ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ   \n1590                       ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة   \n1591                                    ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ   \n\n                                             Summarised  \\\n0     ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...   \n1                                            ﻗﻮﻟﻮﻥ عصبي   \n2     ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...   \n3     ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...   \n4                 ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة   \n...                                                 ...   \n1587                             شعرى وقع من الامام فقط   \n1588  هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...   \n1589                                        ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ   \n1590                       ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة   \n1591                                    ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ   \n\n                                                 Refine  \\\n0     \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1     قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2     \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3     صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4     \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n...                                                 ...   \n1587                                                NaN   \n1588                                                NaN   \n1589                       \\n\\n تساقط الشعر بدرجة كبيرة   \n1590                                                NaN   \n1591                                                NaN   \n\n                                                 Post.1  \\\n0     السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...   \n1             يخوان شو الحل مع القولون العصبي مشان الله   \n2     لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...   \n3     حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...   \n4     عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...   \n...                                                 ...   \n1587                    شعرى وقع من الامام فقط اعمل ايه   \n1588  لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...   \n1589  عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...   \n1590  بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...   \n1591                              علاج للاكزيما العصبية   \n\n                                                Refined  \\\n0     \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1     قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2     \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3     صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4     \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n...                                                 ...   \n1587                    شعرى وقع من الامام فقط اعمل ايه   \n1588   لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونس...   \n1589  \\n\\n تساقط الشعر بدرجة كبيرة عندي تساقط الشعر ...   \n1590   بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف ال...   \n1591                              علاج للاكزيما العصبية   \n\n                                               NER_POST  \\\n0     ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1     ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...   \n2      \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...   \n3      \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4     \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n...                                                 ...   \n1587  شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...   \n1588  كريم خافي للعيوب كونسيلر طبي للهالات السوداء ل...   \n1589  ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...   \n1590  ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...   \n1591              ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية   \n\n                                        Summarised_POST  \n0     ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...  \n1     ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...  \n2     ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...  \n3     ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...  \n4     ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...  \n...                                                 ...  \n1587  شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...  \n1588  هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...  \n1589  ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...  \n1590  ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...  \n1591              ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية  \n\n[1592 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image type</th>\n      <th>Post</th>\n      <th>Severity</th>\n      <th>Diagnosis</th>\n      <th>Type</th>\n      <th>NER</th>\n      <th>Summarised</th>\n      <th>Refine</th>\n      <th>Post.1</th>\n      <th>Refined</th>\n      <th>NER_POST</th>\n      <th>Summarised_POST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Unknown</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>حرج</td>\n      <td>مخ واعصاب</td>\n      <td>مخ واعصاب</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unknown</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>غير حرج</td>\n      <td>قولون عصبي</td>\n      <td>باطنه</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Unknown</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>حرج</td>\n      <td>كدمه في الوجه</td>\n      <td>انف واذن وحنجره</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Unknown</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>غير حرج</td>\n      <td>ضغط</td>\n      <td>باطنه</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unknown</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>غير حرج</td>\n      <td>عدم التركيز و النسيان</td>\n      <td>مخ واعصاب</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1587</th>\n      <td>NaN</td>\n      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n      <td>غير حرج</td>\n      <td>تساقط الشعر</td>\n      <td>جلديه وتناسليه</td>\n      <td>شعرى وقع من الامام فقط</td>\n      <td>شعرى وقع من الامام فقط</td>\n      <td>NaN</td>\n      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n      <td>شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...</td>\n      <td>شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...</td>\n    </tr>\n    <tr>\n      <th>1588</th>\n      <td>NaN</td>\n      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...</td>\n      <td>غير حرج</td>\n      <td>هالات سوداء</td>\n      <td>جلديه وتناسليه</td>\n      <td>كريم خافي للعيوب كونسيلر طبي للهالات السوداء</td>\n      <td>هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...</td>\n      <td>NaN</td>\n      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...</td>\n      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونس...</td>\n      <td>كريم خافي للعيوب كونسيلر طبي للهالات السوداء ل...</td>\n      <td>هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...</td>\n    </tr>\n    <tr>\n      <th>1589</th>\n      <td>NaN</td>\n      <td>عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...</td>\n      <td>حرج</td>\n      <td>تساقط الشعر</td>\n      <td>جلديه وتناسليه</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ</td>\n      <td>\\n\\n تساقط الشعر بدرجة كبيرة</td>\n      <td>عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...</td>\n      <td>\\n\\n تساقط الشعر بدرجة كبيرة عندي تساقط الشعر ...</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...</td>\n    </tr>\n    <tr>\n      <th>1590</th>\n      <td>NaN</td>\n      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...</td>\n      <td>غير حرج</td>\n      <td>اكسده البشره</td>\n      <td>جلديه وتناسليه</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة</td>\n      <td>NaN</td>\n      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...</td>\n      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف ال...</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...</td>\n    </tr>\n    <tr>\n      <th>1591</th>\n      <td>NaN</td>\n      <td>علاج للاكزيما العصبية</td>\n      <td>حرج</td>\n      <td>اكزيما العصبيه</td>\n      <td>جلديه وتناسليه</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ</td>\n      <td>NaN</td>\n      <td>علاج للاكزيما العصبية</td>\n      <td>علاج للاكزيما العصبية</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية</td>\n    </tr>\n  </tbody>\n</table>\n<p>1592 rows × 12 columns</p>\n</div>"},"metadata":{}}],"execution_count":197},{"cell_type":"code","source":"df['Type']=df['Type'].astype('category')\ndf['target']=df['Type'].cat.codes\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:39:51.920212Z","iopub.execute_input":"2024-12-28T18:39:51.920529Z","iopub.status.idle":"2024-12-28T18:39:51.936689Z","shell.execute_reply.started":"2024-12-28T18:39:51.920506Z","shell.execute_reply":"2024-12-28T18:39:51.935858Z"},"trusted":true},"outputs":[{"execution_count":198,"output_type":"execute_result","data":{"text/plain":"  Image type                                               Post Severity  \\\n0    Unknown  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...      حرج   \n1    Unknown          يخوان شو الحل مع القولون العصبي مشان الله  غير حرج   \n2    Unknown  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...      حرج   \n3    Unknown  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...  غير حرج   \n4    Unknown  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...  غير حرج   \n\n               Diagnosis             Type  \\\n0              مخ واعصاب        مخ واعصاب   \n1             قولون عصبي            باطنه   \n2          كدمه في الوجه  انف واذن وحنجره   \n3                    ضغط            باطنه   \n4  عدم التركيز و النسيان        مخ واعصاب   \n\n                                                 NER  \\\n0  ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1                                     ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ   \n2                        \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ   \n3   \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4  \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n\n                                          Summarised  \\\n0  ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...   \n1                                         ﻗﻮﻟﻮﻥ عصبي   \n2  ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...   \n3  ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...   \n4              ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة   \n\n                                              Refine  \\\n0  \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1  قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2  \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3  صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4  \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n\n                                              Post.1  \\\n0  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...   \n1          يخوان شو الحل مع القولون العصبي مشان الله   \n2  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...   \n3  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...   \n4  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...   \n\n                                             Refined  \\\n0  \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1  قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2  \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3  صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4  \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n\n                                            NER_POST  \\\n0  ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1  ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...   \n2   \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...   \n3   \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4  \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n\n                                     Summarised_POST  target  \n0  ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...       5  \n1  ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...       1  \n2  ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...       0  \n3  ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...       1  \n4  ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...       5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image type</th>\n      <th>Post</th>\n      <th>Severity</th>\n      <th>Diagnosis</th>\n      <th>Type</th>\n      <th>NER</th>\n      <th>Summarised</th>\n      <th>Refine</th>\n      <th>Post.1</th>\n      <th>Refined</th>\n      <th>NER_POST</th>\n      <th>Summarised_POST</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Unknown</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>حرج</td>\n      <td>مخ واعصاب</td>\n      <td>مخ واعصاب</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unknown</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>غير حرج</td>\n      <td>قولون عصبي</td>\n      <td>باطنه</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Unknown</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>حرج</td>\n      <td>كدمه في الوجه</td>\n      <td>انف واذن وحنجره</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Unknown</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>غير حرج</td>\n      <td>ضغط</td>\n      <td>باطنه</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unknown</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>غير حرج</td>\n      <td>عدم التركيز و النسيان</td>\n      <td>مخ واعصاب</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":198},{"cell_type":"code","source":"df['Type'].cat.categories\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:39:54.505261Z","iopub.execute_input":"2024-12-28T18:39:54.505550Z","iopub.status.idle":"2024-12-28T18:39:54.511911Z","shell.execute_reply.started":"2024-12-28T18:39:54.505530Z","shell.execute_reply":"2024-12-28T18:39:54.511217Z"},"trusted":true},"outputs":[{"execution_count":199,"output_type":"execute_result","data":{"text/plain":"Index(['انف واذن وحنجره', 'باطنه', 'باطنه اطفال', 'جلديه وتناسليه', 'عظام',\n       'مخ واعصاب', 'نساء وتوليد'],\n      dtype='object')"},"metadata":{}}],"execution_count":199},{"cell_type":"code","source":"category_map = {code: category for code, category in enumerate(df['Type'].cat.categories)}\ncategory_map","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:39:57.818363Z","iopub.execute_input":"2024-12-28T18:39:57.818647Z","iopub.status.idle":"2024-12-28T18:39:57.824957Z","shell.execute_reply.started":"2024-12-28T18:39:57.818627Z","shell.execute_reply":"2024-12-28T18:39:57.824204Z"},"trusted":true},"outputs":[{"execution_count":200,"output_type":"execute_result","data":{"text/plain":"{0: 'انف واذن وحنجره',\n 1: 'باطنه',\n 2: 'باطنه اطفال',\n 3: 'جلديه وتناسليه',\n 4: 'عظام',\n 5: 'مخ واعصاب',\n 6: 'نساء وتوليد'}"},"metadata":{}}],"execution_count":200},{"cell_type":"code","source":"train_end_point = int(df.shape[0] * 0.6)\nval_end_point = int(df.shape[0] * 0.8)\ndf_train = df.iloc[:train_end_point, :]\ndf_val = df.iloc[train_end_point:val_end_point, :]\ndf_test = df.iloc[val_end_point:, :]\nprint(df_train.shape, df_val.shape, df_test.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:39:59.584415Z","iopub.execute_input":"2024-12-28T18:39:59.584794Z","iopub.status.idle":"2024-12-28T18:39:59.594188Z","shell.execute_reply.started":"2024-12-28T18:39:59.584766Z","shell.execute_reply":"2024-12-28T18:39:59.593322Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(955, 13) (318, 13) (319, 13)\n","output_type":"stream"}],"execution_count":201},{"cell_type":"code","source":"# Drop 'type', 'severity', and 'age' columns along with 'label'\ndataset_train = Dataset.from_pandas(df_train.drop(['Type', 'Severity','Diagnosis', 'Image type','Summarised_POST','NER','Summarised','Refine','Post.1','NER_POST','Post'], axis=1))\ndataset_val = Dataset.from_pandas(df_val.drop(['Type', 'Severity','Diagnosis', 'Image type','Summarised_POST','NER','Summarised','Refine','Post.1','NER_POST','Post'], axis=1))\ndataset_test = Dataset.from_pandas(df_test.drop(['Type', 'Severity','Diagnosis', 'Image type','Summarised_POST','NER','Summarised','Refine','Post.1','NER_POST','Post'], axis=1))\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:01.528190Z","iopub.execute_input":"2024-12-28T18:40:01.528523Z","iopub.status.idle":"2024-12-28T18:40:01.559639Z","shell.execute_reply.started":"2024-12-28T18:40:01.528496Z","shell.execute_reply":"2024-12-28T18:40:01.559019Z"},"trusted":true},"outputs":[],"execution_count":202},{"cell_type":"code","source":"dataset_train_shuffled = dataset_train.shuffle(seed=42)  # Using a seed for reproducibility\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:03.042524Z","iopub.execute_input":"2024-12-28T18:40:03.042815Z","iopub.status.idle":"2024-12-28T18:40:03.052006Z","shell.execute_reply.started":"2024-12-28T18:40:03.042793Z","shell.execute_reply":"2024-12-28T18:40:03.051199Z"},"trusted":true},"outputs":[],"execution_count":203},{"cell_type":"code","source":"\n# Combine them into a single DatasetDict\ndataset = DatasetDict({\n    'train': dataset_train_shuffled,\n    'val': dataset_val,\n    'test': dataset_test\n})\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:04.676743Z","iopub.execute_input":"2024-12-28T18:40:04.677050Z","iopub.status.idle":"2024-12-28T18:40:04.683428Z","shell.execute_reply.started":"2024-12-28T18:40:04.677024Z","shell.execute_reply":"2024-12-28T18:40:04.682664Z"},"trusted":true},"outputs":[{"execution_count":204,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Refined', 'target'],\n        num_rows: 955\n    })\n    val: Dataset({\n        features: ['Refined', 'target'],\n        num_rows: 318\n    })\n    test: Dataset({\n        features: ['Refined', 'target'],\n        num_rows: 319\n    })\n})"},"metadata":{}}],"execution_count":204},{"cell_type":"code","source":"dataset['train']\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:06.240873Z","iopub.execute_input":"2024-12-28T18:40:06.241171Z","iopub.status.idle":"2024-12-28T18:40:06.247110Z","shell.execute_reply.started":"2024-12-28T18:40:06.241147Z","shell.execute_reply":"2024-12-28T18:40:06.246442Z"},"trusted":true},"outputs":[{"execution_count":205,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Refined', 'target'],\n    num_rows: 955\n})"},"metadata":{}}],"execution_count":205},{"cell_type":"code","source":"print(df_train['Type'].unique())\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:07.562532Z","iopub.execute_input":"2024-12-28T18:40:07.562816Z","iopub.status.idle":"2024-12-28T18:40:07.569668Z","shell.execute_reply.started":"2024-12-28T18:40:07.562795Z","shell.execute_reply":"2024-12-28T18:40:07.568775Z"},"trusted":true},"outputs":[{"name":"stdout","text":"['مخ واعصاب', 'باطنه', 'انف واذن وحنجره', 'باطنه اطفال', 'عظام', 'نساء وتوليد', 'جلديه وتناسليه']\nCategories (7, object): ['انف واذن وحنجره', 'باطنه', 'باطنه اطفال', 'جلديه وتناسليه', 'عظام', 'مخ واعصاب', 'نساء وتوليد']\n","output_type":"stream"}],"execution_count":206},{"cell_type":"code","source":"df_train.target.value_counts(normalize=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:09.062521Z","iopub.execute_input":"2024-12-28T18:40:09.062812Z","iopub.status.idle":"2024-12-28T18:40:09.071165Z","shell.execute_reply.started":"2024-12-28T18:40:09.062791Z","shell.execute_reply":"2024-12-28T18:40:09.070445Z"},"trusted":true},"outputs":[{"execution_count":207,"output_type":"execute_result","data":{"text/plain":"target\n1    0.313089\n4    0.184293\n5    0.119372\n2    0.112042\n6    0.110995\n0    0.104712\n3    0.055497\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":207},{"cell_type":"code","source":"\nclass_weights = (1 / df_train.target.value_counts(normalize=True).sort_index()).tolist()\nclass_weights = torch.tensor(class_weights)\nclass_weights = class_weights / class_weights.sum()\nprint(\"Class Weights:\", class_weights)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:10.717669Z","iopub.execute_input":"2024-12-28T18:40:10.717953Z","iopub.status.idle":"2024-12-28T18:40:10.727992Z","shell.execute_reply.started":"2024-12-28T18:40:10.717931Z","shell.execute_reply":"2024-12-28T18:40:10.727239Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Class Weights: tensor([0.1528, 0.0511, 0.1428, 0.2883, 0.0868, 0.1340, 0.1441])\n","output_type":"stream"}],"execution_count":208},{"cell_type":"code","source":"model_name = \"aubmindlab/bert-base-arabertv2\"","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:12.112506Z","iopub.execute_input":"2024-12-28T18:40:12.112784Z","iopub.status.idle":"2024-12-28T18:40:12.117152Z","shell.execute_reply.started":"2024-12-28T18:40:12.112764Z","shell.execute_reply":"2024-12-28T18:40:12.116363Z"},"trusted":true},"outputs":[],"execution_count":209},{"cell_type":"code","source":"\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:13.535718Z","iopub.execute_input":"2024-12-28T18:40:13.535998Z","iopub.status.idle":"2024-12-28T18:40:13.542179Z","shell.execute_reply.started":"2024-12-28T18:40:13.535977Z","shell.execute_reply":"2024-12-28T18:40:13.541398Z"},"trusted":true},"outputs":[],"execution_count":210},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,\n    lora_alpha=8,\n    target_modules=['query', 'key', 'value', 'dense'],  # Simplified layer names\n    lora_dropout=0.05,\n    bias='none',\n    task_type='SEQ_CLS'\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:15.037182Z","iopub.execute_input":"2024-12-28T18:40:15.037498Z","iopub.status.idle":"2024-12-28T18:40:15.042558Z","shell.execute_reply.started":"2024-12-28T18:40:15.037474Z","shell.execute_reply":"2024-12-28T18:40:15.041710Z"},"trusted":true},"outputs":[],"execution_count":211},{"cell_type":"code","source":"\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=len(category_map)\n)\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:17.077487Z","iopub.execute_input":"2024-12-28T18:40:17.077772Z","iopub.status.idle":"2024-12-28T18:40:18.466639Z","shell.execute_reply.started":"2024-12-28T18:40:17.077749Z","shell.execute_reply":"2024-12-28T18:40:18.465821Z"},"trusted":true},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":212,"output_type":"execute_result","data":{"text/plain":"PeftModelForSequenceClassification(\n  (base_model): LoraModel(\n    (model): BertForSequenceClassification(\n      (bert): BertModel(\n        (embeddings): BertEmbeddings(\n          (word_embeddings): Embedding(64000, 768, padding_idx=0)\n          (position_embeddings): Embedding(512, 768)\n          (token_type_embeddings): Embedding(2, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): BertEncoder(\n          (layer): ModuleList(\n            (0-11): 12 x BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (key): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (value): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=768, out_features=3072, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=768, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3072, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3072, out_features=768, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3072, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=768, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (pooler): BertPooler(\n          (dense): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.05, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=768, out_features=16, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=16, out_features=768, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n          )\n          (activation): Tanh()\n        )\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n      (classifier): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=768, out_features=7, bias=True)\n        (modules_to_save): ModuleDict(\n          (default): Linear(in_features=768, out_features=7, bias=True)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":212},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the tokenizer with `add_prefix_space` if necessary for the specific model\ntokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n\n# Assign the `eos_token` to be used as the padding token\nif tokenizer.pad_token is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id  # Use eos_token_id for padding\n    tokenizer.pad_token = tokenizer.eos_token       # Assign eos_token as pad_token\n\n# Update the model configuration to use the tokenizer's pad_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False  # Prevent caching during training for better compatibility\n\n# Resize model embeddings if a new pad_token was added\nif len(tokenizer) != model.config.vocab_size:\n    model.resize_token_embeddings(len(tokenizer))\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:22.661501Z","iopub.execute_input":"2024-12-28T18:40:22.661799Z","iopub.status.idle":"2024-12-28T18:40:23.353369Z","shell.execute_reply.started":"2024-12-28T18:40:22.661775Z","shell.execute_reply":"2024-12-28T18:40:23.352657Z"},"trusted":true},"outputs":[],"execution_count":213},{"cell_type":"code","source":"batch_size = 16  # You can adjust this based on your system's memory capacity\ntext = df_test['Refined'].tolist()\n\n# Initialize an empty list to store the model outputs\nall_outputs = []\n\n# Process the sentences in batches\nfor i in range(0, len(text), batch_size):\n    # Get the batch of sentences\n    batch_sentences = text[i:i + batch_size]\n\n    # Tokenize the batch\n    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n    # Move tensors to the device where the model is (e.g., GPU or CPU)\n    inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n\n    # Perform inference and store the logits\n    with torch.no_grad():\n        outputs = model(**inputs)\n        all_outputs.append(outputs['logits'])","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:27.619899Z","iopub.execute_input":"2024-12-28T18:40:27.620263Z","iopub.status.idle":"2024-12-28T18:40:31.400293Z","shell.execute_reply.started":"2024-12-28T18:40:27.620229Z","shell.execute_reply":"2024-12-28T18:40:31.399386Z"},"trusted":true},"outputs":[],"execution_count":214},{"cell_type":"code","source":"\nfinal_outputs = torch.cat(all_outputs, dim=0)\nfinal_outputs\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:34.170050Z","iopub.execute_input":"2024-12-28T18:40:34.170397Z","iopub.status.idle":"2024-12-28T18:40:34.180007Z","shell.execute_reply.started":"2024-12-28T18:40:34.170369Z","shell.execute_reply":"2024-12-28T18:40:34.179215Z"},"trusted":true},"outputs":[{"execution_count":215,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.4693, -0.9560, -0.5505,  ...,  0.3677, -0.3434, -0.1829],\n        [-0.7394, -0.7682, -0.8440,  ...,  0.0321, -0.4879,  0.0377],\n        [-0.6450, -1.0139, -0.5635,  ...,  0.3519, -0.2781,  0.0833],\n        ...,\n        [-0.7130, -0.7879, -0.8520,  ...,  0.0989, -0.3132, -0.3217],\n        [-0.2084, -0.8008, -0.6882,  ...,  0.1995,  0.1437, -0.5251],\n        [-0.0124, -0.8745, -0.7275,  ...,  0.1929, -0.0470, -0.3539]],\n       device='cuda:0')"},"metadata":{}}],"execution_count":215},{"cell_type":"code","source":"final_outputs.argmax(axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:36.997493Z","iopub.execute_input":"2024-12-28T18:40:36.997774Z","iopub.status.idle":"2024-12-28T18:40:37.009958Z","shell.execute_reply.started":"2024-12-28T18:40:36.997751Z","shell.execute_reply":"2024-12-28T18:40:37.009194Z"},"trusted":true},"outputs":[{"execution_count":216,"output_type":"execute_result","data":{"text/plain":"tensor([4, 6, 4, 6, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n        4, 4, 5, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4,\n        4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n        4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 6, 4, 6, 4, 4,\n        4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n        6, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4,\n        4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n        4, 4, 4, 4, 5, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5,\n        4, 4, 5, 4, 4, 4, 4, 4, 4, 5, 4, 6, 4, 4, 4, 4, 4, 4, 4, 6, 6, 4, 4, 5,\n        4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4,\n        4, 6, 4, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4,\n        4, 4, 4, 5, 4, 4, 4], device='cuda:0')"},"metadata":{}}],"execution_count":216},{"cell_type":"code","source":"\ndf_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\ndf_test['predictions']","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:39.124573Z","iopub.execute_input":"2024-12-28T18:40:39.124863Z","iopub.status.idle":"2024-12-28T18:40:39.134390Z","shell.execute_reply.started":"2024-12-28T18:40:39.124832Z","shell.execute_reply":"2024-12-28T18:40:39.133517Z"},"trusted":true},"outputs":[{"name":"stderr","text":"<ipython-input-217-7c1d2547ae19>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n","output_type":"stream"},{"execution_count":217,"output_type":"execute_result","data":{"text/plain":"1273    4\n1274    6\n1275    4\n1276    6\n1277    4\n       ..\n1587    4\n1588    5\n1589    4\n1590    4\n1591    4\nName: predictions, Length: 319, dtype: int64"},"metadata":{}}],"execution_count":217},{"cell_type":"code","source":"def get_performance_metrics(df_test):\n  y_test = df_test.target\n  y_pred = df_test.predictions\n\n  print(\"Confusion Matrix:\")\n  print(confusion_matrix(y_test, y_pred))\n\n  print(\"\\nClassification Report:\")\n  print(classification_report(y_test, y_pred))\n\n  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:41.874093Z","iopub.execute_input":"2024-12-28T18:40:41.874418Z","iopub.status.idle":"2024-12-28T18:40:41.879959Z","shell.execute_reply.started":"2024-12-28T18:40:41.874396Z","shell.execute_reply":"2024-12-28T18:40:41.879250Z"},"trusted":true},"outputs":[],"execution_count":218},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"get_performance_metrics(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:46.794349Z","iopub.execute_input":"2024-12-28T18:40:46.794642Z","iopub.status.idle":"2024-12-28T18:40:46.818000Z","shell.execute_reply.started":"2024-12-28T18:40:46.794611Z","shell.execute_reply":"2024-12-28T18:40:46.817177Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[  0   0   0   0  20   0   1]\n [  0   0   0   0  36   0   4]\n [  0   0   0   0  54   0   6]\n [  0   0   0   0 128  12   7]\n [  0   0   0   0   5   0   0]\n [  0   0   0   0  10   0   1]\n [  0   0   0   0  28   2   5]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        21\n           1       0.00      0.00      0.00        40\n           2       0.00      0.00      0.00        60\n           3       0.00      0.00      0.00       147\n           4       0.02      1.00      0.03         5\n           5       0.00      0.00      0.00        11\n           6       0.21      0.14      0.17        35\n\n    accuracy                           0.03       319\n   macro avg       0.03      0.16      0.03       319\nweighted avg       0.02      0.03      0.02       319\n\nBalanced Accuracy Score: 0.16326530612244897\nAccuracy Score: 0.03134796238244514\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":219},{"cell_type":"code","source":"df_test['predictions'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:50.313616Z","iopub.execute_input":"2024-12-28T18:40:50.313910Z","iopub.status.idle":"2024-12-28T18:40:50.321201Z","shell.execute_reply.started":"2024-12-28T18:40:50.313888Z","shell.execute_reply":"2024-12-28T18:40:50.320497Z"},"trusted":true},"outputs":[{"execution_count":220,"output_type":"execute_result","data":{"text/plain":"predictions\n4    281\n6     24\n5     14\nName: count, dtype: int64"},"metadata":{}}],"execution_count":220},{"cell_type":"code","source":"MAX_LEN = 512","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:52.376088Z","iopub.execute_input":"2024-12-28T18:40:52.376420Z","iopub.status.idle":"2024-12-28T18:40:52.381039Z","shell.execute_reply.started":"2024-12-28T18:40:52.376396Z","shell.execute_reply":"2024-12-28T18:40:52.380206Z"},"trusted":true},"outputs":[],"execution_count":221},{"cell_type":"code","source":"def preprocessing_function(examples):\n    return tokenizer(examples['Refined'], truncation=True, max_length=MAX_LEN)\n\ntokenized_datasets = dataset.map(preprocessing_function, batched=True, remove_columns=['Refined'])\ntokenized_datasets = tokenized_datasets.rename_column(\"target\", \"label\")\ntokenized_datasets.set_format(\"torch\")","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:54.008171Z","iopub.execute_input":"2024-12-28T18:40:54.008509Z","iopub.status.idle":"2024-12-28T18:40:54.337935Z","shell.execute_reply.started":"2024-12-28T18:40:54.008470Z","shell.execute_reply":"2024-12-28T18:40:54.337087Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/955 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"557e78dbcda24f1484b9123a25212aca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/318 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00f5f490a8204a2294d1d1f1627fcd7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af0475fe87c0434faf5ee5cb7a34134e"}},"metadata":{}}],"execution_count":222},{"cell_type":"code","source":"collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:56.384022Z","iopub.execute_input":"2024-12-28T18:40:56.384345Z","iopub.status.idle":"2024-12-28T18:40:56.388657Z","shell.execute_reply.started":"2024-12-28T18:40:56.384319Z","shell.execute_reply":"2024-12-28T18:40:56.387773Z"},"trusted":true},"outputs":[],"execution_count":223},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:57.943379Z","iopub.execute_input":"2024-12-28T18:40:57.943683Z","iopub.status.idle":"2024-12-28T18:40:57.948783Z","shell.execute_reply.started":"2024-12-28T18:40:57.943662Z","shell.execute_reply":"2024-12-28T18:40:57.947923Z"},"trusted":true},"outputs":[],"execution_count":224},{"cell_type":"code","source":"class CustomTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Ensure class_weights is handled correctly\n        if class_weights is not None:\n            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n        else:\n            self.class_weights = None\n        self.epoch_logs = []\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        # Extract labels and convert them to long type for cross_entropy\n        labels = inputs.pop(\"labels\").long()\n\n        # Forward pass\n        outputs = model(**inputs)\n\n        # Extract logits assuming they are directly outputted by the model\n        logits = outputs.get('logits')\n\n        # Compute custom loss with class weights for imbalanced data handling\n        if self.class_weights is not None:\n            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n        else:\n            loss = F.cross_entropy(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss\n\n    def log_metrics(self, metrics, epoch):\n        # Custom function to log and save metrics\n        print(f\"Epoch {epoch}: {metrics}\")  # Print metrics\n        self.epoch_logs.append(metrics)  # Store the results\n\n    def training_epoch_end(self, outputs):\n        # Overriding to log after each epoch\n        metrics = self.evaluate()  # Evaluate after each epoch\n        self.log_metrics(metrics, epoch=len(self.epoch_logs))  # Log metrics\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:40:59.668893Z","iopub.execute_input":"2024-12-28T18:40:59.669235Z","iopub.status.idle":"2024-12-28T18:40:59.676761Z","shell.execute_reply.started":"2024-12-28T18:40:59.669209Z","shell.execute_reply":"2024-12-28T18:40:59.676014Z"},"trusted":true},"outputs":[],"execution_count":225},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"72d0e227429bd347553a5563b7396b82cb04a364\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:41:01.687875Z","iopub.execute_input":"2024-12-28T18:41:01.688179Z","iopub.status.idle":"2024-12-28T18:41:01.695579Z","shell.execute_reply.started":"2024-12-28T18:41:01.688156Z","shell.execute_reply":"2024-12-28T18:41:01.694885Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":226,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":226},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='sentiment_classification',\n    logging_dir='./logs',\n    logging_steps=10,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    num_train_epochs=25,\n    learning_rate=1e-4,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    weight_decay=0.01\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:41:13.859825Z","iopub.execute_input":"2024-12-28T18:41:13.860122Z","iopub.status.idle":"2024-12-28T18:41:13.895325Z","shell.execute_reply.started":"2024-12-28T18:41:13.860101Z","shell.execute_reply":"2024-12-28T18:41:13.894595Z"},"trusted":true},"outputs":[],"execution_count":227},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['val'],\n    tokenizer=tokenizer,\n    data_collator=collate_fn,\n    compute_metrics=lambda eval_pred: {\n        'balanced_accuracy': balanced_accuracy_score(eval_pred[1], np.argmax(eval_pred[0], axis=1)),\n        'accuracy': accuracy_score(eval_pred[1], np.argmax(eval_pred[0], axis=1))\n    },\n    class_weights=class_weights  # Pass the weights tensor\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:41:17.498066Z","iopub.execute_input":"2024-12-28T18:41:17.498396Z","iopub.status.idle":"2024-12-28T18:41:17.514371Z","shell.execute_reply.started":"2024-12-28T18:41:17.498371Z","shell.execute_reply":"2024-12-28T18:41:17.513451Z"},"trusted":true},"outputs":[{"name":"stderr","text":"<ipython-input-225-f7f84dfa52ac>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n","output_type":"stream"}],"execution_count":228},{"cell_type":"code","source":"train_result = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-12-28T18:41:36.359760Z","iopub.execute_input":"2024-12-28T18:41:36.360089Z","iopub.status.idle":"2024-12-28T19:09:29.403584Z","shell.execute_reply.started":"2024-12-28T18:41:36.360063Z","shell.execute_reply":"2024-12-28T19:09:29.402726Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3000/3000 27:52, Epoch 25/25]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Balanced Accuracy</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.962100</td>\n      <td>1.893147</td>\n      <td>0.171948</td>\n      <td>0.229560</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.788900</td>\n      <td>1.792520</td>\n      <td>0.248294</td>\n      <td>0.345912</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.460300</td>\n      <td>1.463584</td>\n      <td>0.395515</td>\n      <td>0.468553</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.217800</td>\n      <td>1.114347</td>\n      <td>0.530178</td>\n      <td>0.597484</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.118400</td>\n      <td>1.036068</td>\n      <td>0.567156</td>\n      <td>0.650943</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.962600</td>\n      <td>1.006758</td>\n      <td>0.610806</td>\n      <td>0.679245</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.776700</td>\n      <td>1.017590</td>\n      <td>0.609520</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.770000</td>\n      <td>0.880330</td>\n      <td>0.628049</td>\n      <td>0.713836</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.456600</td>\n      <td>0.952373</td>\n      <td>0.627063</td>\n      <td>0.691824</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.506300</td>\n      <td>1.009790</td>\n      <td>0.628210</td>\n      <td>0.679245</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.395500</td>\n      <td>0.957900</td>\n      <td>0.624169</td>\n      <td>0.691824</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.381800</td>\n      <td>0.933197</td>\n      <td>0.634491</td>\n      <td>0.723270</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.411900</td>\n      <td>1.050307</td>\n      <td>0.613354</td>\n      <td>0.679245</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.350200</td>\n      <td>0.981709</td>\n      <td>0.611118</td>\n      <td>0.682390</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.351800</td>\n      <td>1.011483</td>\n      <td>0.622635</td>\n      <td>0.701258</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.181000</td>\n      <td>1.113418</td>\n      <td>0.632205</td>\n      <td>0.676101</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.201900</td>\n      <td>1.132014</td>\n      <td>0.639845</td>\n      <td>0.698113</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.310400</td>\n      <td>1.095887</td>\n      <td>0.662895</td>\n      <td>0.716981</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.171000</td>\n      <td>1.109718</td>\n      <td>0.664506</td>\n      <td>0.710692</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.130700</td>\n      <td>1.144648</td>\n      <td>0.644353</td>\n      <td>0.707547</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.170500</td>\n      <td>1.189707</td>\n      <td>0.663599</td>\n      <td>0.710692</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.125800</td>\n      <td>1.161250</td>\n      <td>0.644885</td>\n      <td>0.707547</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.136400</td>\n      <td>1.152753</td>\n      <td>0.668922</td>\n      <td>0.723270</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.170500</td>\n      <td>1.183665</td>\n      <td>0.663933</td>\n      <td>0.713836</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.275800</td>\n      <td>1.195523</td>\n      <td>0.663933</td>\n      <td>0.713836</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":229},{"cell_type":"code","source":"df_train['target'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-15T14:05:57.851698Z","iopub.execute_input":"2024-12-15T14:05:57.852060Z","iopub.status.idle":"2024-12-15T14:05:57.860769Z","shell.execute_reply.started":"2024-12-15T14:05:57.852031Z","shell.execute_reply":"2024-12-15T14:05:57.859862Z"},"trusted":true},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"target\n1    0.313089\n4    0.184293\n5    0.119372\n2    0.112042\n6    0.110995\n0    0.104712\n3    0.055497\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"df_test['target'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-15T14:05:59.585995Z","iopub.execute_input":"2024-12-15T14:05:59.586322Z","iopub.status.idle":"2024-12-15T14:05:59.594499Z","shell.execute_reply.started":"2024-12-15T14:05:59.586293Z","shell.execute_reply":"2024-12-15T14:05:59.593715Z"},"trusted":true},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"target\n3    0.460815\n2    0.188088\n1    0.125392\n6    0.109718\n0    0.065831\n5    0.034483\n4    0.015674\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"def make_predictions(model, df_test):\n\n    # Convert summaries to a list\n    sentences = df_test['Refined'].tolist()\n\n    # Define the batch size\n    batch_size = 16  # You can adjust this based on your system's memory capacity\n\n    # Initialize an empty list to store the model outputs\n    all_outputs = []\n\n    # Process the sentences in batches\n    for i in range(0, len(sentences), batch_size):\n        # Get the batch of sentences\n        batch_sentences = sentences[i:i + batch_size]\n\n        # Tokenize the batch\n        inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n        # Move tensors to the device where the model is (e.g., GPU or CPU)\n        inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n\n        # Perform inference and store the logits\n        with torch.no_grad():\n            outputs = model(**inputs)\n            all_outputs.append(outputs['logits'])\n\n    final_outputs = torch.cat(all_outputs, dim=0)\n\n    # Update using .loc to avoid SettingWithCopyWarning\n    df_test.loc[:, 'predictions'] = final_outputs.argmax(axis=1).cpu().numpy()\n\n    # Apply category mapping\n    df_test.loc[:, 'predictions'] = df_test['predictions'].apply(lambda l: category_map[l])\n\n# Make predictions\nmake_predictions(model, df_test)","metadata":{"execution":{"iopub.status.busy":"2024-12-28T19:09:35.470902Z","iopub.execute_input":"2024-12-28T19:09:35.471249Z","iopub.status.idle":"2024-12-28T19:09:39.201675Z","shell.execute_reply.started":"2024-12-28T19:09:35.471222Z","shell.execute_reply":"2024-12-28T19:09:39.200971Z"},"trusted":true},"outputs":[],"execution_count":230},{"cell_type":"code","source":"def get_performance_metrics(df_test):\n    # Convert both target and predictions back to numeric using category_map\n    reverse_category_map = {v: k for k, v in category_map.items()}  # Reverse the category_map to map strings to numbers\n    y_test = df_test['target']\n    y_pred = df_test['predictions'].apply(lambda x: reverse_category_map[x])\n\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_test, y_pred))\n\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n\n    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n\n# Run the function again\nget_performance_metrics(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-12-28T19:09:45.865588Z","iopub.execute_input":"2024-12-28T19:09:45.865890Z","iopub.status.idle":"2024-12-28T19:09:45.890179Z","shell.execute_reply.started":"2024-12-28T19:09:45.865854Z","shell.execute_reply":"2024-12-28T19:09:45.889113Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[ 14   3   2   0   1   1   0]\n [  9  20   1   0   0   3   7]\n [  3   0  49   2   3   1   2]\n [  4   3  17 114   5   2   2]\n [  1   0   0   1   2   0   1]\n [  1   0   0   1   1   4   4]\n [  0   2   1   2   2   0  28]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.44      0.67      0.53        21\n           1       0.71      0.50      0.59        40\n           2       0.70      0.82      0.75        60\n           3       0.95      0.78      0.85       147\n           4       0.14      0.40      0.21         5\n           5       0.36      0.36      0.36        11\n           6       0.64      0.80      0.71        35\n\n    accuracy                           0.72       319\n   macro avg       0.56      0.62      0.57       319\nweighted avg       0.77      0.72      0.74       319\n\nBalanced Accuracy Score: 0.6174971287216184\nAccuracy Score: 0.7241379310344828\n","output_type":"stream"}],"execution_count":231},{"cell_type":"code","source":"import os\n\n# Directory to save the model (inside /kaggle/outputs for persistence)\nsave_directory = \"/kaggle/outputs/arabert-post\"\n\n# Create the directory if it does not exist\nos.makedirs(save_directory, exist_ok=True)\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n","metadata":{"execution":{"iopub.status.busy":"2024-12-28T16:55:47.105737Z","iopub.execute_input":"2024-12-28T16:55:47.106064Z","iopub.status.idle":"2024-12-28T16:55:47.611807Z","shell.execute_reply.started":"2024-12-28T16:55:47.106037Z","shell.execute_reply":"2024-12-28T16:55:47.611043Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model and tokenizer saved successfully to '/kaggle/outputs/arabert-post'\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"import os\n\n# Directory to save the model (inside /kaggle/outputs for persistence)\nsave_directory = \"/kaggle/working/arabert-post\"\n\n# Create the directory if it does not exist\nos.makedirs(save_directory, exist_ok=True)\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T16:56:50.405650Z","iopub.execute_input":"2024-12-28T16:56:50.405944Z","iopub.status.idle":"2024-12-28T16:56:50.894824Z","shell.execute_reply.started":"2024-12-28T16:56:50.405922Z","shell.execute_reply":"2024-12-28T16:56:50.893896Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved successfully to '/kaggle/working/arabert-post'\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import os\n\n# Directory to save the model (inside /kaggle/outputs for persistence)\nsave_directory = \"arabert-post\"\n\n# Create the directory if it does not exist\nos.makedirs(save_directory, exist_ok=True)\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T16:58:27.352629Z","iopub.execute_input":"2024-12-28T16:58:27.352931Z","iopub.status.idle":"2024-12-28T16:58:27.846171Z","shell.execute_reply.started":"2024-12-28T16:58:27.352906Z","shell.execute_reply":"2024-12-28T16:58:27.845346Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved successfully to 'arabert-post'\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"!zip -r arabert_post_model.zip /kaggle/working/arabert-post\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T17:10:43.942200Z","iopub.execute_input":"2024-12-28T17:10:43.942501Z","iopub.status.idle":"2024-12-28T17:10:44.953771Z","shell.execute_reply.started":"2024-12-28T17:10:43.942477Z","shell.execute_reply":"2024-12-28T17:10:44.952771Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/arabert-post/ (stored 0%)\n  adding: kaggle/working/arabert-post/tokenizer.json","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":" (deflated 73%)\n  adding: kaggle/working/arabert-post/vocab.txt (deflated 62%)\n  adding: kaggle/working/arabert-post/special_tokens_map.json (deflated 80%)\n  adding: kaggle/working/arabert-post/README.md (deflated 66%)\n  adding: kaggle/working/arabert-post/tokenizer_config.json (deflated 90%)\n  adding: kaggle/working/arabert-post/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/arabert-post/adapter_config.json (deflated 52%)\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'arabert_post_model.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T17:11:31.014778Z","iopub.execute_input":"2024-12-28T17:11:31.015117Z","iopub.status.idle":"2024-12-28T17:11:31.022218Z","shell.execute_reply.started":"2024-12-28T17:11:31.015090Z","shell.execute_reply":"2024-12-28T17:11:31.021470Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/arabert_post_model.zip","text/html":"<a href='arabert_post_model.zip' target='_blank'>arabert_post_model.zip</a><br>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"import os\n\n# Directory to save the model (inside /kaggle/outputs for persistence)\nsave_directory = \"/kaggle/working/arabert-summarized\"\n\n# Create the directory if it does not exist\nos.makedirs(save_directory, exist_ok=True)\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:33:22.256431Z","iopub.execute_input":"2024-12-28T18:33:22.256736Z","iopub.status.idle":"2024-12-28T18:33:22.738429Z","shell.execute_reply.started":"2024-12-28T18:33:22.256715Z","shell.execute_reply":"2024-12-28T18:33:22.737586Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved successfully to '/kaggle/working/arabert-summarized'\n","output_type":"stream"}],"execution_count":194},{"cell_type":"code","source":"!zip -r arabert_summarized_model.zip /kaggle/working/arabert-summarized\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:33:25.378825Z","iopub.execute_input":"2024-12-28T18:33:25.379123Z","iopub.status.idle":"2024-12-28T18:33:26.409440Z","shell.execute_reply.started":"2024-12-28T18:33:25.379100Z","shell.execute_reply":"2024-12-28T18:33:26.408429Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/arabert-summarized/ (stored 0%)\n  adding: kaggle/working/arabert-summarized/tokenizer.json","output_type":"stream"},{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":" (deflated 73%)\n  adding: kaggle/working/arabert-summarized/vocab.txt (deflated 62%)\n  adding: kaggle/working/arabert-summarized/special_tokens_map.json (deflated 80%)\n  adding: kaggle/working/arabert-summarized/README.md (deflated 66%)\n  adding: kaggle/working/arabert-summarized/tokenizer_config.json (deflated 90%)\n  adding: kaggle/working/arabert-summarized/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/arabert-summarized/adapter_config.json (deflated 52%)\n","output_type":"stream"}],"execution_count":195},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'arabert_summarized_model.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:33:29.213939Z","iopub.execute_input":"2024-12-28T18:33:29.214299Z","iopub.status.idle":"2024-12-28T18:33:29.221161Z","shell.execute_reply.started":"2024-12-28T18:33:29.214271Z","shell.execute_reply":"2024-12-28T18:33:29.220360Z"}},"outputs":[{"execution_count":196,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/arabert_summarized_model.zip","text/html":"<a href='arabert_summarized_model.zip' target='_blank'>arabert_summarized_model.zip</a><br>"},"metadata":{}}],"execution_count":196},{"cell_type":"code","source":"import os\n\n# Directory to save the model (inside /kaggle/outputs for persistence)\nsave_directory = \"/kaggle/working/arabert-refined\"\n\n# Create the directory if it does not exist\nos.makedirs(save_directory, exist_ok=True)\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved successfully to '{save_directory}'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T19:10:46.383970Z","iopub.execute_input":"2024-12-28T19:10:46.384322Z","iopub.status.idle":"2024-12-28T19:10:46.878540Z","shell.execute_reply.started":"2024-12-28T19:10:46.384296Z","shell.execute_reply":"2024-12-28T19:10:46.877461Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved successfully to '/kaggle/working/arabert-refined'\n","output_type":"stream"}],"execution_count":232},{"cell_type":"code","source":"!zip -r arabert_refined_model.zip /kaggle/working/arabert-refined\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T19:11:35.803312Z","iopub.execute_input":"2024-12-28T19:11:35.803787Z","iopub.status.idle":"2024-12-28T19:11:36.887294Z","shell.execute_reply.started":"2024-12-28T19:11:35.803750Z","shell.execute_reply":"2024-12-28T19:11:36.886361Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/arabert-refined/ (stored 0%)\n  adding: kaggle/working/arabert-refined/tokenizer.json (deflated 73%)\n  adding: kaggle/working/arabert-refined/vocab.txt (deflated 62%)\n  adding: kaggle/working/arabert-refined/special_tokens_map.json (deflated 80%)\n  adding: kaggle/working/arabert-refined/README.md (deflated 66%)\n  adding: kaggle/working/arabert-refined/tokenizer_config.json (deflated 90%)\n  adding: kaggle/working/arabert-refined/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/arabert-refined/adapter_config.json (deflated 52%)\n","output_type":"stream"}],"execution_count":233},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'arabert_refined_model.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T19:11:38.609681Z","iopub.execute_input":"2024-12-28T19:11:38.609996Z","iopub.status.idle":"2024-12-28T19:11:38.616930Z","shell.execute_reply.started":"2024-12-28T19:11:38.609973Z","shell.execute_reply":"2024-12-28T19:11:38.616225Z"}},"outputs":[{"execution_count":234,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/arabert_refined_model.zip","text/html":"<a href='arabert_refined_model.zip' target='_blank'>arabert_refined_model.zip</a><br>"},"metadata":{}}],"execution_count":234},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}