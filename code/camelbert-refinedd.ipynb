{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10033022,"sourceType":"datasetVersion","datasetId":6179515},{"sourceId":10043659,"sourceType":"datasetVersion","datasetId":6187325},{"sourceId":10200951,"sourceType":"datasetVersion","datasetId":6303669},{"sourceId":10322007,"sourceType":"datasetVersion","datasetId":6390854}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install Pytorch\n%pip install \"torch==2.2.2\" tensorboard\n\n# Install Hugging Face libraries\n%pip install  --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-28T20:58:04.775479Z","iopub.execute_input":"2024-12-28T20:58:04.775821Z","iopub.status.idle":"2024-12-28T20:58:11.985072Z","shell.execute_reply.started":"2024-12-28T20:58:04.775789Z","shell.execute_reply":"2024-12-28T20:58:11.983989Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2024.2.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.6.85)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\nRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (71.0.4)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: transformers==4.40.0 in /usr/local/lib/python3.10/dist-packages (4.40.0)\nRequirement already satisfied: datasets==2.18.0 in /usr/local/lib/python3.10/dist-packages (2.18.0)\nRequirement already satisfied: accelerate==0.29.3 in /usr/local/lib/python3.10/dist-packages (0.29.3)\nRequirement already satisfied: evaluate==0.4.1 in /usr/local/lib/python3.10/dist-packages (0.4.1)\nRequirement already satisfied: bitsandbytes==0.43.1 in /usr/local/lib/python3.10/dist-packages (0.43.1)\nRequirement already satisfied: huggingface_hub==0.22.2 in /usr/local/lib/python3.10/dist-packages (0.22.2)\nRequirement already satisfied: trl==0.8.6 in /usr/local/lib/python3.10/dist-packages (0.8.6)\nRequirement already satisfied: peft==0.10.0 in /usr/local/lib/python3.10/dist-packages (0.10.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (4.66.5)\nRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (18.1.0)\nRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (2.1.4)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0) (2024.2.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.18.0) (3.10.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (2.2.2)\nRequirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (0.18.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.22.2) (4.12.2)\nRequirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl==0.8.6) (0.9.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.18.0) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3) (12.6.85)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (13.8.1)\nRequirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (1.7.1)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.8.6) (4.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.18.0) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"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\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T20:58:11.986791Z","iopub.execute_input":"2024-12-28T20:58:11.987139Z","iopub.status.idle":"2024-12-28T20:58:12.066369Z","shell.execute_reply.started":"2024-12-28T20:58:11.987111Z","shell.execute_reply":"2024-12-28T20:58:12.065686Z"}},"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"c26df6b59bfb128917e73bbb00a79ca7e9324a11\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T20:58:13.291626Z","iopub.execute_input":"2024-12-28T20:58:13.291895Z","iopub.status.idle":"2024-12-28T20:58:13.345185Z","shell.execute_reply.started":"2024-12-28T20:58:13.291873Z","shell.execute_reply":"2024-12-28T20:58:13.344542Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"import os\nimport random\nimport functools\nimport csv\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport evaluate\nimport bitsandbytes as bnb\nimport accelerate\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n\nfrom datasets import Dataset, DatasetDict\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T20:58:16.260741Z","iopub.execute_input":"2024-12-28T20:58:16.261085Z","iopub.status.idle":"2024-12-28T20:58:16.266645Z","shell.execute_reply.started":"2024-12-28T20:58:16.261054Z","shell.execute_reply":"2024-12-28T20:58:16.265613Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"!pip install evaluate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install bitsandbytes accelerate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install peft\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import csv\nimport pandas as pd\ndf = pd.read_excel(\"/kaggle/input/dataexxcel/reshaped_output2 (6).xlsx\")\n# Slice the first 1951 rows\ndf = df.iloc[:1592]\n\n# Display the DataFrame or its information\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:21.902716Z","iopub.execute_input":"2024-12-28T21:01:21.903077Z","iopub.status.idle":"2024-12-28T21:01:22.267728Z","shell.execute_reply.started":"2024-12-28T21:01:21.903048Z","shell.execute_reply":"2024-12-28T21:01:22.266705Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"     Image type                                               Post Severity  \\\n0       Unknown  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...      حرج   \n1       Unknown          يخوان شو الحل مع القولون العصبي مشان الله  غير حرج   \n2       Unknown  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...      حرج   \n3       Unknown  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...  غير حرج   \n4       Unknown  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...  غير حرج   \n...         ...                                                ...      ...   \n1587        NaN                    شعرى وقع من الامام فقط اعمل ايه  غير حرج   \n1588        NaN  لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...  غير حرج   \n1589        NaN  عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...      حرج   \n1590        NaN  بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...  غير حرج   \n1591        NaN                              علاج للاكزيما العصبية      حرج   \n\n                  Diagnosis             Type  \\\n0                 مخ واعصاب        مخ واعصاب   \n1                قولون عصبي            باطنه   \n2             كدمه في الوجه  انف واذن وحنجره   \n3                       ضغط            باطنه   \n4     عدم التركيز و النسيان        مخ واعصاب   \n...                     ...              ...   \n1587            تساقط الشعر   جلديه وتناسليه   \n1588            هالات سوداء   جلديه وتناسليه   \n1589            تساقط الشعر   جلديه وتناسليه   \n1590           اكسده البشره   جلديه وتناسليه   \n1591         اكزيما العصبيه   جلديه وتناسليه   \n\n                                                    NER  \\\n0     ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1                                        ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ   \n2                           \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ   \n3      \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4     \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n...                                                 ...   \n1587                             شعرى وقع من الامام فقط   \n1588       كريم خافي للعيوب كونسيلر طبي للهالات السوداء   \n1589                                        ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ   \n1590                       ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة   \n1591                                    ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ   \n\n                                             Summarised  \\\n0     ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...   \n1                                            ﻗﻮﻟﻮﻥ عصبي   \n2     ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...   \n3     ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...   \n4                 ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة   \n...                                                 ...   \n1587                             شعرى وقع من الامام فقط   \n1588  هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...   \n1589                                        ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ   \n1590                       ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة   \n1591                                    ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ   \n\n                                                 Refine  \\\n0     \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1     قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2     \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3     صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4     \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n...                                                 ...   \n1587                                                NaN   \n1588                                                NaN   \n1589                       \\n\\n تساقط الشعر بدرجة كبيرة   \n1590                                                NaN   \n1591                                                NaN   \n\n                                                 Post.1  \\\n0     السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...   \n1             يخوان شو الحل مع القولون العصبي مشان الله   \n2     لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...   \n3     حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...   \n4     عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...   \n...                                                 ...   \n1587                    شعرى وقع من الامام فقط اعمل ايه   \n1588  لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...   \n1589  عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...   \n1590  بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...   \n1591                              علاج للاكزيما العصبية   \n\n                                                Refined  \\\n0     \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1     قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2     \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3     صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4     \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n...                                                 ...   \n1587                    شعرى وقع من الامام فقط اعمل ايه   \n1588   لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونس...   \n1589  \\n\\n تساقط الشعر بدرجة كبيرة عندي تساقط الشعر ...   \n1590   بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف ال...   \n1591                              علاج للاكزيما العصبية   \n\n                                               NER_POST  \\\n0     ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1     ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...   \n2      \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...   \n3      \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4     \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n...                                                 ...   \n1587  شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...   \n1588  كريم خافي للعيوب كونسيلر طبي للهالات السوداء ل...   \n1589  ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...   \n1590  ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...   \n1591              ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية   \n\n                                        Summarised_POST  \n0     ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...  \n1     ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...  \n2     ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...  \n3     ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...  \n4     ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...  \n...                                                 ...  \n1587  شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...  \n1588  هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...  \n1589  ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...  \n1590  ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...  \n1591              ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية  \n\n[1592 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image type</th>\n      <th>Post</th>\n      <th>Severity</th>\n      <th>Diagnosis</th>\n      <th>Type</th>\n      <th>NER</th>\n      <th>Summarised</th>\n      <th>Refine</th>\n      <th>Post.1</th>\n      <th>Refined</th>\n      <th>NER_POST</th>\n      <th>Summarised_POST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Unknown</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>حرج</td>\n      <td>مخ واعصاب</td>\n      <td>مخ واعصاب</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unknown</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>غير حرج</td>\n      <td>قولون عصبي</td>\n      <td>باطنه</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Unknown</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>حرج</td>\n      <td>كدمه في الوجه</td>\n      <td>انف واذن وحنجره</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Unknown</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>غير حرج</td>\n      <td>ضغط</td>\n      <td>باطنه</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unknown</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>غير حرج</td>\n      <td>عدم التركيز و النسيان</td>\n      <td>مخ واعصاب</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1587</th>\n      <td>NaN</td>\n      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n      <td>غير حرج</td>\n      <td>تساقط الشعر</td>\n      <td>جلديه وتناسليه</td>\n      <td>شعرى وقع من الامام فقط</td>\n      <td>شعرى وقع من الامام فقط</td>\n      <td>NaN</td>\n      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n      <td>شعرى وقع من الامام فقط اعمل ايه</td>\n      <td>شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...</td>\n      <td>شعرى وقع من الامام فقط شعرى وقع من الامام فقط ...</td>\n    </tr>\n    <tr>\n      <th>1588</th>\n      <td>NaN</td>\n      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...</td>\n      <td>غير حرج</td>\n      <td>هالات سوداء</td>\n      <td>جلديه وتناسليه</td>\n      <td>كريم خافي للعيوب كونسيلر طبي للهالات السوداء</td>\n      <td>هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...</td>\n      <td>NaN</td>\n      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونسي...</td>\n      <td>لو سمحت يادكتور هل يوجد كريم خافي للعيوب كونس...</td>\n      <td>كريم خافي للعيوب كونسيلر طبي للهالات السوداء ل...</td>\n      <td>هل يوجد كريم خافي للعيوب كونسيلر طبي للهالات ا...</td>\n    </tr>\n    <tr>\n      <th>1589</th>\n      <td>NaN</td>\n      <td>عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...</td>\n      <td>حرج</td>\n      <td>تساقط الشعر</td>\n      <td>جلديه وتناسليه</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ</td>\n      <td>\\n\\n تساقط الشعر بدرجة كبيرة</td>\n      <td>عندي تساقط الشعر بدرجة كبيرة لدرجة احط يدي على...</td>\n      <td>\\n\\n تساقط الشعر بدرجة كبيرة عندي تساقط الشعر ...</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...</td>\n      <td>ﺗﺴﺎﻗﻂ ﺍﻟﺸﻌﺮ عندي تساقط الشعر بدرجة كبيرة لدرجة...</td>\n    </tr>\n    <tr>\n      <th>1590</th>\n      <td>NaN</td>\n      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...</td>\n      <td>غير حرج</td>\n      <td>اكسده البشره</td>\n      <td>جلديه وتناسليه</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة</td>\n      <td>NaN</td>\n      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف الب...</td>\n      <td>بشرتي دهنيه حساسه ودايما بتأكسد حتى وانا ف ال...</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...</td>\n      <td>ﺗﺄﻛﺴﺪ ﺍلبشرة الدهنية الحساسة بشرتي دهنيه حساسه...</td>\n    </tr>\n    <tr>\n      <th>1591</th>\n      <td>NaN</td>\n      <td>علاج للاكزيما العصبية</td>\n      <td>حرج</td>\n      <td>اكزيما العصبيه</td>\n      <td>جلديه وتناسليه</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ</td>\n      <td>NaN</td>\n      <td>علاج للاكزيما العصبية</td>\n      <td>علاج للاكزيما العصبية</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية</td>\n      <td>ﺍﻻﻛﺰﻳﻤﺎ ﺍﻟﻌﺼﺒﻴﺔ علاج للاكزيما العصبية</td>\n    </tr>\n  </tbody>\n</table>\n<p>1592 rows × 12 columns</p>\n</div>"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"df['Severity'] = df['Severity'].astype('category')\ndf['target'] = df['Severity'].cat.codes\n\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:26.586942Z","iopub.execute_input":"2024-12-28T21:01:26.587230Z","iopub.status.idle":"2024-12-28T21:01:26.604178Z","shell.execute_reply.started":"2024-12-28T21:01:26.587205Z","shell.execute_reply":"2024-12-28T21:01:26.603054Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"  Image type                                               Post Severity  \\\n0    Unknown  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...      حرج   \n1    Unknown          يخوان شو الحل مع القولون العصبي مشان الله  غير حرج   \n2    Unknown  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...      حرج   \n3    Unknown  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...  غير حرج   \n4    Unknown  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...  غير حرج   \n\n               Diagnosis             Type  \\\n0              مخ واعصاب        مخ واعصاب   \n1             قولون عصبي            باطنه   \n2          كدمه في الوجه  انف واذن وحنجره   \n3                    ضغط            باطنه   \n4  عدم التركيز و النسيان        مخ واعصاب   \n\n                                                 NER  \\\n0  ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1                                     ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ   \n2                        \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ   \n3   \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4  \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n\n                                          Summarised  \\\n0  ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...   \n1                                         ﻗﻮﻟﻮﻥ عصبي   \n2  ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...   \n3  ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...   \n4              ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة   \n\n                                              Refine  \\\n0  \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1  قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2  \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3  صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4  \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n\n                                              Post.1  \\\n0  السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...   \n1          يخوان شو الحل مع القولون العصبي مشان الله   \n2  لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...   \n3  حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...   \n4  عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...   \n\n                                             Refined  \\\n0  \\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...   \n1  قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...   \n2  \\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...   \n3  صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...   \n4  \\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...   \n\n                                            NER_POST  \\\n0  ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...   \n1  ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...   \n2   \\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...   \n3   \\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...   \n4  \\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...   \n\n                                     Summarised_POST  target  \n0  ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...       0  \n1  ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...       1  \n2  ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...       0  \n3  ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...       1  \n4  ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image type</th>\n      <th>Post</th>\n      <th>Severity</th>\n      <th>Diagnosis</th>\n      <th>Type</th>\n      <th>NER</th>\n      <th>Summarised</th>\n      <th>Refine</th>\n      <th>Post.1</th>\n      <th>Refined</th>\n      <th>NER_POST</th>\n      <th>Summarised_POST</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Unknown</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>حرج</td>\n      <td>مخ واعصاب</td>\n      <td>مخ واعصاب</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>السلام عليكم انا بنت 19 سنة  , و رجلي اليمين ب...</td>\n      <td>\\n\\n الشكوى مشكلة في الرجلين\\n الأعراض صعوبة ا...</td>\n      <td>ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﺮﺟﻠﻴﻦ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍﻟﻤﺸﻲ , ﻣﺸﻜﻠﺔ ﻓﻲ ﺍ...</td>\n      <td>ﺍﻟﻤﺸﻲ ﺑﻨﺴﺒﺎﻟﻲ صعب شوية حتى لو قاعدة او نايمة ر...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Unknown</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>غير حرج</td>\n      <td>قولون عصبي</td>\n      <td>باطنه</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>يخوان شو الحل مع القولون العصبي مشان الله</td>\n      <td>قولون العصبي\\nيخوان شو الحل مع القولون العصبي ...</td>\n      <td>ﺍﻟﻘﻮﻟﻮﻥ ﺍﻟﻌﺼﺒﻲ يخوان شو الحل مع القولون العصبي...</td>\n      <td>ﻗﻮﻟﻮﻥ عصبي يخوان شو الحل مع القولون العصبي مشا...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Unknown</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>حرج</td>\n      <td>كدمه في الوجه</td>\n      <td>انف واذن وحنجره</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>لو سمحتوا أنا اتخبط في وشي خبطة جامدة وبقالي ث...</td>\n      <td>\\n\\n الشكوى وشي خبطة جامدة\\n الأعراض\\n   بقالي...</td>\n      <td>\\n, ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ\\n, ﺩﻡ ﻓﻲ ﺃﻧﻒ لو سمحتوا أنا اتخ...</td>\n      <td>ﺧﺒﻄﺔ ﺟﺎﻣﺪﺓ , ﺩﻡ ﻓﻲ ﺃﻧﻒ , ﻣﺶ ﺣﺎﺳﺲ ﺑﺄﺳﻨﺎﻧﻲ , ﻛﺪﻣ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Unknown</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>غير حرج</td>\n      <td>ضغط</td>\n      <td>باطنه</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>حاله اجهاد دائمه وصداع متقطع من وقت للتانى تغي...</td>\n      <td>صداع متقطع\\n ضغط في الرأس حاله اجهاد دائمه وصد...</td>\n      <td>\\n, ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ\\n, ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ\\n, ﻏﺪﺓ ﺣﺪﻳ...</td>\n      <td>ﺻﺪﺍﻉ ﻣﺘﻘﻄﻊ , ﺗﻐﻴﺮ ﻓﻲ ﺿﻐﻂ ﺍﻟﺪﻡ من وقت للتانى تغ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Unknown</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>غير حرج</td>\n      <td>عدم التركيز و النسيان</td>\n      <td>مخ واعصاب</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>عندي 21 سنه تركيزي منعدم بنسى بسرعه ومبركزش \\n...</td>\n      <td>\\n\\n تركيز منعدم بنسى بسرعة ومبركزش\\n الشكوى ا...</td>\n      <td>\\n, ﺗﺮﻛﻴﺰﻱ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﻪ ﻭﻣﺒﺮﻛﺰﺵ \\n, ﺍﻟﻨﺤﺎﻓ...</td>\n      <td>ﺗﺮﻛﻴﺰ ﻣﻨﻌﺪﻡ ﺑﻨﺴﻰ ﺑﺴﺮﻋﺔ ﻭﻣﺒﺮﻛﺰﺵ 21 سنة عندي 21 ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"df['Severity'].cat.categories\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:30.336165Z","iopub.execute_input":"2024-12-28T21:01:30.336464Z","iopub.status.idle":"2024-12-28T21:01:30.342027Z","shell.execute_reply.started":"2024-12-28T21:01:30.336439Z","shell.execute_reply":"2024-12-28T21:01:30.341225Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"Index(['حرج', 'غير حرج'], dtype='object')"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"category_map = {code: category for code, category in enumerate(df['Severity'].cat.categories)}\ncategory_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:33.607428Z","iopub.execute_input":"2024-12-28T21:01:33.607786Z","iopub.status.idle":"2024-12-28T21:01:33.613321Z","shell.execute_reply.started":"2024-12-28T21:01:33.607758Z","shell.execute_reply":"2024-12-28T21:01:33.612456Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"{0: 'حرج', 1: 'غير حرج'}"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"\ntrain_end_point = int(df.shape[0]*0.6)\nval_end_point = int(df.shape[0]*0.8)\ndf_train = df.iloc[:train_end_point,:]\ndf_val = df.iloc[train_end_point:val_end_point,:]\ndf_test = df.iloc[val_end_point:,:]\nprint(df_train.shape, df_test.shape, df_val.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:36.693327Z","iopub.execute_input":"2024-12-28T21:01:36.693639Z","iopub.status.idle":"2024-12-28T21:01:36.699960Z","shell.execute_reply.started":"2024-12-28T21:01:36.693612Z","shell.execute_reply":"2024-12-28T21:01:36.699089Z"}},"outputs":[{"name":"stdout","text":"(955, 13) (319, 13) (318, 13)\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# Drop 'type', 'severity', and 'age' columns along with 'label'\ndataset_train = Dataset.from_pandas(df_train.drop(['Type', 'Severity','Diagnosis', 'Image type','Post','NER','Summarised','Refine','Post.1','Summarised_POST','NER_POST'], axis=1))\ndataset_val = Dataset.from_pandas(df_val.drop(['Type', 'Severity','Diagnosis', 'Image type','Post','NER','Summarised','Refine','Post.1','Summarised_POST','NER_POST'], axis=1))\ndataset_test = Dataset.from_pandas(df_test.drop(['Type', 'Severity','Diagnosis', 'Image type','Post','NER','Summarised','Refine','Post.1','Summarised_POST','NER_POST'], axis=1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:42.247474Z","iopub.execute_input":"2024-12-28T21:01:42.247819Z","iopub.status.idle":"2024-12-28T21:01:42.275397Z","shell.execute_reply.started":"2024-12-28T21:01:42.247791Z","shell.execute_reply":"2024-12-28T21:01:42.274775Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"dataset_train_shuffled = dataset_train.shuffle(seed=42)  # Using a seed for reproducibility\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:48.549289Z","iopub.execute_input":"2024-12-28T21:01:48.549610Z","iopub.status.idle":"2024-12-28T21:01:48.556737Z","shell.execute_reply.started":"2024-12-28T21:01:48.549583Z","shell.execute_reply":"2024-12-28T21:01:48.556041Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"\n# Combine them into a single DatasetDict\ndataset = DatasetDict({\n    'train': dataset_train_shuffled,\n    'val': dataset_val,\n    'test': dataset_test\n})\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:52.226662Z","iopub.execute_input":"2024-12-28T21:01:52.226973Z","iopub.status.idle":"2024-12-28T21:01:52.232334Z","shell.execute_reply.started":"2024-12-28T21:01:52.226944Z","shell.execute_reply":"2024-12-28T21:01:52.231313Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Refined', 'target'],\n        num_rows: 955\n    })\n    val: Dataset({\n        features: ['Refined', 'target'],\n        num_rows: 318\n    })\n    test: Dataset({\n        features: ['Refined', 'target'],\n        num_rows: 319\n    })\n})"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"dataset['train']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:56.821449Z","iopub.execute_input":"2024-12-28T21:01:56.821815Z","iopub.status.idle":"2024-12-28T21:01:56.827078Z","shell.execute_reply.started":"2024-12-28T21:01:56.821784Z","shell.execute_reply":"2024-12-28T21:01:56.826167Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Refined', 'target'],\n    num_rows: 955\n})"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"print(df_train['Severity'].unique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:01:57.669607Z","iopub.execute_input":"2024-12-28T21:01:57.669927Z","iopub.status.idle":"2024-12-28T21:01:57.676009Z","shell.execute_reply.started":"2024-12-28T21:01:57.669900Z","shell.execute_reply":"2024-12-28T21:01:57.674898Z"}},"outputs":[{"name":"stdout","text":"['حرج', 'غير حرج']\nCategories (2, object): ['حرج', 'غير حرج']\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"df_train.target.value_counts(normalize=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:01.097478Z","iopub.execute_input":"2024-12-28T21:02:01.097811Z","iopub.status.idle":"2024-12-28T21:02:01.104793Z","shell.execute_reply.started":"2024-12-28T21:02:01.097786Z","shell.execute_reply":"2024-12-28T21:02:01.103927Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"target\n1    0.548691\n0    0.451309\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"\nclass_weights=(1/df_train.target.value_counts(normalize=True).sort_index()).tolist()\nclass_weights=torch.tensor(class_weights)\nclass_weights=class_weights/class_weights.sum()\nclass_weights\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:02.199414Z","iopub.execute_input":"2024-12-28T21:02:02.199756Z","iopub.status.idle":"2024-12-28T21:02:02.208102Z","shell.execute_reply.started":"2024-12-28T21:02:02.199730Z","shell.execute_reply":"2024-12-28T21:02:02.207335Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"tensor([0.5487, 0.4513])"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"model_name = \"CAMeL-Lab/bert-base-arabic-camelbert-mix\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:02.961271Z","iopub.execute_input":"2024-12-28T21:02:02.961550Z","iopub.status.idle":"2024-12-28T21:02:02.965142Z","shell.execute_reply.started":"2024-12-28T21:02:02.961514Z","shell.execute_reply":"2024-12-28T21:02:02.964320Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enable 4-bit quantization\n    bnb_4bit_quant_type='nf4',  # Quantization type\n    bnb_4bit_use_double_quant=True,  # Double quantization\n    bnb_4bit_compute_dtype=torch.bfloat16  # Compute in bfloat16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:04.624728Z","iopub.execute_input":"2024-12-28T21:02:04.625014Z","iopub.status.idle":"2024-12-28T21:02:04.640913Z","shell.execute_reply.started":"2024-12-28T21:02:04.624987Z","shell.execute_reply":"2024-12-28T21:02:04.640084Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,\n    lora_alpha=8,\n    target_modules=['query', 'key', 'value', 'dense'],  # Simplified layer names\n    lora_dropout=0.05,\n    bias='none',\n    task_type='SEQ_CLS'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:05.043327Z","iopub.execute_input":"2024-12-28T21:02:05.043613Z","iopub.status.idle":"2024-12-28T21:02:05.047735Z","shell.execute_reply.started":"2024-12-28T21:02:05.043588Z","shell.execute_reply":"2024-12-28T21:02:05.046721Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    quantization_config=quantization_config,\n    num_labels=len(category_map)\n)\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:05.393295Z","iopub.execute_input":"2024-12-28T21:02:05.393547Z","iopub.status.idle":"2024-12-28T21:02:07.235307Z","shell.execute_reply.started":"2024-12-28T21:02:05.393525Z","shell.execute_reply":"2024-12-28T21:02:07.234582Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-mix and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"PeftModelForSequenceClassification(\n  (base_model): LoraModel(\n    (model): BertForSequenceClassification(\n      (bert): BertModel(\n        (embeddings): BertEmbeddings(\n          (word_embeddings): Embedding(30000, 768, padding_idx=0)\n          (position_embeddings): Embedding(512, 768)\n          (token_type_embeddings): Embedding(2, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): BertEncoder(\n          (layer): ModuleList(\n            (0-11): 12 x BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (key): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (value): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): lora.Linear4bit(\n                    (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=768, out_features=3072, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=768, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=3072, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): lora.Linear4bit(\n                  (base_layer): Linear4bit(in_features=3072, out_features=768, bias=True)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=3072, out_features=16, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=16, out_features=768, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                )\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (pooler): BertPooler(\n          (dense): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=768, out_features=768, bias=True)\n            (lora_dropout): ModuleDict(\n              (default): Dropout(p=0.05, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (default): Linear(in_features=768, out_features=16, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (default): Linear(in_features=16, out_features=768, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n          )\n          (activation): Tanh()\n        )\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n      (classifier): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=768, out_features=2, bias=True)\n        (modules_to_save): ModuleDict(\n          (default): Linear(in_features=768, out_features=2, bias=True)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"!pip install -U bitsandbytes\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall bitsandbytes -y\n!pip install bitsandbytes\n!pip install -U accelerate\n!pip install bitsandbytes transformers accelerate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the tokenizer with `add_prefix_space` if necessary for the specific model\ntokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n\n# Assign the `eos_token` to be used as the padding token\nif tokenizer.pad_token is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id  # Use eos_token_id for padding\n    tokenizer.pad_token = tokenizer.eos_token       # Assign eos_token as pad_token\n\n# Update the model configuration to use the tokenizer's pad_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\nmodel.config.use_cache = False  # Prevent caching during training for better compatibility\n\n# Resize model embeddings if a new pad_token was added\nif len(tokenizer) != model.config.vocab_size:\n    model.resize_token_embeddings(len(tokenizer))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:12.863383Z","iopub.execute_input":"2024-12-28T21:02:12.863730Z","iopub.status.idle":"2024-12-28T21:02:12.996507Z","shell.execute_reply.started":"2024-12-28T21:02:12.863700Z","shell.execute_reply":"2024-12-28T21:02:12.995574Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"batch_size = 4  # You can adjust this based on your system's memory capacity\ntext = df_test['Refined'].tolist()\n\n# Initialize an empty list to store the model outputs\nall_outputs = []\n\n# Process the sentences in batches\nfor i in range(0, len(text), batch_size):\n    # Get the batch of sentences\n    batch_sentences = text[i:i + batch_size]\n\n    # Tokenize the batch\n    inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n    # Move tensors to the device where the model is (e.g., GPU or CPU)\n    inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n\n    # Perform inference and store the logits\n    with torch.no_grad():\n        outputs = model(**inputs)\n        all_outputs.append(outputs['logits'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:20.288318Z","iopub.execute_input":"2024-12-28T21:02:20.288641Z","iopub.status.idle":"2024-12-28T21:02:24.169262Z","shell.execute_reply.started":"2024-12-28T21:02:20.288613Z","shell.execute_reply":"2024-12-28T21:02:24.168572Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"final_outputs = torch.cat(all_outputs, dim=0)\nfinal_outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:24.170262Z","iopub.execute_input":"2024-12-28T21:02:24.170471Z","iopub.status.idle":"2024-12-28T21:02:24.234025Z","shell.execute_reply.started":"2024-12-28T21:02:24.170451Z","shell.execute_reply":"2024-12-28T21:02:24.233154Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.1668, -0.0180],\n        [ 0.1681,  0.0852],\n        [ 0.1266,  0.0236],\n        [ 0.2137,  0.2833],\n        [ 0.2011,  0.0502],\n        [ 0.0563,  0.0256],\n        [ 0.4111,  0.2196],\n        [ 0.1570,  0.4121],\n        [ 0.0660,  0.2880],\n        [ 0.2485,  0.3359],\n        [ 0.3058,  0.2676],\n        [ 0.1406,  0.2937],\n        [ 0.1525,  0.1467],\n        [ 0.2093,  0.1997],\n        [ 0.2766,  0.1696],\n        [ 0.3083,  0.2756],\n        [ 0.1523,  0.2146],\n        [ 0.0801,  0.1596],\n        [ 0.1797,  0.1700],\n        [ 0.2048,  0.2226],\n        [ 0.1048,  0.1776],\n        [ 0.1472,  0.3305],\n        [ 0.0577,  0.1922],\n        [ 0.3103,  0.2268],\n        [ 0.2958,  0.2105],\n        [ 0.3664,  0.4464],\n        [ 0.3997,  0.3086],\n        [ 0.3318,  0.0721],\n        [ 0.4485,  0.2970],\n        [ 0.2430,  0.1236],\n        [ 0.2847,  0.4116],\n        [ 0.0998, -0.0907],\n        [ 0.1921,  0.2787],\n        [ 0.3995,  0.3809],\n        [ 0.1827, -0.0309],\n        [ 0.2537,  0.2943],\n        [ 0.3445, -0.2338],\n        [ 0.1851,  0.0717],\n        [ 0.1626,  0.3013],\n        [ 0.2332,  0.1732],\n        [ 0.1714,  0.3263],\n        [ 0.1447,  0.2818],\n        [ 0.2636,  0.2066],\n        [ 0.2101,  0.3153],\n        [ 0.1978,  0.1804],\n        [ 0.1833,  0.2389],\n        [ 0.2483,  0.2246],\n        [ 0.1743,  0.2021],\n        [ 0.0648,  0.2785],\n        [ 0.2540,  0.2317],\n        [ 0.2700,  0.2046],\n        [ 0.3504, -0.2704],\n        [ 0.2006,  0.1307],\n        [ 0.0958,  0.1541],\n        [ 0.0915,  0.1298],\n        [ 0.2099,  0.1020],\n        [ 0.2472,  0.1213],\n        [ 0.1011,  0.2380],\n        [ 0.3444,  0.2818],\n        [ 0.0132,  0.0695],\n        [ 0.0906,  0.2840],\n        [ 0.1367,  0.0296],\n        [ 0.0917, -0.1083],\n        [ 0.2876,  0.2244],\n        [ 0.2579,  0.2834],\n        [ 0.0454,  0.1570],\n        [ 0.1070,  0.2975],\n        [ 0.2072,  0.2507],\n        [ 0.1782,  0.1537],\n        [ 0.1523,  0.3256],\n        [ 0.1557,  0.2306],\n        [ 0.1335,  0.1547],\n        [ 0.1484,  0.2089],\n        [ 0.0704,  0.3038],\n        [ 0.3286,  0.2706],\n        [ 0.1773,  0.1667],\n        [ 0.1614,  0.3638],\n        [ 0.2237,  0.1719],\n        [ 0.0622,  0.1398],\n        [ 0.0786,  0.1934],\n        [ 0.2928,  0.2836],\n        [ 0.3732, -0.2040],\n        [ 0.3388,  0.4486],\n        [ 0.3506, -0.1999],\n        [ 0.3724,  0.3411],\n        [ 0.1173,  0.2333],\n        [ 0.1470,  0.1320],\n        [ 0.1723,  0.1566],\n        [ 0.1677,  0.3429],\n        [ 0.1173,  0.1888],\n        [ 0.2271,  0.4331],\n        [ 0.2995,  0.3646],\n        [ 0.3414,  0.1852],\n        [ 0.1694,  0.3346],\n        [ 0.3810,  0.1903],\n        [ 0.0782,  0.1378],\n        [ 0.2009,  0.2714],\n        [ 0.1565,  0.2368],\n        [ 0.2860,  0.3060],\n        [ 0.1321,  0.2301],\n        [ 0.2056,  0.2071],\n        [ 0.1024,  0.2650],\n        [ 0.2821,  0.2035],\n        [ 0.1881,  0.2526],\n        [ 0.3234,  0.2483],\n        [ 0.1562,  0.2173],\n        [ 0.2201,  0.3993],\n        [ 0.2642,  0.1985],\n        [ 0.1208,  0.3786],\n        [ 0.1997,  0.2557],\n        [ 0.2650,  0.3361],\n        [ 0.4113, -0.2340],\n        [ 0.1778,  0.1685],\n        [ 0.1895,  0.1852],\n        [ 0.2223,  0.1247],\n        [ 0.1849, -0.1191],\n        [ 0.0970,  0.3803],\n        [ 0.2257,  0.2139],\n        [ 0.0374,  0.1684],\n        [ 0.1897,  0.2518],\n        [ 0.2426,  0.2786],\n        [ 0.0579,  0.1574],\n        [ 0.2022,  0.2493],\n        [ 0.1843,  0.1417],\n        [ 0.1161, -0.0125],\n        [ 0.0842,  0.2275],\n        [ 0.3356,  0.3317],\n        [ 0.2126,  0.2471],\n        [ 0.2431,  0.1472],\n        [ 0.0312,  0.2952],\n        [ 0.2414,  0.2480],\n        [-0.0858,  0.0629],\n        [ 0.1398,  0.2099],\n        [ 0.1339,  0.2944],\n        [ 0.3242, -0.2812],\n        [ 0.2657,  0.3839],\n        [ 0.2050,  0.2788],\n        [ 0.1889,  0.1472],\n        [ 0.2175,  0.0981],\n        [ 0.1417,  0.2908],\n        [ 0.2470,  0.2780],\n        [ 0.2431,  0.2191],\n        [ 0.2263,  0.1780],\n        [ 0.0262,  0.2091],\n        [ 0.2140,  0.0750],\n        [ 0.2234,  0.1236],\n        [ 0.2085,  0.2262],\n        [ 0.2384,  0.0601],\n        [ 0.1687, -0.0557],\n        [ 0.3149,  0.3285],\n        [ 0.2081,  0.1362],\n        [ 0.2118,  0.2100],\n        [ 0.0623,  0.1319],\n        [ 0.2877,  0.0969],\n        [ 0.1550,  0.1849],\n        [ 0.1731, -0.2670],\n        [ 0.1671,  0.0736],\n        [ 0.1713, -0.2700],\n        [ 0.0459,  0.2456],\n        [ 0.1220,  0.1692],\n        [ 0.2132,  0.3566],\n        [ 0.1932,  0.1908],\n        [ 0.2503,  0.1432],\n        [ 0.2307,  0.2060],\n        [ 0.2331,  0.0595],\n        [ 0.1687, -0.0557],\n        [ 0.2761,  0.2135],\n        [ 0.0522,  0.0588],\n        [ 0.3884,  0.1463],\n        [ 0.2367,  0.3552],\n        [ 0.0253,  0.1988],\n        [-0.0229,  0.2481],\n        [ 0.1412,  0.1901],\n        [ 0.0844,  0.1715],\n        [ 0.2107,  0.2538],\n        [ 0.1979,  0.3600],\n        [ 0.3114,  0.2172],\n        [ 0.1858,  0.2863],\n        [ 0.3870, -0.2987],\n        [ 0.2197, -0.0598],\n        [ 0.1512,  0.3016],\n        [ 0.0253,  0.2700],\n        [ 0.2522,  0.2912],\n        [ 0.1362,  0.2211],\n        [ 0.3897, -0.2016],\n        [ 0.0936,  0.2656],\n        [ 0.2110,  0.0271],\n        [ 0.2089,  0.1889],\n        [ 0.0782,  0.2415],\n        [ 0.0866,  0.1122],\n        [ 0.3889, -0.2722],\n        [ 0.3775, -0.3229],\n        [ 0.2204,  0.3664],\n        [ 0.3815, -0.2494],\n        [ 0.1555,  0.1927],\n        [ 0.2323,  0.3644],\n        [ 0.2403,  0.1659],\n        [ 0.2468,  0.1481],\n        [ 0.3220, -0.2666],\n        [ 0.4382, -0.2350],\n        [ 0.2342,  0.2471],\n        [ 0.0779,  0.2446],\n        [ 0.1824,  0.1879],\n        [ 0.1432,  0.3032],\n        [ 0.4480, -0.3753],\n        [ 0.3956, -0.3804],\n        [ 0.4336, -0.2592],\n        [ 0.3375, -0.0810],\n        [ 0.2320,  0.3738],\n        [ 0.0970,  0.2183],\n        [ 0.3775, -0.3680],\n        [ 0.2207,  0.1373],\n        [ 0.0662,  0.1880],\n        [ 0.3602, -0.2819],\n        [ 0.1874,  0.3020],\n        [ 0.4149, -0.2860],\n        [ 0.2515,  0.2927],\n        [ 0.1213,  0.0866],\n        [ 0.4039,  0.2096],\n        [ 0.2681,  0.2676],\n        [ 0.1680,  0.1596],\n        [ 0.3953, -0.2093],\n        [ 0.1394,  0.3876],\n        [ 0.4073, -0.2296],\n        [ 0.0813,  0.3339],\n        [ 0.2860, -0.1879],\n        [ 0.1897,  0.5238],\n        [ 0.0599,  0.2535],\n        [ 0.2299,  0.1752],\n        [ 0.1154,  0.1160],\n        [ 0.2142,  0.3290],\n        [ 0.2173, -0.0807],\n        [ 0.3370,  0.1901],\n        [ 0.1300,  0.4274],\n        [ 0.1231,  0.1464],\n        [ 0.2377,  0.2062],\n        [ 0.0580,  0.3018],\n        [ 0.1485,  0.0311],\n        [ 0.1674,  0.2936],\n        [ 0.3841, -0.3585],\n        [ 0.2566,  0.2523],\n        [ 0.3049, -0.2364],\n        [ 0.1880,  0.3183],\n        [ 0.0875,  0.1535],\n        [ 0.3319,  0.3119],\n        [ 0.2804,  0.2572],\n        [ 0.2152,  0.3108],\n        [ 0.1228,  0.2393],\n        [ 0.0068,  0.3103],\n        [ 0.1083,  0.4382],\n        [ 0.1365,  0.0939],\n        [ 0.3096, -0.2744],\n        [ 0.1342,  0.1796],\n        [ 0.2942, -0.2247],\n        [ 0.4383, -0.4002],\n        [ 0.1798,  0.2880],\n        [ 0.2462,  0.2576],\n        [ 0.2807,  0.2698],\n        [ 0.3575,  0.2454],\n        [ 0.1915, -0.0323],\n        [ 0.1768,  0.2425],\n        [ 0.3237,  0.2101],\n        [ 0.2455, -0.1419],\n        [ 0.2192, -0.1778],\n        [ 0.3321, -0.1730],\n        [ 0.3101, -0.2128],\n        [ 0.1557, -0.0747],\n        [ 0.3186,  0.2229],\n        [ 0.0432,  0.1499],\n        [ 0.2785, -0.1333],\n        [ 0.3805, -0.2140],\n        [ 0.2580, -0.2708],\n        [ 0.2547,  0.2349],\n        [ 0.1364,  0.0743],\n        [ 0.0803,  0.2492],\n        [ 0.0903,  0.0905],\n        [ 0.2383,  0.2309],\n        [ 0.0586,  0.3676],\n        [ 0.1296,  0.1964],\n        [ 0.3520, -0.0903],\n        [ 0.1687,  0.2648],\n        [-0.0065,  0.2211],\n        [ 0.3312, -0.2433],\n        [ 0.2692, -0.1331],\n        [ 0.3296,  0.0623],\n        [ 0.3597, -0.1030],\n        [ 0.3654, -0.1944],\n        [ 0.2258,  0.2072],\n        [ 0.1882, -0.0328],\n        [ 0.0954,  0.1017],\n        [ 0.2609,  0.0606],\n        [ 0.3908, -0.2497],\n        [ 0.0196,  0.1528],\n        [ 0.2993, -0.1338],\n        [ 0.1272,  0.0808],\n        [ 0.4009, -0.3192],\n        [ 0.3687, -0.1476],\n        [ 0.0829,  0.2006],\n        [ 0.1549,  0.2150],\n        [ 0.2459,  0.0607],\n        [ 0.3923, -0.3573],\n        [ 0.1626,  0.2938],\n        [ 0.2457,  0.3931],\n        [-0.0468,  0.2151],\n        [ 0.1601,  0.2766],\n        [ 0.1293,  0.1927],\n        [ 0.3443, -0.2734],\n        [ 0.3549, -0.2497],\n        [ 0.3070, -0.2213],\n        [ 0.1360,  0.1873],\n        [ 0.2180,  0.2338],\n        [ 0.3723, -0.2346],\n        [ 0.3561, -0.1768],\n        [-0.0099,  0.3373],\n        [ 0.0931, -0.0750],\n        [ 0.4361, -0.3415],\n        [ 0.3240,  0.2122],\n        [ 0.1325,  0.3396],\n        [ 0.2541, -0.0923]], device='cuda:0')"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"final_outputs.argmax(axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:29.915697Z","iopub.execute_input":"2024-12-28T21:02:29.916018Z","iopub.status.idle":"2024-12-28T21:02:29.929769Z","shell.execute_reply.started":"2024-12-28T21:02:29.915974Z","shell.execute_reply":"2024-12-28T21:02:29.928861Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"tensor([0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n        0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n        1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n        1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n        1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n        1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n        1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n        1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n        0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n        0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n        0, 1, 0, 0, 0, 1, 0], device='cuda:0')"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"df_test['Severity'].value_counts()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:31.298058Z","iopub.execute_input":"2024-12-28T21:02:31.298385Z","iopub.status.idle":"2024-12-28T21:02:31.305984Z","shell.execute_reply.started":"2024-12-28T21:02:31.298354Z","shell.execute_reply":"2024-12-28T21:02:31.304995Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"Severity\nغير حرج    191\nحرج        128\nName: count, dtype: int64"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\ndf_test['predictions']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:34.372710Z","iopub.execute_input":"2024-12-28T21:02:34.373035Z","iopub.status.idle":"2024-12-28T21:02:34.381316Z","shell.execute_reply.started":"2024-12-28T21:02:34.373005Z","shell.execute_reply":"2024-12-28T21:02:34.380416Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-78-7c1d2547ae19>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n","output_type":"stream"},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"1273    0\n1274    0\n1275    0\n1276    1\n1277    0\n       ..\n1587    0\n1588    0\n1589    0\n1590    1\n1591    0\nName: predictions, Length: 319, dtype: int64"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"def get_performance_metrics(df_test):\n  y_test = df_test.target\n  y_pred = df_test.predictions\n\n  print(\"Confusion Matrix:\")\n  print(confusion_matrix(y_test, y_pred))\n\n  print(\"\\nClassification Report:\")\n  print(classification_report(y_test, y_pred))\n\n  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:35.838561Z","iopub.execute_input":"2024-12-28T21:02:35.838841Z","iopub.status.idle":"2024-12-28T21:02:35.843380Z","shell.execute_reply.started":"2024-12-28T21:02:35.838818Z","shell.execute_reply":"2024-12-28T21:02:35.842395Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"get_performance_metrics(df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:38.543574Z","iopub.execute_input":"2024-12-28T21:02:38.543887Z","iopub.status.idle":"2024-12-28T21:02:38.565004Z","shell.execute_reply.started":"2024-12-28T21:02:38.543861Z","shell.execute_reply":"2024-12-28T21:02:38.564228Z"}},"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[ 66  62]\n [101  90]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.40      0.52      0.45       128\n           1       0.59      0.47      0.52       191\n\n    accuracy                           0.49       319\n   macro avg       0.49      0.49      0.49       319\nweighted avg       0.51      0.49      0.49       319\n\nBalanced Accuracy Score: 0.49341459424083767\nAccuracy Score: 0.4890282131661442\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"MAX_LEN = 512\ncol_to_delete = ['Refined']\n\ndef llama_preprocessing_function(examples):\n    return tokenizer(examples['Refined'], truncation=True, max_length=MAX_LEN)\n\ntokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\ntokenized_datasets = tokenized_datasets.rename_column(\"target\", \"label\")\ntokenized_datasets.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:45.286058Z","iopub.execute_input":"2024-12-28T21:02:45.286367Z","iopub.status.idle":"2024-12-28T21:02:45.580642Z","shell.execute_reply.started":"2024-12-28T21:02:45.286342Z","shell.execute_reply":"2024-12-28T21:02:45.579744Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/955 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"701c04fbc975485f849f1e078501103b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/318 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fcb75ae3c884e5ba3dd68132aa99376"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15691f06658f4496994de656c8c001bf"}},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:47.173428Z","iopub.execute_input":"2024-12-28T21:02:47.173746Z","iopub.status.idle":"2024-12-28T21:02:47.177551Z","shell.execute_reply.started":"2024-12-28T21:02:47.173719Z","shell.execute_reply":"2024-12-28T21:02:47.176710Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:47.939191Z","iopub.execute_input":"2024-12-28T21:02:47.939473Z","iopub.status.idle":"2024-12-28T21:02:47.943894Z","shell.execute_reply.started":"2024-12-28T21:02:47.939448Z","shell.execute_reply":"2024-12-28T21:02:47.942915Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"class CustomTrainer(Trainer):\n    def __init__(self, *args, class_weights=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Ensure label_weights is a tensor\n        if class_weights is not None:\n            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n        else:\n            self.class_weights = None\n\n        # Initialize an empty list to store epoch results\n        self.epoch_logs = []\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        # Extract labels and convert them to long type for cross_entropy\n        labels = inputs.pop(\"labels\").long()\n\n        # Forward pass\n        outputs = model(**inputs)\n\n        # Extract logits assuming they are directly outputted by the model\n        logits = outputs.get('logits')\n\n        # Compute custom loss with class weights for imbalanced data handling\n        if self.class_weights is not None:\n            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n        else:\n            loss = F.cross_entropy(logits, labels)\n\n        return (loss, outputs) if return_outputs else loss\n\n    def log_metrics(self, metrics, epoch):\n        # Custom function to log and save metrics\n        print(f\"Epoch {epoch}: {metrics}\")  # Print metrics\n        self.epoch_logs.append(metrics)  # Store the results\n\n    def training_epoch_end(self, outputs):\n        # Overriding to log after each epoch\n        metrics = self.evaluate()  # Evaluate after each epoch\n        self.log_metrics(metrics, epoch=len(self.epoch_logs))  # Log metrics\n\n# Setup the trainer with your model and datasets\n\n\n# Save the logged epoch results to a CSV file\nimport csv\n\nwith open(\"epoch_results.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerow([\"epoch\", \"metric_name\", \"value\"])  # Define your columns\n    for epoch, metrics in enumerate(trainer.epoch_logs):\n        for key, value in metrics.items():\n            writer.writerow([epoch + 1, key, value])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:03:05.545580Z","iopub.execute_input":"2024-12-28T21:03:05.545876Z","iopub.status.idle":"2024-12-28T21:03:05.554131Z","shell.execute_reply.started":"2024-12-28T21:03:05.545853Z","shell.execute_reply":"2024-12-28T21:03:05.553313Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='sentiment_classification',\n    logging_dir='./logs',  # Directory to save logs\n    logging_steps=10,  # Adjust the frequency of logging steps\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    num_train_epochs=25,\n    learning_rate=1e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:02:55.064772Z","iopub.execute_input":"2024-12-28T21:02:55.065072Z","iopub.status.idle":"2024-12-28T21:02:55.102751Z","shell.execute_reply.started":"2024-12-28T21:02:55.065046Z","shell.execute_reply":"2024-12-28T21:02:55.102059Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"\ntrainer = CustomTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = tokenized_datasets['train'],\n    eval_dataset = tokenized_datasets['val'],\n    tokenizer = tokenizer,\n    data_collator = collate_fn,\n    compute_metrics = compute_metrics,\n    class_weights=class_weights,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:03:01.470651Z","iopub.execute_input":"2024-12-28T21:03:01.471085Z","iopub.status.idle":"2024-12-28T21:03:01.577932Z","shell.execute_reply.started":"2024-12-28T21:03:01.471043Z","shell.execute_reply":"2024-12-28T21:03:01.577045Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-86-c8295c069935>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"from accelerate import Accelerator\n\naccelerator = Accelerator()\nprint(accelerator.state)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:03:08.381675Z","iopub.execute_input":"2024-12-28T21:03:08.381955Z","iopub.status.idle":"2024-12-28T21:03:08.388187Z","shell.execute_reply.started":"2024-12-28T21:03:08.381931Z","shell.execute_reply":"2024-12-28T21:03:08.387196Z"}},"outputs":[{"name":"stdout","text":"Distributed environment: NO\nNum processes: 1\nProcess index: 0\nLocal process index: 0\nDevice: cuda\n\nMixed precision type: no\n\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"train_result = trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:03:09.221771Z","iopub.execute_input":"2024-12-28T21:03:09.222049Z","iopub.status.idle":"2024-12-28T21:26:36.794195Z","shell.execute_reply.started":"2024-12-28T21:03:09.222027Z","shell.execute_reply":"2024-12-28T21:26:36.793453Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241228_210309-qvsbmsxn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/kokyloka2003-msa/huggingface/runs/qvsbmsxn' target=\"_blank\">fluent-plant-27</a></strong> to <a href='https://wandb.ai/kokyloka2003-msa/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/kokyloka2003-msa/huggingface' target=\"_blank\">https://wandb.ai/kokyloka2003-msa/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/kokyloka2003-msa/huggingface/runs/qvsbmsxn' target=\"_blank\">https://wandb.ai/kokyloka2003-msa/huggingface/runs/qvsbmsxn</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 23:19, Epoch 25/25]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Balanced Accuracy</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.722700</td>\n      <td>0.697502</td>\n      <td>0.557233</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.675000</td>\n      <td>0.690447</td>\n      <td>0.531297</td>\n      <td>0.509434</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.658000</td>\n      <td>0.682509</td>\n      <td>0.568519</td>\n      <td>0.559748</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.625800</td>\n      <td>0.671412</td>\n      <td>0.567050</td>\n      <td>0.562893</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.597800</td>\n      <td>0.683977</td>\n      <td>0.623718</td>\n      <td>0.616352</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.574100</td>\n      <td>0.708742</td>\n      <td>0.655633</td>\n      <td>0.635220</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.567100</td>\n      <td>0.725534</td>\n      <td>0.593822</td>\n      <td>0.597484</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.444900</td>\n      <td>0.797867</td>\n      <td>0.611942</td>\n      <td>0.578616</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.400300</td>\n      <td>0.813890</td>\n      <td>0.574274</td>\n      <td>0.578616</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.285900</td>\n      <td>0.842219</td>\n      <td>0.581311</td>\n      <td>0.578616</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.400700</td>\n      <td>0.944952</td>\n      <td>0.602375</td>\n      <td>0.588050</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.380200</td>\n      <td>1.030969</td>\n      <td>0.586788</td>\n      <td>0.581761</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.151400</td>\n      <td>1.130378</td>\n      <td>0.558836</td>\n      <td>0.559748</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.190200</td>\n      <td>1.270580</td>\n      <td>0.550528</td>\n      <td>0.553459</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.153100</td>\n      <td>1.416352</td>\n      <td>0.559230</td>\n      <td>0.562893</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.115600</td>\n      <td>1.513950</td>\n      <td>0.561804</td>\n      <td>0.559748</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.161700</td>\n      <td>1.660034</td>\n      <td>0.571301</td>\n      <td>0.575472</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.085900</td>\n      <td>1.777452</td>\n      <td>0.558162</td>\n      <td>0.562893</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.067900</td>\n      <td>1.840057</td>\n      <td>0.542024</td>\n      <td>0.544025</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.047400</td>\n      <td>1.870204</td>\n      <td>0.553459</td>\n      <td>0.553459</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.040600</td>\n      <td>1.961950</td>\n      <td>0.550079</td>\n      <td>0.550314</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.019000</td>\n      <td>2.051292</td>\n      <td>0.549496</td>\n      <td>0.553459</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.047000</td>\n      <td>2.075992</td>\n      <td>0.548748</td>\n      <td>0.550314</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.046200</td>\n      <td>2.104162</td>\n      <td>0.547547</td>\n      <td>0.550314</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.019200</td>\n      <td>2.116832</td>\n      <td>0.547547</td>\n      <td>0.550314</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"metrics = trainer.evaluate(eval_dataset=tokenized_datasets['test'])\nprint(\"Test Set Metrics:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:33:52.751015Z","iopub.execute_input":"2024-12-28T21:33:52.751330Z","iopub.status.idle":"2024-12-28T21:33:57.000890Z","shell.execute_reply.started":"2024-12-28T21:33:52.751305Z","shell.execute_reply":"2024-12-28T21:33:56.999966Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Test Set Metrics: {'eval_loss': 0.6689162850379944, 'eval_balanced_accuracy': 0.581008060944282, 'eval_accuracy': 0.6050156739811913, 'eval_runtime': 4.2391, 'eval_samples_per_second': 75.251, 'eval_steps_per_second': 4.718, 'epoch': 25.0}\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"df_train['target'].value_counts(normalize=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:33:57.001997Z","iopub.execute_input":"2024-12-28T21:33:57.002333Z","iopub.status.idle":"2024-12-28T21:33:57.010192Z","shell.execute_reply.started":"2024-12-28T21:33:57.002307Z","shell.execute_reply":"2024-12-28T21:33:57.009203Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"target\n1    0.548691\n0    0.451309\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":92},{"cell_type":"code","source":"df_test['target'].value_counts(normalize=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:33:57.011817Z","iopub.execute_input":"2024-12-28T21:33:57.012095Z","iopub.status.idle":"2024-12-28T21:33:57.023428Z","shell.execute_reply.started":"2024-12-28T21:33:57.012073Z","shell.execute_reply":"2024-12-28T21:33:57.022576Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"target\n1    0.598746\n0    0.401254\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"df_val['target'].value_counts(normalize=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:33:57.024445Z","iopub.execute_input":"2024-12-28T21:33:57.024741Z","iopub.status.idle":"2024-12-28T21:33:57.037779Z","shell.execute_reply.started":"2024-12-28T21:33:57.024713Z","shell.execute_reply":"2024-12-28T21:33:57.036743Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"target\n1    0.537736\n0    0.462264\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"def make_predictions(model, df_test):\n\n    # Convert summaries to a list\n    sentences = df_test['Refined'].tolist()\n\n    # Define the batch size\n    batch_size = 4  # You can adjust this based on your system's memory capacity\n\n    # Initialize an empty list to store the model outputs\n    all_outputs = []\n\n    # Process the sentences in batches\n    for i in range(0, len(sentences), batch_size):\n        # Get the batch of sentences\n        batch_sentences = sentences[i:i + batch_size]\n\n        # Tokenize the batch\n        inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n\n        # Move tensors to the device where the model is (e.g., GPU or CPU)\n        inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n\n        # Perform inference and store the logits\n        with torch.no_grad():\n            outputs = model(**inputs)\n            all_outputs.append(outputs['logits'])\n\n    final_outputs = torch.cat(all_outputs, dim=0)\n\n    # Update using .loc to avoid SettingWithCopyWarning\n    df_test.loc[:, 'predictions'] = final_outputs.argmax(axis=1).cpu().numpy()\n\n    # Apply category mapping\n    df_test.loc[:, 'predictions'] = df_test['predictions'].apply(lambda l: category_map[l])\n\n# Make predictions\nmake_predictions(model, df_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:33:57.332456Z","iopub.execute_input":"2024-12-28T21:33:57.332728Z","iopub.status.idle":"2024-12-28T21:34:01.174952Z","shell.execute_reply.started":"2024-12-28T21:33:57.332707Z","shell.execute_reply":"2024-12-28T21:34:01.174282Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"def get_performance_metrics(df_test):\n    # Convert both target and predictions back to numeric using category_map\n    reverse_category_map = {v: k for k, v in category_map.items()}  # Reverse the category_map to map strings to numbers\n    y_test = df_test['target']\n    y_pred = df_test['predictions'].apply(lambda x: reverse_category_map[x])\n\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_test, y_pred))\n\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n\n    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n\n# Run the function again\nget_performance_metrics(df_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:34:01.175983Z","iopub.execute_input":"2024-12-28T21:34:01.176234Z","iopub.status.idle":"2024-12-28T21:34:01.200965Z","shell.execute_reply.started":"2024-12-28T21:34:01.176203Z","shell.execute_reply":"2024-12-28T21:34:01.199870Z"}},"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[ 54  74]\n [ 52 139]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.51      0.42      0.46       128\n           1       0.65      0.73      0.69       191\n\n    accuracy                           0.61       319\n   macro avg       0.58      0.57      0.57       319\nweighted avg       0.60      0.61      0.60       319\n\nBalanced Accuracy Score: 0.5748118455497382\nAccuracy Score: 0.6050156739811913\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"import os\n\n# Directory to save the model (inside /kaggle/outputs for persistence)\nsave_directory = \"/kaggle/working/camelbert-Refinedd\"\n\n# Create the directory if it does not exist\nos.makedirs(save_directory, exist_ok=True)\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model and tokenizer saved successfully to '{save_directory}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:37:08.371662Z","iopub.execute_input":"2024-12-28T21:37:08.371989Z","iopub.status.idle":"2024-12-28T21:37:08.631413Z","shell.execute_reply.started":"2024-12-28T21:37:08.371961Z","shell.execute_reply":"2024-12-28T21:37:08.630652Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved successfully to '/kaggle/working/camelbert-Refinedd'\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"!zip -r camelbert-Refinedd_model.zip /kaggle/working/camelbert-Refinedd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:37:08.852685Z","iopub.execute_input":"2024-12-28T21:37:08.853037Z","iopub.status.idle":"2024-12-28T21:37:09.696777Z","shell.execute_reply.started":"2024-12-28T21:37:08.853006Z","shell.execute_reply":"2024-12-28T21:37:09.695975Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/camelbert-Refinedd/ (stored 0%)\n  adding: kaggle/working/camelbert-Refinedd/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/camelbert-Refinedd/tokenizer.json (deflated 73%)\n  adding: kaggle/working/camelbert-Refinedd/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/camelbert-Refinedd/README.md (deflated 66%)\n  adding: kaggle/working/camelbert-Refinedd/vocab.txt (deflated 62%)\n  adding: kaggle/working/camelbert-Refinedd/special_tokens_map.json (deflated 42%)\n  adding: kaggle/working/camelbert-Refinedd/adapter_config.json (deflated 51%)\n","output_type":"stream"}],"execution_count":107},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'camelbert-Refinedd_model.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T21:37:09.698360Z","iopub.execute_input":"2024-12-28T21:37:09.698718Z","iopub.status.idle":"2024-12-28T21:37:09.705149Z","shell.execute_reply.started":"2024-12-28T21:37:09.698682Z","shell.execute_reply":"2024-12-28T21:37:09.704287Z"}},"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/camelbert-Refinedd_model.zip","text/html":"<a href='camelbert-Refinedd_model.zip' target='_blank'>camelbert-Refinedd_model.zip</a><br>"},"metadata":{}}],"execution_count":108},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}